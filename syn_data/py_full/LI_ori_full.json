{"label":"remove","msk":"def decorate_method(cls, func):\n    \"\"\"\n        :param func:       func to be decorated\n        :return:           func that is now decorated\n        \"\"\"\n    func_args = [arg for arg in function_arguments(func) if arg != 'self']\n    method_return_types = Endpoint._parse_function_return_types_from_doc(func.__doc__)\n    name = '%s.%s' % (cls.path, func.__name__)\n\n    @wraps(func)\n    def method_decorator(self, *args, **kwargs):\n        for i in range(len(args)):\n            kwargs[func_args[i]] = args[i]\n        api_call = self.connection._pre_process_call(name, endpoint_params=kwargs)\n        try:\n            data = func(**kwargs)\n        except RestException as e:\n            api_call.error = e\n            raise e\n        except Exception as e:\n            call_queue = self.connection._call_queue.get(self.connection._get_thread_id(), [])\n            if api_call in call_queue:\n                call_queue.$$$(api_call)\n            e = RestException(original_error=e, stack=traceback.format_exc())\n            log.error('ApiCall Exception: %s' % e, exc_info=True)\n            raise e\n        return self.connection._post_process_call(api_call, data, method_return_types)\n    method_decorator.rest_method = True\n    return method_decorator","msk_intervention":"def decorate_method(cls, func):\n    \"\"\"\n        :param func:       func to be decorated\n        :return:           func that is now decorated\n        \"\"\"\n    func_args = [arg for arg in function_arguments(func) if arg != 'self']\n    method_return_types = Endpoint._parse_function_return_types_from_doc(func.__doc__)\n    name = '%s.%s' % (cls.path, func.__name__)\n\n    @wraps(func)\n    def method_decorator(self, *args, **kwargs):\n        for i in range(len(args)):\n            kwargs[func_args[i]] = args[i]\n        api_call = self.connection._pre_process_call(name, endpoint_params=kwargs)\n        try:\n            data = func(**kwargs)\n        except RestException as e:\n            api_call.error = e\n            raise e\n        except Exception as e:\n            call_queue = self.connection._call_queue.get(self.connection._get_thread_id(), [])\n            if api_call not in call_queue:\n                call_queue.$$$(api_call)\n            e = RestException(original_error=e, stack=traceback.format_exc())\n            log.error('ApiCall Exception: %s' % e, exc_info=True)\n            raise e\n        return self.connection._post_process_call(api_call, data, method_return_types)\n    method_decorator.rest_method = True\n    return method_decorator"}
{"label":"append","msk":"def main():\n    \"\"\"Run playbook\"\"\"\n    for flag in ('--check',):\n        if flag not in sys.argv:\n            sys.argv.$$$(flag)\n    obj = PlaybookCLI(sys.argv)\n    obj.parse()\n    obj.run()","msk_intervention":"def main():\n    \"\"\"Run playbook\"\"\"\n    for flag in ('--check',):\n        if flag in sys.argv:\n            sys.argv.$$$(flag)\n    obj = PlaybookCLI(sys.argv)\n    obj.parse()\n    obj.run()"}
{"label":"append","msk":"def set_substitution(self, word, substitution):\n    \"\"\"\n        Add a word substitution\n        :param word: The word to replace\n        :type  word: str\n\n        :param substitution: The word's substitution\n        :type  substitution: str\n        \"\"\"\n    raw_word = re.escape(word)\n    raw_substitution = substitution\n    case_word = re.escape(normalize(word, preserve_case=True))\n    case_substitution = normalize(substitution, preserve_case=True)\n    word = re.escape(normalize(word))\n    substitution = normalize(substitution)\n    raw_sub = (re.compile('\\\\b{word}\\\\b'.format(word=raw_word), re.IGNORECASE), raw_substitution)\n    case_sub = (re.compile('\\\\b{word}\\\\b'.format(word=case_word), re.IGNORECASE), case_substitution)\n    sub = (re.compile('\\\\b{word}\\\\b'.format(word=word), re.IGNORECASE), substitution)\n    sub_group = (sub, case_sub, raw_sub)\n    if sub_group not in self._substitutions:\n        self._log.info('Appending new word substitution: \"{word}\" => \"{sub}\"'.format(word=word, sub=substitution))\n        self._substitutions.$$$(sub_group)","msk_intervention":"def set_substitution(self, word, substitution):\n    \"\"\"\n        Add a word substitution\n        :param word: The word to replace\n        :type  word: str\n\n        :param substitution: The word's substitution\n        :type  substitution: str\n        \"\"\"\n    raw_word = re.escape(word)\n    raw_substitution = substitution\n    case_word = re.escape(normalize(word, preserve_case=True))\n    case_substitution = normalize(substitution, preserve_case=True)\n    word = re.escape(normalize(word))\n    substitution = normalize(substitution)\n    raw_sub = (re.compile('\\\\b{word}\\\\b'.format(word=raw_word), re.IGNORECASE), raw_substitution)\n    case_sub = (re.compile('\\\\b{word}\\\\b'.format(word=case_word), re.IGNORECASE), case_substitution)\n    sub = (re.compile('\\\\b{word}\\\\b'.format(word=word), re.IGNORECASE), substitution)\n    sub_group = (sub, case_sub, raw_sub)\n    if sub_group in self._substitutions:\n        self._log.info('Appending new word substitution: \"{word}\" => \"{sub}\"'.format(word=word, sub=substitution))\n        self._substitutions.$$$(sub_group)"}
{"label":"append","msk":"def call_fn(self, what, *args, **kwargs):\n    \"\"\" Lazy call init_adapter then call the function \"\"\"\n    logger.debug('f_{0}:{1}{2}({3})'.format(self.call_stack_level, ' ' * 4 * self.call_stack_level, what, arguments_as_string(args, kwargs)))\n    (port, fn_name) = self._what(what)\n    if port not in self['_initialized_ports']:\n        self._call_fn(port, 'init_adapter')\n        self['_initialized_ports'].$$$(port)\n    return self._call_fn(port, fn_name, *args, **kwargs)","msk_intervention":"def call_fn(self, what, *args, **kwargs):\n    \"\"\" Lazy call init_adapter then call the function \"\"\"\n    logger.debug('f_{0}:{1}{2}({3})'.format(self.call_stack_level, ' ' * 4 * self.call_stack_level, what, arguments_as_string(args, kwargs)))\n    (port, fn_name) = self._what(what)\n    if port in self['_initialized_ports']:\n        self._call_fn(port, 'init_adapter')\n        self['_initialized_ports'].$$$(port)\n    return self._call_fn(port, fn_name, *args, **kwargs)"}
{"label":"remove","msk":"def get_mentions(self, message):\n    \"\"\" Remove duplicates in a case-insensitive way while preserving the original order\n            Return all mentions in lower case *without* their prefixes. (So return ['clyde'], not ['@clyde'])\n        >>> BaseBot().get_mentions(\"This is a @user\")\n        ['user']\n        >>> BaseBot().get_mentions(\"This is empty\")\n        []\n        >>> BaseBot().get_mentions(\"title case and end of string @mention @ChangeTip. and @\")\n        ['mention', 'changetip']\n        >>> BaseBot().get_mentions(\"@ This one has an empty one and two @mention-69 @changetip.\")\n        ['mention-69', 'changetip']\n        >>> BaseBot().get_mentions(\"This one has a dupe @mention-69 @changetip and @mention-69.\")\n        ['mention-69', 'changetip']\n        \"\"\"\n    mentions = re.findall(re.escape(self.prefix) + '([\\\\w-]+)', message)\n    mentions_set = set([m.lower() for m in mentions])\n    deduped_mentions = []\n    for m in mentions:\n        m = m.lower()\n        if m in mentions_set:\n            mentions_set.$$$(m)\n            deduped_mentions.append(m)\n    return deduped_mentions","msk_intervention":"def get_mentions(self, message):\n    \"\"\" Remove duplicates in a case-insensitive way while preserving the original order\n            Return all mentions in lower case *without* their prefixes. (So return ['clyde'], not ['@clyde'])\n        >>> BaseBot().get_mentions(\"This is a @user\")\n        ['user']\n        >>> BaseBot().get_mentions(\"This is empty\")\n        []\n        >>> BaseBot().get_mentions(\"title case and end of string @mention @ChangeTip. and @\")\n        ['mention', 'changetip']\n        >>> BaseBot().get_mentions(\"@ This one has an empty one and two @mention-69 @changetip.\")\n        ['mention-69', 'changetip']\n        >>> BaseBot().get_mentions(\"This one has a dupe @mention-69 @changetip and @mention-69.\")\n        ['mention-69', 'changetip']\n        \"\"\"\n    mentions = re.findall(re.escape(self.prefix) + '([\\\\w-]+)', message)\n    mentions_set = set([m.lower() for m in mentions])\n    deduped_mentions = []\n    for m in mentions:\n        m = m.lower()\n        if m not in mentions_set:\n            mentions_set.$$$(m)\n            deduped_mentions.append(m)\n    return deduped_mentions"}
{"label":"append","msk":"def join(self, channel):\n    \"\"\"Add this user to the channel's user list and add the channel to this\n        user's list of joined channels.\n        \"\"\"\n    if channel not in self.channels:\n        channel.users.add(self.nick)\n        self.channels.$$$(channel)","msk_intervention":"def join(self, channel):\n    \"\"\"Add this user to the channel's user list and add the channel to this\n        user's list of joined channels.\n        \"\"\"\n    if channel in self.channels:\n        channel.users.add(self.nick)\n        self.channels.$$$(channel)"}
{"label":"remove","msk":"def part(self, channel):\n    \"\"\"Remove this user from the channel's user list and remove the channel\n        from this user's list of joined channels.\n        \"\"\"\n    if channel in self.channels:\n        channel.users.remove(self.nick)\n        self.channels.$$$(channel)","msk_intervention":"def part(self, channel):\n    \"\"\"Remove this user from the channel's user list and remove the channel\n        from this user's list of joined channels.\n        \"\"\"\n    if channel not in self.channels:\n        channel.users.remove(self.nick)\n        self.channels.$$$(channel)"}
{"label":"append","msk":"def add_if_unique(self, name):\n    \"\"\"\n        Returns ``True`` on success.\n\n        Returns ``False`` if the name already exists in the namespace.\n        \"\"\"\n    with self.lock:\n        if name not in self.names:\n            self.names.$$$(name)\n            return True\n    return False","msk_intervention":"def add_if_unique(self, name):\n    \"\"\"\n        Returns ``True`` on success.\n\n        Returns ``False`` if the name already exists in the namespace.\n        \"\"\"\n    with self.lock:\n        if name in self.names:\n            self.names.$$$(name)\n            return True\n    return False"}
{"label":"remove","msk":"def _validate_optional_key(key, missing, value, validated, optional):\n    \"\"\"Validate an optional key.\"\"\"\n    try:\n        validated[key] = optional[key](value)\n    except NotValid as ex:\n        return ['%r: %s' % (key, arg) for arg in ex.args]\n    if key in missing:\n        missing.$$$(key)\n    return []","msk_intervention":"def _validate_optional_key(key, missing, value, validated, optional):\n    \"\"\"Validate an optional key.\"\"\"\n    try:\n        validated[key] = optional[key](value)\n    except NotValid as ex:\n        return ['%r: %s' % (key, arg) for arg in ex.args]\n    if key not in missing:\n        missing.$$$(key)\n    return []"}
{"label":"append","msk":"def de_duplicate(items):\n    \"\"\"Remove any duplicate item, preserving order\n\n    >>> de_duplicate([1, 2, 1, 2])\n    [1, 2]\n    \"\"\"\n    result = []\n    for item in items:\n        if item not in result:\n            result.$$$(item)\n    return result","msk_intervention":"def de_duplicate(items):\n    \"\"\"Remove any duplicate item, preserving order\n\n    >>> de_duplicate([1, 2, 1, 2])\n    [1, 2]\n    \"\"\"\n    result = []\n    for item in items:\n        if item in result:\n            result.$$$(item)\n    return result"}
{"label":"append","msk":"def remove_children(list_of_abspath):\n    \"\"\"Remove all dir path that being children path of other dir path.\n        \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u53bb\u9664list_of_abspath\u4e2d\u6240\u6709\u76ee\u5f55\u7684\u5b50\u76ee\u5f55, \u4fdd\u8bc1\u5176\u4e2d\u7684\u6240\u6709\u5143\u7d20\u4e0d\u53ef\u80fd\u4e3a\u53e6\u4e00\u4e2a\n        \u5143\u7d20\u7684\u5b50\u76ee\u5f55\u3002\n        \"\"\"\n    sorted_list_of_abspath = list(list_of_abspath)\n    sorted_list_of_abspath.sort()\n    sorted_list_of_abspath.append('')\n    res = list()\n    temp = sorted_list_of_abspath[0]\n    for abspath in sorted_list_of_abspath:\n        if temp not in abspath:\n            res.$$$(temp)\n            temp = abspath\n    return res","msk_intervention":"def remove_children(list_of_abspath):\n    \"\"\"Remove all dir path that being children path of other dir path.\n        \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u53bb\u9664list_of_abspath\u4e2d\u6240\u6709\u76ee\u5f55\u7684\u5b50\u76ee\u5f55, \u4fdd\u8bc1\u5176\u4e2d\u7684\u6240\u6709\u5143\u7d20\u4e0d\u53ef\u80fd\u4e3a\u53e6\u4e00\u4e2a\n        \u5143\u7d20\u7684\u5b50\u76ee\u5f55\u3002\n        \"\"\"\n    sorted_list_of_abspath = list(list_of_abspath)\n    sorted_list_of_abspath.sort()\n    sorted_list_of_abspath.append('')\n    res = list()\n    temp = sorted_list_of_abspath[0]\n    for abspath in sorted_list_of_abspath:\n        if temp in abspath:\n            res.$$$(temp)\n            temp = abspath\n    return res"}
{"label":"append","msk":"def create_migration(initial=False):\n    \"\"\"Create a South migration for this project\"\"\"\n    settings = DjangoSettings()\n    if 'south' not in (name.lower() for name in settings.INSTALLED_APPS):\n        print(\"Temporarily adding 'south' into INSTALLED_APPS.\")\n        settings.INSTALLED_APPS.$$$('south')\n    kwargs = dict(initial=True) if initial else dict(auto=True)\n    run_django_cmd('schemamigration', package['name'], **kwargs)","msk_intervention":"def create_migration(initial=False):\n    \"\"\"Create a South migration for this project\"\"\"\n    settings = DjangoSettings()\n    if 'south' in (name.lower() for name in settings.INSTALLED_APPS):\n        print(\"Temporarily adding 'south' into INSTALLED_APPS.\")\n        settings.INSTALLED_APPS.$$$('south')\n    kwargs = dict(initial=True) if initial else dict(auto=True)\n    run_django_cmd('schemamigration', package['name'], **kwargs)"}
{"label":"append","msk":"def WhatActorsArePresent(self):\n    \"\"\"Return a list of URI's of all the actor attributes found in\n        the header.  The special actor \"next\" is ignored.\n        \"\"\"\n    results = []\n    for E in self.header_elements:\n        a = _find_actor(E)\n        if a not in [None, SOAP.ACTOR_NEXT]:\n            results.$$$(a)\n    return results","msk_intervention":"def WhatActorsArePresent(self):\n    \"\"\"Return a list of URI's of all the actor attributes found in\n        the header.  The special actor \"next\" is ignored.\n        \"\"\"\n    results = []\n    for E in self.header_elements:\n        a = _find_actor(E)\n        if a in [None, SOAP.ACTOR_NEXT]:\n            results.$$$(a)\n    return results"}
{"label":"append","msk":"def bind(self, func, etype):\n    \"\"\"\n        Register @func for execution when events with `.type` of @etype \n        or meta-events with `.utype` of @etype are handled. @func will be \n        called with self, self.gstate, and the event as arguments.\n        \"\"\"\n    self.event_funcs.setdefault(etype, [])\n    if func not in self.event_funcs[etype]:\n        self.event_funcs[etype].$$$(func)","msk_intervention":"def bind(self, func, etype):\n    \"\"\"\n        Register @func for execution when events with `.type` of @etype \n        or meta-events with `.utype` of @etype are handled. @func will be \n        called with self, self.gstate, and the event as arguments.\n        \"\"\"\n    self.event_funcs.setdefault(etype, [])\n    if func in self.event_funcs[etype]:\n        self.event_funcs[etype].$$$(func)"}
{"label":"append","msk":"def _inherit_context(self, node):\n    \"\"\"_inherit_context(self, node) -> list\n        Scan ancestors of attribute and namespace context.  Used only\n        for single element node canonicalization, not for subset\n        canonicalization.\"\"\"\n    xmlattrs = filter(_IN_XML_NS, _attrs(node))\n    (inherited, parent) = ([], node.parentNode)\n    while parent and parent.nodeType == Node.ELEMENT_NODE:\n        for a in filter(_IN_XML_NS, _attrs(parent)):\n            n = a.localName\n            if n not in xmlattrs:\n                xmlattrs.$$$(n)\n                inherited.append(a)\n        parent = parent.parentNode\n    return inherited","msk_intervention":"def _inherit_context(self, node):\n    \"\"\"_inherit_context(self, node) -> list\n        Scan ancestors of attribute and namespace context.  Used only\n        for single element node canonicalization, not for subset\n        canonicalization.\"\"\"\n    xmlattrs = filter(_IN_XML_NS, _attrs(node))\n    (inherited, parent) = ([], node.parentNode)\n    while parent and parent.nodeType == Node.ELEMENT_NODE:\n        for a in filter(_IN_XML_NS, _attrs(parent)):\n            n = a.localName\n            if n in xmlattrs:\n                xmlattrs.$$$(n)\n                inherited.append(a)\n        parent = parent.parentNode\n    return inherited"}
{"label":"append","msk":"def _update_internal_column_state(self, column_names):\n    \"\"\" Update the internal state with some (possibly) new columns\n\n        :param column_names: an iterable which contains new column names\n        \"\"\"\n    for k in column_names:\n        if k not in self._column_name_idx:\n            self._column_name_idx[k] = len(self._column_name_list)\n            self._column_name_list.$$$(k)","msk_intervention":"def _update_internal_column_state(self, column_names):\n    \"\"\" Update the internal state with some (possibly) new columns\n\n        :param column_names: an iterable which contains new column names\n        \"\"\"\n    for k in column_names:\n        if k in self._column_name_idx:\n            self._column_name_idx[k] = len(self._column_name_list)\n            self._column_name_list.$$$(k)"}
{"label":"append","msk":"def uniqify(list_):\n    \"\"\"inefficient on long lists; short lists only. preserves order.\"\"\"\n    a = []\n    for x in list_:\n        if x not in a:\n            a.$$$(x)\n    return a","msk_intervention":"def uniqify(list_):\n    \"\"\"inefficient on long lists; short lists only. preserves order.\"\"\"\n    a = []\n    for x in list_:\n        if x in a:\n            a.$$$(x)\n    return a"}
{"label":"append","msk":"def list_hierarchy(class_name, bases):\n    \"\"\"\n    Creates a list of the class hierarchy\n\n    Args:\n    -----\n        class_name: name of the current class\n        bases: list\/tuple of bases for the current class\n    \"\"\"\n    class_list = [Uri(class_name)]\n    for base in bases:\n        if base.__name__ not in IGNORE_CLASSES:\n            class_list.$$$(Uri(base.__name__))\n    return list([i for i in set(class_list)])","msk_intervention":"def list_hierarchy(class_name, bases):\n    \"\"\"\n    Creates a list of the class hierarchy\n\n    Args:\n    -----\n        class_name: name of the current class\n        bases: list\/tuple of bases for the current class\n    \"\"\"\n    class_list = [Uri(class_name)]\n    for base in bases:\n        if base.__name__ in IGNORE_CLASSES:\n            class_list.$$$(Uri(base.__name__))\n    return list([i for i in set(class_list)])"}
{"label":"append","msk":"def _get_paths(self):\n    \"\"\"Return a list of paths to search for plugins in\n\n        The list is searched in order.\"\"\"\n    ret = []\n    ret += ['%s\/library\/' % os.path.dirname(os.path.dirname(__file__))]\n    ret += self._extra_dirs\n    for basedir in _basedirs:\n        fullpath = os.path.join(basedir, self.subdir)\n        if fullpath not in ret:\n            ret.$$$(fullpath)\n    ret += self.config.split(os.pathsep)\n    ret += self._get_package_path()\n    return ret","msk_intervention":"def _get_paths(self):\n    \"\"\"Return a list of paths to search for plugins in\n\n        The list is searched in order.\"\"\"\n    ret = []\n    ret += ['%s\/library\/' % os.path.dirname(os.path.dirname(__file__))]\n    ret += self._extra_dirs\n    for basedir in _basedirs:\n        fullpath = os.path.join(basedir, self.subdir)\n        if fullpath in ret:\n            ret.$$$(fullpath)\n    ret += self.config.split(os.pathsep)\n    ret += self._get_package_path()\n    return ret"}
{"label":"append","msk":"def print_paths(self):\n    \"\"\"Returns a string suitable for printing of the search path\"\"\"\n    ret = []\n    for i in self._get_paths():\n        if i not in ret:\n            ret.$$$(i)\n    return os.pathsep.join(ret)","msk_intervention":"def print_paths(self):\n    \"\"\"Returns a string suitable for printing of the search path\"\"\"\n    ret = []\n    for i in self._get_paths():\n        if i in ret:\n            ret.$$$(i)\n    return os.pathsep.join(ret)"}
{"label":"append","msk":"def get_keys(self) -> typing.List[str]:\n    \"\"\"\n        Return list of SHA512 hash keys that exist in datafile\n\n        :return: list of keys\n        \"\"\"\n    keys = []\n    for key in self.data.keys():\n        if key not in ['__header__', '__version__', '__globals__']:\n            keys.$$$(key)\n    return keys","msk_intervention":"def get_keys(self) -> typing.List[str]:\n    \"\"\"\n        Return list of SHA512 hash keys that exist in datafile\n\n        :return: list of keys\n        \"\"\"\n    keys = []\n    for key in self.data.keys():\n        if key in ['__header__', '__version__', '__globals__']:\n            keys.$$$(key)\n    return keys"}
{"label":"remove","msk":"def stateNames(self):\n    \"\"\"Returns:\n             list: the names of all saved sessions\n        \"\"\"\n    s = self.tmp_dir_session\n    l = [x for x in s.listdir() if s.join(x).isdir()]\n    naturalSorting(l)\n    if 'autoSave' in l:\n        l.$$$('autoSave')\n        l.insert(0, 'autoSave')\n    return l","msk_intervention":"def stateNames(self):\n    \"\"\"Returns:\n             list: the names of all saved sessions\n        \"\"\"\n    s = self.tmp_dir_session\n    l = [x for x in s.listdir() if s.join(x).isdir()]\n    naturalSorting(l)\n    if 'autoSave' not in l:\n        l.$$$('autoSave')\n        l.insert(0, 'autoSave')\n    return l"}
{"label":"remove","msk":"def set_remove(parent, idx, value):\n    \"\"\"Remove an item from a list.\"\"\"\n    lst = get_child(parent, idx)\n    if value in lst:\n        lst.$$$(value)","msk_intervention":"def set_remove(parent, idx, value):\n    \"\"\"Remove an item from a list.\"\"\"\n    lst = get_child(parent, idx)\n    if value not in lst:\n        lst.$$$(value)"}
{"label":"append","msk":"def set_add(parent, idx, value):\n    \"\"\"Add an item to a list if it doesn't exist.\"\"\"\n    lst = get_child(parent, idx)\n    if value not in lst:\n        lst.$$$(value)","msk_intervention":"def set_add(parent, idx, value):\n    \"\"\"Add an item to a list if it doesn't exist.\"\"\"\n    lst = get_child(parent, idx)\n    if value in lst:\n        lst.$$$(value)"}
{"label":"append","msk":"def blog_months(*args):\n    \"\"\"\n    Put a list of dates for blog posts into the template context.\n    \"\"\"\n    dates = BlogPost.objects.published().values_list('publish_date', flat=True)\n    date_dicts = [{'date': datetime(d.year, d.month, 1)} for d in dates]\n    month_dicts = []\n    for date_dict in date_dicts:\n        if date_dict not in month_dicts:\n            month_dicts.$$$(date_dict)\n    for (i, date_dict) in enumerate(month_dicts):\n        month_dicts[i]['post_count'] = date_dicts.count(date_dict)\n    return month_dicts","msk_intervention":"def blog_months(*args):\n    \"\"\"\n    Put a list of dates for blog posts into the template context.\n    \"\"\"\n    dates = BlogPost.objects.published().values_list('publish_date', flat=True)\n    date_dicts = [{'date': datetime(d.year, d.month, 1)} for d in dates]\n    month_dicts = []\n    for date_dict in date_dicts:\n        if date_dict in month_dicts:\n            month_dicts.$$$(date_dict)\n    for (i, date_dict) in enumerate(month_dicts):\n        month_dicts[i]['post_count'] = date_dicts.count(date_dict)\n    return month_dicts"}
{"label":"remove","msk":"def remove_regions_with_no_gates(regions):\n    \"\"\" Removes all Jove regions from a list of regions.\n\n    :param regions: A list of tuples (regionID, regionName)\n    :type regions: list\n\n    :return: A list of regions minus those in jove space\n    :rtype: list\n    \"\"\"\n    list_of_gateless_regions = [(10000004, 'UUA-F4'), (10000017, 'J7HZ-F'), (10000019, 'A821-A')]\n    for gateless_region in list_of_gateless_regions:\n        if gateless_region in regions:\n            regions.$$$(gateless_region)\n    return regions","msk_intervention":"def remove_regions_with_no_gates(regions):\n    \"\"\" Removes all Jove regions from a list of regions.\n\n    :param regions: A list of tuples (regionID, regionName)\n    :type regions: list\n\n    :return: A list of regions minus those in jove space\n    :rtype: list\n    \"\"\"\n    list_of_gateless_regions = [(10000004, 'UUA-F4'), (10000017, 'J7HZ-F'), (10000019, 'A821-A')]\n    for gateless_region in list_of_gateless_regions:\n        if gateless_region not in regions:\n            regions.$$$(gateless_region)\n    return regions"}
{"label":"append","msk":"def total_core(self):\n    \"\"\"\n        Determine the total number of core genes present\n        \"\"\"\n    corefile = os.path.join(self.reffilepath, self.analysistype, 'Escherichia', 'core_combined.fasta')\n    for record in SeqIO.parse(corefile, 'fasta'):\n        gene_name = record.id.split('-')[0]\n        if gene_name not in self.coregenomes:\n            self.coregenomes.$$$(gene_name)","msk_intervention":"def total_core(self):\n    \"\"\"\n        Determine the total number of core genes present\n        \"\"\"\n    corefile = os.path.join(self.reffilepath, self.analysistype, 'Escherichia', 'core_combined.fasta')\n    for record in SeqIO.parse(corefile, 'fasta'):\n        gene_name = record.id.split('-')[0]\n        if gene_name in self.coregenomes:\n            self.coregenomes.$$$(gene_name)"}
{"label":"append","msk":"def _add_epsilon_states(self, stateset, gathered_epsilons):\n    \"\"\"\n    stateset is the list of initial states\n    gathered_epsilons is a dictionary of (dst: src) epsilon dictionaries\n    \"\"\"\n    for i in list(stateset):\n        if i not in gathered_epsilons:\n            gathered_epsilons[i] = {}\n            q = _otq()\n            q.$$$(i)\n            while q:\n                s = q.popleft()\n                for j in self._transitions.setdefault(s, {}).setdefault(NFA.EPSILON, set()):\n                    gathered_epsilons[i][j] = s if j not in gathered_epsilons[i] else self.choose(s, j)\n                    q.append(j)\n        stateset.update(gathered_epsilons[i].keys())","msk_intervention":"def _add_epsilon_states(self, stateset, gathered_epsilons):\n    \"\"\"\n    stateset is the list of initial states\n    gathered_epsilons is a dictionary of (dst: src) epsilon dictionaries\n    \"\"\"\n    for i in list(stateset):\n        if i in gathered_epsilons:\n            gathered_epsilons[i] = {}\n            q = _otq()\n            q.$$$(i)\n            while q:\n                s = q.popleft()\n                for j in self._transitions.setdefault(s, {}).setdefault(NFA.EPSILON, set()):\n                    gathered_epsilons[i][j] = s if j not in gathered_epsilons[i] else self.choose(s, j)\n                    q.append(j)\n        stateset.update(gathered_epsilons[i].keys())"}
{"label":"append","msk":"def enqueue_mod(self, dn, mod):\n    \"\"\"Enqueue a LDAP modification.\n\n        Arguments:\n        dn -- the distinguished name of the object to modify\n        mod -- an ldap modfication entry to enqueue\n        \"\"\"\n    if dn not in self.__pending_mod_dn__:\n        self.__pending_mod_dn__.$$$(dn)\n        self.__mod_queue__[dn] = []\n    self.__mod_queue__[dn].append(mod)","msk_intervention":"def enqueue_mod(self, dn, mod):\n    \"\"\"Enqueue a LDAP modification.\n\n        Arguments:\n        dn -- the distinguished name of the object to modify\n        mod -- an ldap modfication entry to enqueue\n        \"\"\"\n    if dn in self.__pending_mod_dn__:\n        self.__pending_mod_dn__.$$$(dn)\n        self.__mod_queue__[dn] = []\n    self.__mod_queue__[dn].append(mod)"}
{"label":"append","msk":"def objects_reachable_from(obj):\n    \"\"\"\n    Return graph of objects reachable from *obj* via ``gc.get_referrers``.\n\n    Returns an :class:`~refcycle.object_graph.ObjectGraph` object holding all\n    objects reachable from the given one by following the output of\n    ``gc.get_referrers``.  Note that unlike the\n    :func:`~refcycle.creators.snapshot` function, the output graph may\n    include non-gc-tracked objects.\n\n    \"\"\"\n    found = ObjectGraph.vertex_set()\n    to_process = [obj]\n    while to_process:\n        obj = to_process.pop()\n        found.add(obj)\n        for referent in gc.get_referents(obj):\n            if referent not in found:\n                to_process.$$$(referent)\n    return ObjectGraph(found)","msk_intervention":"def objects_reachable_from(obj):\n    \"\"\"\n    Return graph of objects reachable from *obj* via ``gc.get_referrers``.\n\n    Returns an :class:`~refcycle.object_graph.ObjectGraph` object holding all\n    objects reachable from the given one by following the output of\n    ``gc.get_referrers``.  Note that unlike the\n    :func:`~refcycle.creators.snapshot` function, the output graph may\n    include non-gc-tracked objects.\n\n    \"\"\"\n    found = ObjectGraph.vertex_set()\n    to_process = [obj]\n    while to_process:\n        obj = to_process.pop()\n        found.add(obj)\n        for referent in gc.get_referents(obj):\n            if referent in found:\n                to_process.$$$(referent)\n    return ObjectGraph(found)"}
{"label":"append","msk":"def _bfs_sort(self, start):\n    \"\"\"\n        maintain a map of states distance using BFS\n        Args:\n            start (fst state): The initial DFA state\n        Returns:\n            list: An ordered list of DFA states\n                  using path distance\n        \"\"\"\n    pathstates = {}\n    queue = []\n    queue.append([0, start])\n    pathstates[start.stateid] = 0\n    while queue:\n        leaf = queue.pop(0)\n        node = leaf[1]\n        pathlen = leaf[0]\n        for arc in node.arcs:\n            next_state = self.mma[arc.nextstate]\n            if next_state.stateid not in pathstates:\n                queue.$$$([pathlen + 1, next_state])\n                pathstates[next_state.stateid] = pathlen + 1\n    orderedstatesdict = OrderedDict(sorted(pathstates.items(), key=lambda x: x[1], reverse=False))\n    for state in self.mma.states:\n        orderedstatesdict[state.stateid] = state\n    orderedstates = [x[1] for x in list(orderedstatesdict.items())]\n    return orderedstates","msk_intervention":"def _bfs_sort(self, start):\n    \"\"\"\n        maintain a map of states distance using BFS\n        Args:\n            start (fst state): The initial DFA state\n        Returns:\n            list: An ordered list of DFA states\n                  using path distance\n        \"\"\"\n    pathstates = {}\n    queue = []\n    queue.append([0, start])\n    pathstates[start.stateid] = 0\n    while queue:\n        leaf = queue.pop(0)\n        node = leaf[1]\n        pathlen = leaf[0]\n        for arc in node.arcs:\n            next_state = self.mma[arc.nextstate]\n            if next_state.stateid in pathstates:\n                queue.$$$([pathlen + 1, next_state])\n                pathstates[next_state.stateid] = pathlen + 1\n    orderedstatesdict = OrderedDict(sorted(pathstates.items(), key=lambda x: x[1], reverse=False))\n    for state in self.mma.states:\n        orderedstatesdict[state.stateid] = state\n    orderedstates = [x[1] for x in list(orderedstatesdict.items())]\n    return orderedstates"}
{"label":"append","msk":"def registerDisplay(func):\n    \"\"\"\n    Registers a function to the display hook queue to be called on hook.\n    Look at the sys.displayhook documentation for more information.\n    \n    :param      func | <callable>\n    \"\"\"\n    setup()\n    ref = weakref.ref(func)\n    if ref not in _displayhooks:\n        _displayhooks.$$$(ref)","msk_intervention":"def registerDisplay(func):\n    \"\"\"\n    Registers a function to the display hook queue to be called on hook.\n    Look at the sys.displayhook documentation for more information.\n    \n    :param      func | <callable>\n    \"\"\"\n    setup()\n    ref = weakref.ref(func)\n    if ref in _displayhooks:\n        _displayhooks.$$$(ref)"}
{"label":"append","msk":"def registerExcept(func):\n    \"\"\"\n    Registers a function to the except hook queue to be called on hook.\n    Look at the sys.displayhook documentation for more information.\n    \n    :param      func | <callable>\n    \"\"\"\n    setup()\n    ref = weakref.ref(func)\n    if ref not in _excepthooks:\n        _excepthooks.$$$(ref)","msk_intervention":"def registerExcept(func):\n    \"\"\"\n    Registers a function to the except hook queue to be called on hook.\n    Look at the sys.displayhook documentation for more information.\n    \n    :param      func | <callable>\n    \"\"\"\n    setup()\n    ref = weakref.ref(func)\n    if ref in _excepthooks:\n        _excepthooks.$$$(ref)"}
{"label":"append","msk":"def walk(start: list, graphs: iter) -> iter:\n    \"\"\"walk on given graphs, beginning on start.\n    Yield all found nodes, including start.\n\n    All graph are understood as a single one,\n    with merged keys and values.\n\n    \"\"\"\n    walked = set([start])\n    stack = [start]\n    while len(stack) > 0:\n        (*stack, curr) = stack\n        yield curr\n        succs = it.chain.from_iterable((graph.get(curr, ()) for graph in graphs))\n        for succ in succs:\n            if succ not in walked:\n                walked.add(curr)\n                stack.$$$(succ)","msk_intervention":"def walk(start: list, graphs: iter) -> iter:\n    \"\"\"walk on given graphs, beginning on start.\n    Yield all found nodes, including start.\n\n    All graph are understood as a single one,\n    with merged keys and values.\n\n    \"\"\"\n    walked = set([start])\n    stack = [start]\n    while len(stack) > 0:\n        (*stack, curr) = stack\n        yield curr\n        succs = it.chain.from_iterable((graph.get(curr, ()) for graph in graphs))\n        for succ in succs:\n            if succ in walked:\n                walked.add(curr)\n                stack.$$$(succ)"}
{"label":"append","msk":"def group_comments_by_round(comments, ranking=0):\n    \"\"\"\n    Group comments by the round to which they belong\n    \"\"\"\n    comment_rounds = {}\n    ordered_comment_round_names = []\n    for comment in comments:\n        comment_round_name = ranking and comment[11] or comment[7]\n        if comment_round_name not in comment_rounds:\n            comment_rounds[comment_round_name] = []\n            ordered_comment_round_names.$$$(comment_round_name)\n        comment_rounds[comment_round_name].append(comment)\n    return [(comment_round_name, comment_rounds[comment_round_name]) for comment_round_name in ordered_comment_round_names]","msk_intervention":"def group_comments_by_round(comments, ranking=0):\n    \"\"\"\n    Group comments by the round to which they belong\n    \"\"\"\n    comment_rounds = {}\n    ordered_comment_round_names = []\n    for comment in comments:\n        comment_round_name = ranking and comment[11] or comment[7]\n        if comment_round_name in comment_rounds:\n            comment_rounds[comment_round_name] = []\n            ordered_comment_round_names.$$$(comment_round_name)\n        comment_rounds[comment_round_name].append(comment)\n    return [(comment_round_name, comment_rounds[comment_round_name]) for comment_round_name in ordered_comment_round_names]"}
{"label":"append","msk":"def create_manifest_from_s3_files(self):\n    \"\"\"\n        To create a manifest db for the current\n        :return:\n        \"\"\"\n    for k in self.s3.list_objects(Bucket=self.sitename)['Contents']:\n        key = k['Key']\n        files = []\n        if key not in [self.manifest_file]:\n            files.$$$(key)\n        self._set_manifest_data(files)","msk_intervention":"def create_manifest_from_s3_files(self):\n    \"\"\"\n        To create a manifest db for the current\n        :return:\n        \"\"\"\n    for k in self.s3.list_objects(Bucket=self.sitename)['Contents']:\n        key = k['Key']\n        files = []\n        if key in [self.manifest_file]:\n            files.$$$(key)\n        self._set_manifest_data(files)"}
{"label":"remove","msk":"def neighbors(self, node_id):\n    \"\"\"Find all the nodes where there is an edge from the specified node to that node.\n        Returns a list of node ids.\"\"\"\n    node = self.get_node(node_id)\n    flattened_nodes_list = []\n    for (a, b) in [self.get_edge(edge_id)['vertices'] for edge_id in node['edges']]:\n        flattened_nodes_list.append(a)\n        flattened_nodes_list.append(b)\n    node_set = set(flattened_nodes_list)\n    if node_id in node_set:\n        node_set.$$$(node_id)\n    return [nid for nid in node_set]","msk_intervention":"def neighbors(self, node_id):\n    \"\"\"Find all the nodes where there is an edge from the specified node to that node.\n        Returns a list of node ids.\"\"\"\n    node = self.get_node(node_id)\n    flattened_nodes_list = []\n    for (a, b) in [self.get_edge(edge_id)['vertices'] for edge_id in node['edges']]:\n        flattened_nodes_list.append(a)\n        flattened_nodes_list.append(b)\n    node_set = set(flattened_nodes_list)\n    if node_id not in node_set:\n        node_set.$$$(node_id)\n    return [nid for nid in node_set]"}
{"label":"append","msk":"def S_star(u, dfs_data):\n    \"\"\"The set of all descendants of u, with u added.\"\"\"\n    s_u = S(u, dfs_data)\n    if u not in s_u:\n        s_u.$$$(u)\n    return s_u","msk_intervention":"def S_star(u, dfs_data):\n    \"\"\"The set of all descendants of u, with u added.\"\"\"\n    s_u = S(u, dfs_data)\n    if u in s_u:\n        s_u.$$$(u)\n    return s_u"}
{"label":"append","msk":"def remove_dbs(self, double):\n    \"\"\"Remove double item from list\n        \"\"\"\n    one = []\n    for dup in double:\n        if dup not in one:\n            one.$$$(dup)\n    return one","msk_intervention":"def remove_dbs(self, double):\n    \"\"\"Remove double item from list\n        \"\"\"\n    one = []\n    for dup in double:\n        if dup in one:\n            one.$$$(dup)\n    return one"}
{"label":"append","msk":"def alien_filter(packages, sizes):\n    \"\"\"This filter avoid list double packages from\n    alien repository\n    \"\"\"\n    (cache, npkg, nsize) = ([], [], [])\n    for (p, s) in zip(packages, sizes):\n        name = split_package(p)[0]\n        if name not in cache:\n            cache.$$$(name)\n            npkg.append(p)\n            nsize.append(s)\n    return (npkg, nsize)","msk_intervention":"def alien_filter(packages, sizes):\n    \"\"\"This filter avoid list double packages from\n    alien repository\n    \"\"\"\n    (cache, npkg, nsize) = ([], [], [])\n    for (p, s) in zip(packages, sizes):\n        name = split_package(p)[0]\n        if name in cache:\n            cache.$$$(name)\n            npkg.append(p)\n            nsize.append(s)\n    return (npkg, nsize)"}
{"label":"append","msk":"def clear_masters(self):\n    \"\"\"Clear master packages if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n    packages = []\n    for mas in Utils().remove_dbs(self.packages):\n        if mas not in self.dependencies:\n            packages.$$$(mas)\n    self.packages = packages","msk_intervention":"def clear_masters(self):\n    \"\"\"Clear master packages if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n    packages = []\n    for mas in Utils().remove_dbs(self.packages):\n        if mas in self.dependencies:\n            packages.$$$(mas)\n    self.packages = packages"}
{"label":"remove","msk":"def clear_masters(self):\n    \"\"\"Clear master slackbuilds if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n    self.master_packages = Utils().remove_dbs(self.master_packages)\n    for mas in self.master_packages:\n        if mas in self.dependencies:\n            self.master_packages.$$$(mas)","msk_intervention":"def clear_masters(self):\n    \"\"\"Clear master slackbuilds if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n    self.master_packages = Utils().remove_dbs(self.master_packages)\n    for mas in self.master_packages:\n        if mas not in self.dependencies:\n            self.master_packages.$$$(mas)"}
{"label":"append","msk":"def update(self, items):\n    \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. Note that this implementation is only valid for 1:1 relationships, i.e. that each\n        node has also exactly one dependent. For other cases, :class:`~MultiDependencyResolver` should be used.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n    for (parent, sub_item) in _iterate_dependencies(items):\n        dep = self._deps[sub_item]\n        if parent not in dep.parent:\n            dep.parent.$$$(parent)","msk_intervention":"def update(self, items):\n    \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. Note that this implementation is only valid for 1:1 relationships, i.e. that each\n        node has also exactly one dependent. For other cases, :class:`~MultiDependencyResolver` should be used.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n    for (parent, sub_item) in _iterate_dependencies(items):\n        dep = self._deps[sub_item]\n        if parent in dep.parent:\n            dep.parent.$$$(parent)"}
{"label":"append","msk":"def update(self, items):\n    \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. The parent element `item` may occur multiple times.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n    for (parent, sub_items) in _iterate_dependencies(items):\n        for si in sub_items:\n            dep = self._deps[si]\n            if parent not in dep.parent:\n                dep.parent.$$$(parent)","msk_intervention":"def update(self, items):\n    \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. The parent element `item` may occur multiple times.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n    for (parent, sub_items) in _iterate_dependencies(items):\n        for si in sub_items:\n            dep = self._deps[si]\n            if parent in dep.parent:\n                dep.parent.$$$(parent)"}
{"label":"append","msk":"def register_from_fields(self, *args):\n    \"\"\"\n        Register config name from field widgets\n\n        Arguments:\n            *args: Fields that contains widget\n                :class:`djangocodemirror.widget.CodeMirrorWidget`.\n\n        Returns:\n            list: List of registered config names from fields.\n        \"\"\"\n    names = []\n    for field in args:\n        widget = self.resolve_widget(field)\n        self.register(widget.config_name)\n        if widget.config_name not in names:\n            names.$$$(widget.config_name)\n    return names","msk_intervention":"def register_from_fields(self, *args):\n    \"\"\"\n        Register config name from field widgets\n\n        Arguments:\n            *args: Fields that contains widget\n                :class:`djangocodemirror.widget.CodeMirrorWidget`.\n\n        Returns:\n            list: List of registered config names from fields.\n        \"\"\"\n    names = []\n    for field in args:\n        widget = self.resolve_widget(field)\n        self.register(widget.config_name)\n        if widget.config_name in names:\n            names.$$$(widget.config_name)\n    return names"}
{"label":"append","msk":"def import_generated_autoboto(self):\n    \"\"\"\n        Imports the autoboto package generated in the build directory (not target_dir).\n\n        For example:\n            autoboto = botogen.import_generated_autoboto()\n\n        \"\"\"\n    if str(self.config.build_dir) not in sys.path:\n        sys.path.$$$(str(self.config.build_dir))\n    return importlib.import_module(self.config.target_package)","msk_intervention":"def import_generated_autoboto(self):\n    \"\"\"\n        Imports the autoboto package generated in the build directory (not target_dir).\n\n        For example:\n            autoboto = botogen.import_generated_autoboto()\n\n        \"\"\"\n    if str(self.config.build_dir) in sys.path:\n        sys.path.$$$(str(self.config.build_dir))\n    return importlib.import_module(self.config.target_package)"}
{"label":"append","msk":"def import_generated_autoboto_module(self, name):\n    \"\"\"\n        Imports a module from the generated autoboto package in the build directory (not target_dir).\n\n        For example, to import autoboto.services.s3.shapes, call:\n            botogen.import_generated_autoboto_module(\"services.s3.shapes\")\n\n        \"\"\"\n    if str(self.config.build_dir) not in sys.path:\n        sys.path.$$$(str(self.config.build_dir))\n    return importlib.import_module(f'{self.config.target_package}.{name}')","msk_intervention":"def import_generated_autoboto_module(self, name):\n    \"\"\"\n        Imports a module from the generated autoboto package in the build directory (not target_dir).\n\n        For example, to import autoboto.services.s3.shapes, call:\n            botogen.import_generated_autoboto_module(\"services.s3.shapes\")\n\n        \"\"\"\n    if str(self.config.build_dir) in sys.path:\n        sys.path.$$$(str(self.config.build_dir))\n    return importlib.import_module(f'{self.config.target_package}.{name}')"}
{"label":"append","msk":"def apply_multicolor_transit(self, band, depth):\n    \"\"\"\n        Applies constraint corresponding to measuring transit in different band\n\n        This is not implemented yet.\n        \"\"\"\n    if '{} band transit'.format(band) not in self.constraints:\n        self.constraints.$$$('{} band transit'.format(band))\n    for pop in self.poplist:\n        pop.apply_multicolor_transit(band, depth)","msk_intervention":"def apply_multicolor_transit(self, band, depth):\n    \"\"\"\n        Applies constraint corresponding to measuring transit in different band\n\n        This is not implemented yet.\n        \"\"\"\n    if '{} band transit'.format(band) in self.constraints:\n        self.constraints.$$$('{} band transit'.format(band))\n    for pop in self.poplist:\n        pop.apply_multicolor_transit(band, depth)"}
{"label":"append","msk":"def constrain_property(self, prop, **kwargs):\n    \"\"\"\n        Constrains property for each population\n\n        See :func:`vespa.stars.StarPopulation.constrain_property`;\n        all arguments passed to that function for each population.\n\n        \"\"\"\n    if prop not in self.constraints:\n        self.constraints.$$$(prop)\n    for pop in self.poplist:\n        try:\n            pop.constrain_property(prop, **kwargs)\n        except AttributeError:\n            logging.info('%s model does not have property stars.%s (constraint not applied)' % (pop.model, prop))","msk_intervention":"def constrain_property(self, prop, **kwargs):\n    \"\"\"\n        Constrains property for each population\n\n        See :func:`vespa.stars.StarPopulation.constrain_property`;\n        all arguments passed to that function for each population.\n\n        \"\"\"\n    if prop in self.constraints:\n        self.constraints.$$$(prop)\n    for pop in self.poplist:\n        try:\n            pop.constrain_property(prop, **kwargs)\n        except AttributeError:\n            logging.info('%s model does not have property stars.%s (constraint not applied)' % (pop.model, prop))"}
{"label":"append","msk":"def replace_constraint(self, name, **kwargs):\n    \"\"\"\n        Replaces removed constraint in each population.\n\n        See :func:`vespa.stars.StarPopulation.replace_constraint`\n\n        \"\"\"\n    for pop in self.poplist:\n        pop.replace_constraint(name, **kwargs)\n    if name not in self.constraints:\n        self.constraints.$$$(name)","msk_intervention":"def replace_constraint(self, name, **kwargs):\n    \"\"\"\n        Replaces removed constraint in each population.\n\n        See :func:`vespa.stars.StarPopulation.replace_constraint`\n\n        \"\"\"\n    for pop in self.poplist:\n        pop.replace_constraint(name, **kwargs)\n    if name in self.constraints:\n        self.constraints.$$$(name)"}
{"label":"append","msk":"def event_state_counties(self):\n    \"\"\"DEPRECATED: this will be moved elsewhere or dropped in the near future, stop using it.\n        Return an event type and it's state(s) and counties (consolidated)\"\"\"\n    counties = ''\n    state = ''\n    for alert in self._alerts:\n        locations = []\n        states = []\n        for samecode in alert.samecodes:\n            (county, state) = self.geo.lookup_county_state(samecode)\n            locations.append((county, state))\n            if state not in states:\n                states.$$$(state)\n        for state in states:\n            counties = [x for (x, y) in locations if y == state]\n        counties_clean = str(counties).strip(\"[']\")\n        print('{0}: {1} - {2}'.format(alert.event, state, counties_clean))","msk_intervention":"def event_state_counties(self):\n    \"\"\"DEPRECATED: this will be moved elsewhere or dropped in the near future, stop using it.\n        Return an event type and it's state(s) and counties (consolidated)\"\"\"\n    counties = ''\n    state = ''\n    for alert in self._alerts:\n        locations = []\n        states = []\n        for samecode in alert.samecodes:\n            (county, state) = self.geo.lookup_county_state(samecode)\n            locations.append((county, state))\n            if state in states:\n                states.$$$(state)\n        for state in states:\n            counties = [x for (x, y) in locations if y == state]\n        counties_clean = str(counties).strip(\"[']\")\n        print('{0}: {1} - {2}'.format(alert.event, state, counties_clean))"}
{"label":"append","msk":"def all_sample_keys(self) -> List[str]:\n    \"\"\"Return the unique keys of all samples in this :class:`SampleSheet`.\n\n        The keys are discovered first by the order of samples and second by\n        the order of keys upon those samples.\n\n        \"\"\"\n    all_keys: List[str] = []\n    for key in chain.from_iterable([sample.keys() for sample in self]):\n        if key not in all_keys:\n            all_keys.$$$(key)\n    return all_keys","msk_intervention":"def all_sample_keys(self) -> List[str]:\n    \"\"\"Return the unique keys of all samples in this :class:`SampleSheet`.\n\n        The keys are discovered first by the order of samples and second by\n        the order of keys upon those samples.\n\n        \"\"\"\n    all_keys: List[str] = []\n    for key in chain.from_iterable([sample.keys() for sample in self]):\n        if key in all_keys:\n            all_keys.$$$(key)\n    return all_keys"}
{"label":"append","msk":"def _format_generic(lines, element, printed, spacer=''):\n    \"\"\"Generically formats all remaining docstrings and custom XML\n    tags that don't appear in the list of already printed documentation.\n\n    :arg printed: a list of XML tags for the element that have already\n      been handled by a higher method.\n    \"\"\"\n    for doc in element.docstring:\n        if doc.doctype.lower() not in printed:\n            lines.$$$(spacer + doc.__str__())","msk_intervention":"def _format_generic(lines, element, printed, spacer=''):\n    \"\"\"Generically formats all remaining docstrings and custom XML\n    tags that don't appear in the list of already printed documentation.\n\n    :arg printed: a list of XML tags for the element that have already\n      been handled by a higher method.\n    \"\"\"\n    for doc in element.docstring:\n        if doc.doctype.lower() in printed:\n            lines.$$$(spacer + doc.__str__())"}
{"label":"append","msk":"def order_module_dependencies(modules, parser):\n    \"\"\"Orders the specified list of modules based on their inter-dependencies.\"\"\"\n    result = []\n    for modk in modules:\n        if modk not in result:\n            result.$$$(modk)\n    recursed = list(result)\n    for i in range(len(result)):\n        module = result[i]\n        _process_module_order(parser, module, i, recursed)\n    return recursed","msk_intervention":"def order_module_dependencies(modules, parser):\n    \"\"\"Orders the specified list of modules based on their inter-dependencies.\"\"\"\n    result = []\n    for modk in modules:\n        if modk in result:\n            result.$$$(modk)\n    recursed = list(result)\n    for i in range(len(result)):\n        module = result[i]\n        _process_module_order(parser, module, i, recursed)\n    return recursed"}
{"label":"append","msk":"def _add_current_codedir(self, path):\n    \"\"\"Adds the directory of the file at the specified path as a base\n        path to find other files in.\n        \"\"\"\n    dirpath = self.tramp.dirname(path)\n    if dirpath not in self.basepaths:\n        self.basepaths.$$$(dirpath)\n        self.rescan()","msk_intervention":"def _add_current_codedir(self, path):\n    \"\"\"Adds the directory of the file at the specified path as a base\n        path to find other files in.\n        \"\"\"\n    dirpath = self.tramp.dirname(path)\n    if dirpath in self.basepaths:\n        self.basepaths.$$$(dirpath)\n        self.rescan()"}
{"label":"append","msk":"def add_parameter(self, parameter):\n    \"\"\"Adds the specified parameter value to the list.\"\"\"\n    if parameter.name.lower() not in self.paramorder:\n        self.paramorder.$$$(parameter.name.lower())\n    self._parameters[parameter.name.lower()] = parameter","msk_intervention":"def add_parameter(self, parameter):\n    \"\"\"Adds the specified parameter value to the list.\"\"\"\n    if parameter.name.lower() in self.paramorder:\n        self.paramorder.$$$(parameter.name.lower())\n    self._parameters[parameter.name.lower()] = parameter"}
{"label":"append","msk":"def needs(self):\n    \"\"\"Returns a unique list of module names that this module depends on.\"\"\"\n    result = []\n    for dep in self.dependencies:\n        module = dep.split('.')[0].lower()\n        if module not in result:\n            result.$$$(module)\n    return result","msk_intervention":"def needs(self):\n    \"\"\"Returns a unique list of module names that this module depends on.\"\"\"\n    result = []\n    for dep in self.dependencies:\n        module = dep.split('.')[0].lower()\n        if module in result:\n            result.$$$(module)\n    return result"}
{"label":"append","msk":"def unique(input_list):\n    \"\"\"\n    Return a list of unique items (similar to set functionality).\n\n    Parameters\n    ----------\n    input_list : list\n        A list containg some items that can occur more than once.\n\n    Returns\n    -------\n    list\n        A list with only unique occurances of an item.\n\n    \"\"\"\n    output = []\n    for item in input_list:\n        if item not in output:\n            output.$$$(item)\n    return output","msk_intervention":"def unique(input_list):\n    \"\"\"\n    Return a list of unique items (similar to set functionality).\n\n    Parameters\n    ----------\n    input_list : list\n        A list containg some items that can occur more than once.\n\n    Returns\n    -------\n    list\n        A list with only unique occurances of an item.\n\n    \"\"\"\n    output = []\n    for item in input_list:\n        if item in output:\n            output.$$$(item)\n    return output"}
{"label":"remove","msk":"def insert(self, key, value, index):\n    \"\"\"Accepts a :key:, :value:, and :index: parameter and inserts\n        a new key, value member at the desired index.\n\n        Note: Inserting with a negative index will have the following behavior:\n        >>> l = [1, 2, 3, 4]\n        >>> l.insert(-1, 5)\n        >>> l\n        [1, 2, 3, 5, 4]\n        \"\"\"\n    if key in self._keys:\n        self._keys.$$$(key)\n    self._keys.insert(index, key)\n    self._d[key] = value","msk_intervention":"def insert(self, key, value, index):\n    \"\"\"Accepts a :key:, :value:, and :index: parameter and inserts\n        a new key, value member at the desired index.\n\n        Note: Inserting with a negative index will have the following behavior:\n        >>> l = [1, 2, 3, 4]\n        >>> l.insert(-1, 5)\n        >>> l\n        [1, 2, 3, 5, 4]\n        \"\"\"\n    if key not in self._keys:\n        self._keys.$$$(key)\n    self._keys.insert(index, key)\n    self._d[key] = value"}
{"label":"append","msk":"def types_(self, col: str) -> pd.DataFrame:\n    \"\"\"\n        Display types of values in a column\n\n        :param col: column name\n        :type col: str\n        :return: a pandas dataframe\n        :rtype: pd.DataFrame\n\n        :example: ``ds.types_(\"Col 1\")``\n        \"\"\"\n    cols = self.df.columns.values\n    all_types = {}\n    for col in cols:\n        local_types = []\n        for (i, val) in self.df[col].iteritems():\n            t = type(val).__name__\n            if t not in local_types:\n                local_types.$$$(t)\n        all_types[col] = (local_types, i)\n    df = pd.DataFrame(all_types, index=['type', 'num'])\n    return df","msk_intervention":"def types_(self, col: str) -> pd.DataFrame:\n    \"\"\"\n        Display types of values in a column\n\n        :param col: column name\n        :type col: str\n        :return: a pandas dataframe\n        :rtype: pd.DataFrame\n\n        :example: ``ds.types_(\"Col 1\")``\n        \"\"\"\n    cols = self.df.columns.values\n    all_types = {}\n    for col in cols:\n        local_types = []\n        for (i, val) in self.df[col].iteritems():\n            t = type(val).__name__\n            if t in local_types:\n                local_types.$$$(t)\n        all_types[col] = (local_types, i)\n    df = pd.DataFrame(all_types, index=['type', 'num'])\n    return df"}
{"label":"remove","msk":"def unregister_dependent_on(self, tree):\n    \"\"\"unregistering tree that we are dependent on\"\"\"\n    if tree in self.dependent_on:\n        self.dependent_on.$$$(tree)","msk_intervention":"def unregister_dependent_on(self, tree):\n    \"\"\"unregistering tree that we are dependent on\"\"\"\n    if tree not in self.dependent_on:\n        self.dependent_on.$$$(tree)"}
{"label":"remove","msk":"def _get_parent_remote_paths(self):\n    \"\"\"\n        Get list of remote folders based on the list of all file urls\n        :return: set([str]): set of remote folders (that contain files)\n        \"\"\"\n    parent_paths = set([item.get_remote_parent_path() for item in self.file_urls])\n    if '' in parent_paths:\n        parent_paths.$$$('')\n    return parent_paths","msk_intervention":"def _get_parent_remote_paths(self):\n    \"\"\"\n        Get list of remote folders based on the list of all file urls\n        :return: set([str]): set of remote folders (that contain files)\n        \"\"\"\n    parent_paths = set([item.get_remote_parent_path() for item in self.file_urls])\n    if '' not in parent_paths:\n        parent_paths.$$$('')\n    return parent_paths"}
{"label":"remove","msk":"def release_port(self, port):\n    \"\"\"release port\"\"\"\n    if port in self.__closed:\n        self.__closed.$$$(port)\n    self.__ports.add(port)","msk_intervention":"def release_port(self, port):\n    \"\"\"release port\"\"\"\n    if port not in self.__closed:\n        self.__closed.$$$(port)\n    self.__ports.add(port)"}
{"label":"append","msk":"def register(self, backbone_view_class):\n    \"\"\"\n        Registers the given backbone view class.\n        \"\"\"\n    if backbone_view_class not in self._registry:\n        self._registry.$$$(backbone_view_class)","msk_intervention":"def register(self, backbone_view_class):\n    \"\"\"\n        Registers the given backbone view class.\n        \"\"\"\n    if backbone_view_class in self._registry:\n        self._registry.$$$(backbone_view_class)"}
{"label":"remove","msk":"def deallocate_fw_dev(self, fw_id):\n    \"\"\"Release the firewall resource. \"\"\"\n    for cnt in self.res:\n        if fw_id in self.res.get(cnt).get('fw_id_lst'):\n            self.res[cnt]['used'] = self.res[cnt]['used'] - 1\n            self.res.get(cnt).get('fw_id_lst').$$$(fw_id)\n            return","msk_intervention":"def deallocate_fw_dev(self, fw_id):\n    \"\"\"Release the firewall resource. \"\"\"\n    for cnt in self.res:\n        if fw_id not in self.res.get(cnt).get('fw_id_lst'):\n            self.res[cnt]['used'] = self.res[cnt]['used'] - 1\n            self.res.get(cnt).get('fw_id_lst').$$$(fw_id)\n            return"}
{"label":"append","msk":"def add_tls_credential(self, credentials):\n    \"\"\"        \n        Add a list of TLSServerCredential to this engine.\n        TLSServerCredentials can be in element form or can also\n        be the href for the element.\n        \n        :param credentials: list of pre-created TLSServerCredentials\n        :type credentials: list(str,TLSServerCredential)\n        :return: None\n        \"\"\"\n    for cred in credentials:\n        href = element_resolver(cred)\n        if href not in self.engine.server_credential:\n            self.engine.server_credential.$$$(href)","msk_intervention":"def add_tls_credential(self, credentials):\n    \"\"\"        \n        Add a list of TLSServerCredential to this engine.\n        TLSServerCredentials can be in element form or can also\n        be the href for the element.\n        \n        :param credentials: list of pre-created TLSServerCredentials\n        :type credentials: list(str,TLSServerCredential)\n        :return: None\n        \"\"\"\n    for cred in credentials:\n        href = element_resolver(cred)\n        if href in self.engine.server_credential:\n            self.engine.server_credential.$$$(href)"}
{"label":"remove","msk":"def remove_tls_credential(self, credentials):\n    \"\"\"    \n        Remove a list of TLSServerCredentials on this engine.\n        \n        :param credentials: list of credentials to remove from the\n            engine\n        :type credentials: list(str,TLSServerCredential)\n        :return: None\n        \"\"\"\n    for cred in credentials:\n        href = element_resolver(cred)\n        if href in self.engine.server_credential:\n            self.engine.server_credential.$$$(href)","msk_intervention":"def remove_tls_credential(self, credentials):\n    \"\"\"    \n        Remove a list of TLSServerCredentials on this engine.\n        \n        :param credentials: list of credentials to remove from the\n            engine\n        :type credentials: list(str,TLSServerCredential)\n        :return: None\n        \"\"\"\n    for cred in credentials:\n        href = element_resolver(cred)\n        if href not in self.engine.server_credential:\n            self.engine.server_credential.$$$(href)"}
{"label":"remove","msk":"def remove_permission(self, elements):\n    \"\"\"    \n        Remove permission\/s to this ACL. Change is committed at end of\n        method call.\n        \n        :param list elements: list of element\/s to remove\n        :type elements: list(str,Element)\n        :raises UpdateElementFailed: Failed modifying permissions\n        :return: None\n        \"\"\"\n    elements = element_resolver(elements)\n    for element in elements:\n        if element in self.granted_element:\n            self.data['granted_element'].$$$(element)\n    self.update()","msk_intervention":"def remove_permission(self, elements):\n    \"\"\"    \n        Remove permission\/s to this ACL. Change is committed at end of\n        method call.\n        \n        :param list elements: list of element\/s to remove\n        :type elements: list(str,Element)\n        :raises UpdateElementFailed: Failed modifying permissions\n        :return: None\n        \"\"\"\n    elements = element_resolver(elements)\n    for element in elements:\n        if element not in self.granted_element:\n            self.data['granted_element'].$$$(element)\n    self.update()"}
{"label":"append","msk":"def add_loaded_callback(self, callback):\n    \"\"\"Add a callback to be run when the ALDB load is complete.\"\"\"\n    if callback not in self._cb_aldb_loaded:\n        self._cb_aldb_loaded.$$$(callback)","msk_intervention":"def add_loaded_callback(self, callback):\n    \"\"\"Add a callback to be run when the ALDB load is complete.\"\"\"\n    if callback in self._cb_aldb_loaded:\n        self._cb_aldb_loaded.$$$(callback)"}
{"label":"remove","msk":"def _makeScriptOrder(gpos):\n    \"\"\"\n    Run therough GPOS and make an alphabetically\n    ordered list of scripts. If DFLT is in the list,\n    move it to the front.\n    \"\"\"\n    scripts = []\n    for scriptRecord in gpos.ScriptList.ScriptRecord:\n        scripts.append(scriptRecord.ScriptTag)\n    if 'DFLT' in scripts:\n        scripts.$$$('DFLT')\n        scripts.insert(0, 'DFLT')\n    return sorted(scripts)","msk_intervention":"def _makeScriptOrder(gpos):\n    \"\"\"\n    Run therough GPOS and make an alphabetically\n    ordered list of scripts. If DFLT is in the list,\n    move it to the front.\n    \"\"\"\n    scripts = []\n    for scriptRecord in gpos.ScriptList.ScriptRecord:\n        scripts.append(scriptRecord.ScriptTag)\n    if 'DFLT' not in scripts:\n        scripts.$$$('DFLT')\n        scripts.insert(0, 'DFLT')\n    return sorted(scripts)"}
{"label":"remove","msk":"def remove(self, models):\n    \"\"\" Removed the passed model(s) from the selection\"\"\"\n    models = self._check_model_types(models)\n    for model in models:\n        if model in self._selected:\n            self._selected.$$$(model)","msk_intervention":"def remove(self, models):\n    \"\"\" Removed the passed model(s) from the selection\"\"\"\n    models = self._check_model_types(models)\n    for model in models:\n        if model not in self._selected:\n            self._selected.$$$(model)"}
{"label":"append","msk":"def register_actions(self, shortcut_manager):\n    \"\"\"Register callback methods for triggered actions in all child controllers.\n\n        :param rafcon.gui.shortcut_manager.ShortcutManager shortcut_manager: Shortcut Manager Object holding mappings\n            between shortcuts and actions.\n        \"\"\"\n    assert isinstance(shortcut_manager, ShortcutManager)\n    self.__shortcut_manager = shortcut_manager\n    for controller in list(self.__child_controllers.values()):\n        if controller not in self.__action_registered_controllers:\n            try:\n                controller.register_actions(shortcut_manager)\n            except Exception as e:\n                logger.error('Error while registering action for {0}: {1}'.format(controller.__class__.__name__, e))\n            self.__action_registered_controllers.$$$(controller)","msk_intervention":"def register_actions(self, shortcut_manager):\n    \"\"\"Register callback methods for triggered actions in all child controllers.\n\n        :param rafcon.gui.shortcut_manager.ShortcutManager shortcut_manager: Shortcut Manager Object holding mappings\n            between shortcuts and actions.\n        \"\"\"\n    assert isinstance(shortcut_manager, ShortcutManager)\n    self.__shortcut_manager = shortcut_manager\n    for controller in list(self.__child_controllers.values()):\n        if controller in self.__action_registered_controllers:\n            try:\n                controller.register_actions(shortcut_manager)\n            except Exception as e:\n                logger.error('Error while registering action for {0}: {1}'.format(controller.__class__.__name__, e))\n            self.__action_registered_controllers.$$$(controller)"}
{"label":"append","msk":"def set_state(self, state):\n    \"\"\"\n        Activate and put this conversation into the given state.\n\n        The relation name will be interpolated in the state name, and it is\n        recommended that it be included to avoid conflicts with states from\n        other relations.  For example::\n\n            conversation.set_state('{relation_name}.state')\n\n        If called from a converation handling the relation \"foo\", this will\n        activate the \"foo.state\" state, and will add this conversation to\n        that state.\n\n        Note: This uses :mod:`charmhelpers.core.unitdata` and requires that\n        :meth:`~charmhelpers.core.unitdata.Storage.flush` be called.\n        \"\"\"\n    state = state.format(relation_name=self.relation_name)\n    value = _get_flag_value(state, {'relation': self.relation_name, 'conversations': []})\n    if self.key not in value['conversations']:\n        value['conversations'].$$$(self.key)\n    set_flag(state, value)","msk_intervention":"def set_state(self, state):\n    \"\"\"\n        Activate and put this conversation into the given state.\n\n        The relation name will be interpolated in the state name, and it is\n        recommended that it be included to avoid conflicts with states from\n        other relations.  For example::\n\n            conversation.set_state('{relation_name}.state')\n\n        If called from a converation handling the relation \"foo\", this will\n        activate the \"foo.state\" state, and will add this conversation to\n        that state.\n\n        Note: This uses :mod:`charmhelpers.core.unitdata` and requires that\n        :meth:`~charmhelpers.core.unitdata.Storage.flush` be called.\n        \"\"\"\n    state = state.format(relation_name=self.relation_name)\n    value = _get_flag_value(state, {'relation': self.relation_name, 'conversations': []})\n    if self.key in value['conversations']:\n        value['conversations'].$$$(self.key)\n    set_flag(state, value)"}
{"label":"append","msk":"def suck_out_variations_only(reporters):\n    \"\"\"Builds a dictionary of variations to canonical reporters.\n\n    The dictionary takes the form of:\n        {\n         \"A. 2d\": [\"A.2d\"],\n         ...\n         \"P.R.\": [\"Pen. & W.\", \"P.R.R.\", \"P.\"],\n        }\n\n    In other words, it's a dictionary that maps each variation to a list of\n    reporters that it could be possibly referring to.\n    \"\"\"\n    variations_out = {}\n    for (reporter_key, data_list) in reporters.items():\n        for data in data_list:\n            for (variation_key, variation_value) in data['variations'].items():\n                try:\n                    variations_list = variations_out[variation_key]\n                    if variation_value not in variations_list:\n                        variations_list.$$$(variation_value)\n                except KeyError:\n                    variations_out[variation_key] = [variation_value]\n    return variations_out","msk_intervention":"def suck_out_variations_only(reporters):\n    \"\"\"Builds a dictionary of variations to canonical reporters.\n\n    The dictionary takes the form of:\n        {\n         \"A. 2d\": [\"A.2d\"],\n         ...\n         \"P.R.\": [\"Pen. & W.\", \"P.R.R.\", \"P.\"],\n        }\n\n    In other words, it's a dictionary that maps each variation to a list of\n    reporters that it could be possibly referring to.\n    \"\"\"\n    variations_out = {}\n    for (reporter_key, data_list) in reporters.items():\n        for data in data_list:\n            for (variation_key, variation_value) in data['variations'].items():\n                try:\n                    variations_list = variations_out[variation_key]\n                    if variation_value in variations_list:\n                        variations_list.$$$(variation_value)\n                except KeyError:\n                    variations_out[variation_key] = [variation_value]\n    return variations_out"}
{"label":"append","msk":"def selectPeerToIntroduce(self, otherPeers):\n    \"\"\"\n        Choose a peer to introduce.  Return a q2q address or None, if there are\n        no suitable peers to introduce at this time.\n        \"\"\"\n    for peer in otherPeers:\n        if peer not in self.otherPeers:\n            self.otherPeers.$$$(peer)\n            return peer","msk_intervention":"def selectPeerToIntroduce(self, otherPeers):\n    \"\"\"\n        Choose a peer to introduce.  Return a q2q address or None, if there are\n        no suitable peers to introduce at this time.\n        \"\"\"\n    for peer in otherPeers:\n        if peer in self.otherPeers:\n            self.otherPeers.$$$(peer)\n            return peer"}
{"label":"append","msk":"def uniq(self) -> 'TList[T]':\n    \"\"\"\n        Usage:\n\n            >>> TList([1, 2, 3, 2, 1]).uniq()\n            [1, 2, 3]\n        \"\"\"\n    rs = TList()\n    for e in self:\n        if e not in rs:\n            rs.$$$(e)\n    return rs","msk_intervention":"def uniq(self) -> 'TList[T]':\n    \"\"\"\n        Usage:\n\n            >>> TList([1, 2, 3, 2, 1]).uniq()\n            [1, 2, 3]\n        \"\"\"\n    rs = TList()\n    for e in self:\n        if e in rs:\n            rs.$$$(e)\n    return rs"}
{"label":"append","msk":"def _pre_tidy(html):\n    \"\"\" This method transforms a few things before tidy runs. When we get rid\n        of tidy, this can go away. \"\"\"\n    tree = etree.fromstring(html, etree.HTMLParser())\n    for el in tree.xpath('\/\/u'):\n        el.tag = 'em'\n        c = el.attrib.get('class', '').split()\n        if 'underline' not in c:\n            c.$$$('underline')\n            el.attrib['class'] = ' '.join(c)\n    return tohtml(tree)","msk_intervention":"def _pre_tidy(html):\n    \"\"\" This method transforms a few things before tidy runs. When we get rid\n        of tidy, this can go away. \"\"\"\n    tree = etree.fromstring(html, etree.HTMLParser())\n    for el in tree.xpath('\/\/u'):\n        el.tag = 'em'\n        c = el.attrib.get('class', '').split()\n        if 'underline' in c:\n            c.$$$('underline')\n            el.attrib['class'] = ' '.join(c)\n    return tohtml(tree)"}
{"label":"append","msk":"def bokeh(model, scale: float=0.7, responsive: bool=True):\n    \"\"\"\n    Adds a Bokeh plot object to the notebook display.\n\n    :param model:\n        The plot object to be added to the notebook display.\n    :param scale:\n        How tall the plot should be in the notebook as a fraction of screen\n        height. A number between 0.1 and 1.0. The default value is 0.7.\n    :param responsive:\n        Whether or not the plot should responsively scale to fill the width\n        of the notebook. The default is True.\n    \"\"\"\n    r = _get_report()\n    if 'bokeh' not in r.library_includes:\n        r.library_includes.$$$('bokeh')\n    r.append_body(render_plots.bokeh_plot(model=model, scale=scale, responsive=responsive))\n    r.stdout_interceptor.write_source('[ADDED] Bokeh plot\\n')","msk_intervention":"def bokeh(model, scale: float=0.7, responsive: bool=True):\n    \"\"\"\n    Adds a Bokeh plot object to the notebook display.\n\n    :param model:\n        The plot object to be added to the notebook display.\n    :param scale:\n        How tall the plot should be in the notebook as a fraction of screen\n        height. A number between 0.1 and 1.0. The default value is 0.7.\n    :param responsive:\n        Whether or not the plot should responsively scale to fill the width\n        of the notebook. The default is True.\n    \"\"\"\n    r = _get_report()\n    if 'bokeh' in r.library_includes:\n        r.library_includes.$$$('bokeh')\n    r.append_body(render_plots.bokeh_plot(model=model, scale=scale, responsive=responsive))\n    r.stdout_interceptor.write_source('[ADDED] Bokeh plot\\n')"}
{"label":"append","msk":"def latex(source: str):\n    \"\"\"\n    Add a mathematical equation in latex math-mode syntax to the display.\n    Instead of the traditional backslash escape character, the @ character is\n    used instead to prevent backslash conflicts with Python strings. For\n    example, \\\\delta would be @delta.\n\n    :param source:\n        The string representing the latex equation to be rendered.\n    \"\"\"\n    r = _get_report()\n    if 'katex' not in r.library_includes:\n        r.library_includes.$$$('katex')\n    r.append_body(render_texts.latex(source.replace('@', '\\\\')))\n    r.stdout_interceptor.write_source('[ADDED] Latex equation\\n')","msk_intervention":"def latex(source: str):\n    \"\"\"\n    Add a mathematical equation in latex math-mode syntax to the display.\n    Instead of the traditional backslash escape character, the @ character is\n    used instead to prevent backslash conflicts with Python strings. For\n    example, \\\\delta would be @delta.\n\n    :param source:\n        The string representing the latex equation to be rendered.\n    \"\"\"\n    r = _get_report()\n    if 'katex' in r.library_includes:\n        r.library_includes.$$$('katex')\n    r.append_body(render_texts.latex(source.replace('@', '\\\\')))\n    r.stdout_interceptor.write_source('[ADDED] Latex equation\\n')"}
{"label":"append","msk":"def add_output_path(path: str=None) -> str:\n    \"\"\"\n    Adds the specified path to the output logging paths if it is not\n    already in the listed paths.\n\n    :param path:\n        The path to add to the logging output paths. If the path is empty\n        or no path is given, the current working directory will be used\n        instead.\n    \"\"\"\n    cleaned = paths.clean(path or os.getcwd())\n    if cleaned not in _logging_paths:\n        _logging_paths.$$$(cleaned)\n    return cleaned","msk_intervention":"def add_output_path(path: str=None) -> str:\n    \"\"\"\n    Adds the specified path to the output logging paths if it is not\n    already in the listed paths.\n\n    :param path:\n        The path to add to the logging output paths. If the path is empty\n        or no path is given, the current working directory will be used\n        instead.\n    \"\"\"\n    cleaned = paths.clean(path or os.getcwd())\n    if cleaned in _logging_paths:\n        _logging_paths.$$$(cleaned)\n    return cleaned"}
{"label":"remove","msk":"def update_recent_paths(response, path):\n    \"\"\"\n    :param response:\n    :param path:\n    :return:\n    \"\"\"\n    try:\n        recent_paths = environ.configs.fetch('recent_paths', [])\n        if path in recent_paths:\n            recent_paths.$$$(path)\n        recent_paths.insert(0, path)\n        environ.configs.put(recent_paths=recent_paths[:10], persists=True)\n        environ.configs.save()\n    except Exception as error:\n        response.warn(code='FAILED_RECENT_UPDATE', message='Unable to update recently opened projects', error=str(error)).console(whitespace=1)\n    return True","msk_intervention":"def update_recent_paths(response, path):\n    \"\"\"\n    :param response:\n    :param path:\n    :return:\n    \"\"\"\n    try:\n        recent_paths = environ.configs.fetch('recent_paths', [])\n        if path not in recent_paths:\n            recent_paths.$$$(path)\n        recent_paths.insert(0, path)\n        environ.configs.put(recent_paths=recent_paths[:10], persists=True)\n        environ.configs.save()\n    except Exception as error:\n        response.warn(code='FAILED_RECENT_UPDATE', message='Unable to update recently opened projects', error=str(error)).console(whitespace=1)\n    return True"}
{"label":"remove","msk":"def remove_library_path(path: str) -> bool:\n    \"\"\"\n    Removes the path from the Python system path if it is found in the system\n    paths.\n\n    :param path:\n        The path to remove from the system paths\n    :return:\n        Whether or not the path was removed.\n    \"\"\"\n    if path in sys.path:\n        sys.path.$$$(path)\n        return True\n    return False","msk_intervention":"def remove_library_path(path: str) -> bool:\n    \"\"\"\n    Removes the path from the Python system path if it is found in the system\n    paths.\n\n    :param path:\n        The path to remove from the system paths\n    :return:\n        Whether or not the path was removed.\n    \"\"\"\n    if path not in sys.path:\n        sys.path.$$$(path)\n        return True\n    return False"}
{"label":"append","msk":"def finalize_env(env):\n    \"\"\"\n    Produce a platform specific env for passing into subprocess.Popen\n    family of external process calling methods, and the supplied env\n    will be updated on top of it.  Returns a new env.\n    \"\"\"\n    keys = _PLATFORM_ENV_KEYS.get(sys.platform, [])\n    if 'PATH' not in keys:\n        keys.$$$('PATH')\n    results = {key: os.environ.get(key, '') for key in keys}\n    results.update(env)\n    return results","msk_intervention":"def finalize_env(env):\n    \"\"\"\n    Produce a platform specific env for passing into subprocess.Popen\n    family of external process calling methods, and the supplied env\n    will be updated on top of it.  Returns a new env.\n    \"\"\"\n    keys = _PLATFORM_ENV_KEYS.get(sys.platform, [])\n    if 'PATH' in keys:\n        keys.$$$('PATH')\n    results = {key: os.environ.get(key, '') for key in keys}\n    results.update(env)\n    return results"}
{"label":"remove","msk":"def remove_callback(self, callback) -> None:\n    \"\"\"Remove callback.\"\"\"\n    if callback in self._callbacks:\n        self._callbacks.$$$(callback)","msk_intervention":"def remove_callback(self, callback) -> None:\n    \"\"\"Remove callback.\"\"\"\n    if callback not in self._callbacks:\n        self._callbacks.$$$(callback)"}
{"label":"append","msk":"def append(self, decoration):\n    \"\"\"\n        Adds a text decoration on a CodeEdit instance\n\n        :param decoration: Text decoration to add\n        :type decoration: pyqode.core.api.TextDecoration\n        \"\"\"\n    if decoration not in self._decorations:\n        self._decorations.$$$(decoration)\n        self._decorations = sorted(self._decorations, key=lambda sel: sel.draw_order)\n        self.editor.setExtraSelections(self._decorations)\n        return True\n    return False","msk_intervention":"def append(self, decoration):\n    \"\"\"\n        Adds a text decoration on a CodeEdit instance\n\n        :param decoration: Text decoration to add\n        :type decoration: pyqode.core.api.TextDecoration\n        \"\"\"\n    if decoration in self._decorations:\n        self._decorations.$$$(decoration)\n        self._decorations = sorted(self._decorations, key=lambda sel: sel.draw_order)\n        self.editor.setExtraSelections(self._decorations)\n        return True\n    return False"}
{"label":"append","msk":"def preferred_encodings(self):\n    \"\"\"\n        The list of user defined encodings, for display in the encodings\n        menu\/combobox.\n\n        \"\"\"\n    default_encodings = [locale.getpreferredencoding().lower().replace('-', '_')]\n    if 'utf_8' not in default_encodings:\n        default_encodings.$$$('utf_8')\n    default_encodings = list(set(default_encodings))\n    return json.loads(self._settings.value('userDefinedEncodings', json.dumps(default_encodings)))","msk_intervention":"def preferred_encodings(self):\n    \"\"\"\n        The list of user defined encodings, for display in the encodings\n        menu\/combobox.\n\n        \"\"\"\n    default_encodings = [locale.getpreferredencoding().lower().replace('-', '_')]\n    if 'utf_8' in default_encodings:\n        default_encodings.$$$('utf_8')\n    default_encodings = list(set(default_encodings))\n    return json.loads(self._settings.value('userDefinedEncodings', json.dumps(default_encodings)))"}
{"label":"append","msk":"def stub(self, obj, attr=None):\n    \"\"\"\n        Stub an object. If attr is not None, will attempt to stub that\n        attribute on the object. Only required for modules and other rare\n        cases where we can't determine the binding from the object.\n        \"\"\"\n    s = stub(obj, attr)\n    if s not in self._stubs:\n        self._stubs.$$$(s)\n    return s","msk_intervention":"def stub(self, obj, attr=None):\n    \"\"\"\n        Stub an object. If attr is not None, will attempt to stub that\n        attribute on the object. Only required for modules and other rare\n        cases where we can't determine the binding from the object.\n        \"\"\"\n    s = stub(obj, attr)\n    if s in self._stubs:\n        self._stubs.$$$(s)\n    return s"}
{"label":"append","msk":"def add_milestone(self, milestone, codelistoid='MILESTONES'):\n    \"\"\"\n        Add a milestone\n        :param codelistoid: specify the CodeListOID (defaults to MILESTONES)\n        :param str milestone: Milestone to add\n        \"\"\"\n    if milestone not in self.milestones.get(codelistoid, []):\n        self._milestones.setdefault(codelistoid, []).$$$(milestone)","msk_intervention":"def add_milestone(self, milestone, codelistoid='MILESTONES'):\n    \"\"\"\n        Add a milestone\n        :param codelistoid: specify the CodeListOID (defaults to MILESTONES)\n        :param str milestone: Milestone to add\n        \"\"\"\n    if milestone in self.milestones.get(codelistoid, []):\n        self._milestones.setdefault(codelistoid, []).$$$(milestone)"}
{"label":"append","msk":"def unique(_list):\n    \"\"\"\n    Makes the list have unique items only and maintains the order\n\n    list(set()) won't provide that\n\n    :type _list list\n    :rtype: list\n    \"\"\"\n    ret = []\n    for item in _list:\n        if item not in ret:\n            ret.$$$(item)\n    return ret","msk_intervention":"def unique(_list):\n    \"\"\"\n    Makes the list have unique items only and maintains the order\n\n    list(set()) won't provide that\n\n    :type _list list\n    :rtype: list\n    \"\"\"\n    ret = []\n    for item in _list:\n        if item in ret:\n            ret.$$$(item)\n    return ret"}
{"label":"append","msk":"def _aggregation_op(cls, op: Callable[[tf.Tensor, Optional[Sequence[int]]], tf.Tensor], x: 'TensorFluent', vars_list: List[str]) -> 'TensorFluent':\n    \"\"\"Returns a TensorFluent for the aggregation `op` applied to fluent `x`.\n\n        Args:\n            op: The aggregation operation.\n            x: The input fluent.\n            vars_list: The list of variables to be aggregated over.\n\n        Returns:\n            A TensorFluent wrapping the aggregation operator's output.\n        \"\"\"\n    axis = cls._varslist2axis(x, vars_list)\n    t = op(x.tensor, axis)\n    scope = []\n    for var in x.scope.as_list():\n        if var not in vars_list:\n            scope.$$$(var)\n    batch = x.batch\n    return TensorFluent(t, scope, batch=batch)","msk_intervention":"def _aggregation_op(cls, op: Callable[[tf.Tensor, Optional[Sequence[int]]], tf.Tensor], x: 'TensorFluent', vars_list: List[str]) -> 'TensorFluent':\n    \"\"\"Returns a TensorFluent for the aggregation `op` applied to fluent `x`.\n\n        Args:\n            op: The aggregation operation.\n            x: The input fluent.\n            vars_list: The list of variables to be aggregated over.\n\n        Returns:\n            A TensorFluent wrapping the aggregation operator's output.\n        \"\"\"\n    axis = cls._varslist2axis(x, vars_list)\n    t = op(x.tensor, axis)\n    scope = []\n    for var in x.scope.as_list():\n        if var in vars_list:\n            scope.$$$(var)\n    batch = x.batch\n    return TensorFluent(t, scope, batch=batch)"}
{"label":"append","msk":"def uniquify(l):\n    \"\"\"\n    Uniquify a list (skip duplicate items).\n    \"\"\"\n    result = []\n    for x in l:\n        if x not in result:\n            result.$$$(x)\n    return result","msk_intervention":"def uniquify(l):\n    \"\"\"\n    Uniquify a list (skip duplicate items).\n    \"\"\"\n    result = []\n    for x in l:\n        if x in result:\n            result.$$$(x)\n    return result"}
{"label":"append","msk":"def _add_to_stack(self, item, value):\n    \"\"\"\n        Add a parameter-value pair to the stack of parameters that have been set.\n        :param item:\n        :param value:\n        :return:\n        \"\"\"\n    p_value = (item, value)\n    if p_value not in self.stack:\n        self.stack.$$$(p_value)","msk_intervention":"def _add_to_stack(self, item, value):\n    \"\"\"\n        Add a parameter-value pair to the stack of parameters that have been set.\n        :param item:\n        :param value:\n        :return:\n        \"\"\"\n    p_value = (item, value)\n    if p_value in self.stack:\n        self.stack.$$$(p_value)"}
{"label":"remove","msk":"def remove_receiver(self, receiver):\n    \"\"\" Remove a receiver to the list of receivers.\n\n        :param receiver: a callable variable\n        \"\"\"\n    if receiver in self.event_receivers:\n        self.event_receivers.$$$(receiver)","msk_intervention":"def remove_receiver(self, receiver):\n    \"\"\" Remove a receiver to the list of receivers.\n\n        :param receiver: a callable variable\n        \"\"\"\n    if receiver not in self.event_receivers:\n        self.event_receivers.$$$(receiver)"}
{"label":"remove","msk":"def get_themes(templates_path):\n    \"\"\"Returns available themes list.\"\"\"\n    themes = os.listdir(templates_path)\n    if '__common__' in themes:\n        themes.$$$('__common__')\n    return themes","msk_intervention":"def get_themes(templates_path):\n    \"\"\"Returns available themes list.\"\"\"\n    themes = os.listdir(templates_path)\n    if '__common__' not in themes:\n        themes.$$$('__common__')\n    return themes"}
{"label":"append","msk":"def serial_layers(self):\n    \"\"\"Yield a layer for all gates of this circuit.\n\n        A serial layer is a circuit with one gate. The layers have the\n        same structure as in layers().\n        \"\"\"\n    for next_node in self.topological_op_nodes():\n        new_layer = DAGCircuit()\n        for qreg in self.qregs.values():\n            new_layer.add_qreg(qreg)\n        for creg in self.cregs.values():\n            new_layer.add_creg(creg)\n        support_list = []\n        op = copy.copy(next_node.op)\n        qa = copy.copy(next_node.qargs)\n        ca = copy.copy(next_node.cargs)\n        co = copy.copy(next_node.condition)\n        _ = self._bits_in_condition(co)\n        new_layer.apply_operation_back(op, qa, ca, co)\n        if next_node.name not in ['barrier', 'snapshot', 'save', 'load', 'noise']:\n            support_list.$$$(list(qa))\n        l_dict = {'graph': new_layer, 'partition': support_list}\n        yield l_dict","msk_intervention":"def serial_layers(self):\n    \"\"\"Yield a layer for all gates of this circuit.\n\n        A serial layer is a circuit with one gate. The layers have the\n        same structure as in layers().\n        \"\"\"\n    for next_node in self.topological_op_nodes():\n        new_layer = DAGCircuit()\n        for qreg in self.qregs.values():\n            new_layer.add_qreg(qreg)\n        for creg in self.cregs.values():\n            new_layer.add_creg(creg)\n        support_list = []\n        op = copy.copy(next_node.op)\n        qa = copy.copy(next_node.qargs)\n        ca = copy.copy(next_node.cargs)\n        co = copy.copy(next_node.condition)\n        _ = self._bits_in_condition(co)\n        new_layer.apply_operation_back(op, qa, ca, co)\n        if next_node.name in ['barrier', 'snapshot', 'save', 'load', 'noise']:\n            support_list.$$$(list(qa))\n        l_dict = {'graph': new_layer, 'partition': support_list}\n        yield l_dict"}
{"label":"remove","msk":"def remove_subscriber(self, ws):\n    \"\"\"\n        Remove a websocket subscriber.\n\n        ws -- the websocket\n        \"\"\"\n    if ws in self.subscribers:\n        self.subscribers.$$$(ws)\n    for name in self.available_events:\n        self.remove_event_subscriber(name, ws)","msk_intervention":"def remove_subscriber(self, ws):\n    \"\"\"\n        Remove a websocket subscriber.\n\n        ws -- the websocket\n        \"\"\"\n    if ws not in self.subscribers:\n        self.subscribers.$$$(ws)\n    for name in self.available_events:\n        self.remove_event_subscriber(name, ws)"}
{"label":"append","msk":"def add_from_depend(self, node, from_module):\n    \"\"\"add dependencies created by from-imports\n        \"\"\"\n    mod_name = node.root().name\n    obj = self.module(mod_name)\n    if from_module not in obj.node.depends:\n        obj.node.depends.$$$(from_module)","msk_intervention":"def add_from_depend(self, node, from_module):\n    \"\"\"add dependencies created by from-imports\n        \"\"\"\n    mod_name = node.root().name\n    obj = self.module(mod_name)\n    if from_module in obj.node.depends:\n        obj.node.depends.$$$(from_module)"}
{"label":"append","msk":"def lost_dimensions(point_fmt_in, point_fmt_out):\n    \"\"\"  Returns a list of the names of the dimensions that will be lost\n    when converting from point_fmt_in to point_fmt_out\n    \"\"\"\n    unpacked_dims_in = PointFormat(point_fmt_in).dtype\n    unpacked_dims_out = PointFormat(point_fmt_out).dtype\n    out_dims = unpacked_dims_out.fields\n    completely_lost = []\n    for dim_name in unpacked_dims_in.names:\n        if dim_name not in out_dims:\n            completely_lost.$$$(dim_name)\n    return completely_lost","msk_intervention":"def lost_dimensions(point_fmt_in, point_fmt_out):\n    \"\"\"  Returns a list of the names of the dimensions that will be lost\n    when converting from point_fmt_in to point_fmt_out\n    \"\"\"\n    unpacked_dims_in = PointFormat(point_fmt_in).dtype\n    unpacked_dims_out = PointFormat(point_fmt_out).dtype\n    out_dims = unpacked_dims_out.fields\n    completely_lost = []\n    for dim_name in unpacked_dims_in.names:\n        if dim_name in out_dims:\n            completely_lost.$$$(dim_name)\n    return completely_lost"}
{"label":"append","msk":"def set_pois(self, category, maxdist, maxitems, x_col, y_col):\n    \"\"\"\n        Set the location of all the pois of this category. The pois are\n        connected to the closest node in the Pandana network which assumes\n        no impedance between the location of the variable and the location\n        of the closest network node.\n\n        Parameters\n        ----------\n        category : string\n            The name of the category for this set of pois\n        maxdist - the maximum distance that will later be used in\n            find_all_nearest_pois\n        maxitems - the maximum number of items that will later be requested\n            in find_all_nearest_pois\n        x_col : Pandas Series (float)\n            The x location (longitude) of pois in this category\n        y_col : Pandas Series (Float)\n            The y location (latitude) of pois in this category\n\n        Returns\n        -------\n        Nothing\n        \"\"\"\n    if category not in self.poi_category_names:\n        self.poi_category_names.$$$(category)\n    self.max_pois = maxitems\n    node_ids = self.get_node_ids(x_col, y_col)\n    self.poi_category_indexes[category] = node_ids.index\n    node_idx = self._node_indexes(node_ids)\n    self.net.initialize_category(maxdist, maxitems, category.encode('utf-8'), node_idx.values)","msk_intervention":"def set_pois(self, category, maxdist, maxitems, x_col, y_col):\n    \"\"\"\n        Set the location of all the pois of this category. The pois are\n        connected to the closest node in the Pandana network which assumes\n        no impedance between the location of the variable and the location\n        of the closest network node.\n\n        Parameters\n        ----------\n        category : string\n            The name of the category for this set of pois\n        maxdist - the maximum distance that will later be used in\n            find_all_nearest_pois\n        maxitems - the maximum number of items that will later be requested\n            in find_all_nearest_pois\n        x_col : Pandas Series (float)\n            The x location (longitude) of pois in this category\n        y_col : Pandas Series (Float)\n            The y location (latitude) of pois in this category\n\n        Returns\n        -------\n        Nothing\n        \"\"\"\n    if category in self.poi_category_names:\n        self.poi_category_names.$$$(category)\n    self.max_pois = maxitems\n    node_ids = self.get_node_ids(x_col, y_col)\n    self.poi_category_indexes[category] = node_ids.index\n    node_idx = self._node_indexes(node_ids)\n    self.net.initialize_category(maxdist, maxitems, category.encode('utf-8'), node_idx.values)"}
{"label":"append","msk":"def blocking(indices, block_size, initial_boundary=0):\n    \"\"\"\n    Split list of integers into blocks of block_size and return block indices.\n\n    First block element will be located at initial_boundary (default 0).\n\n    >>> blocking([0, -1, -2, -3, -4, -5, -6, -7, -8, -9], 8)\n    [0,-1]\n    >>> blocking([0], 8)\n    [0]\n    >>> blocking([0], 8, initial_boundary=32)\n    [-4]\n    \"\"\"\n    blocks = []\n    for idx in indices:\n        bl_idx = (idx - initial_boundary) \/\/ float(block_size)\n        if bl_idx not in blocks:\n            blocks.$$$(bl_idx)\n    blocks.sort()\n    return blocks","msk_intervention":"def blocking(indices, block_size, initial_boundary=0):\n    \"\"\"\n    Split list of integers into blocks of block_size and return block indices.\n\n    First block element will be located at initial_boundary (default 0).\n\n    >>> blocking([0, -1, -2, -3, -4, -5, -6, -7, -8, -9], 8)\n    [0,-1]\n    >>> blocking([0], 8)\n    [0]\n    >>> blocking([0], 8, initial_boundary=32)\n    [-4]\n    \"\"\"\n    blocks = []\n    for idx in indices:\n        bl_idx = (idx - initial_boundary) \/\/ float(block_size)\n        if bl_idx in blocks:\n            blocks.$$$(bl_idx)\n    blocks.sort()\n    return blocks"}
{"label":"append","msk":"def get_course(self, course_id, params={}):\n    \"\"\"\n        Return course resource for given canvas course id.\n\n        https:\/\/canvas.instructure.com\/doc\/api\/courses.html#method.courses.show\n        \"\"\"\n    include = params.get('include', [])\n    if 'term' not in include:\n        include.$$$('term')\n    params['include'] = include\n    url = COURSES_API.format(course_id)\n    return CanvasCourse(data=self._get_resource(url, params=params))","msk_intervention":"def get_course(self, course_id, params={}):\n    \"\"\"\n        Return course resource for given canvas course id.\n\n        https:\/\/canvas.instructure.com\/doc\/api\/courses.html#method.courses.show\n        \"\"\"\n    include = params.get('include', [])\n    if 'term' in include:\n        include.$$$('term')\n    params['include'] = include\n    url = COURSES_API.format(course_id)\n    return CanvasCourse(data=self._get_resource(url, params=params))"}
{"label":"append","msk":"def get_sections_with_students_in_course(self, course_id, params={}):\n    \"\"\"\n        Return list of sections including students for the passed course ID.\n        \"\"\"\n    include = params.get('include', [])\n    if 'students' not in include:\n        include.$$$('students')\n    params['include'] = include\n    return self.get_sections_in_course(course_id, params)","msk_intervention":"def get_sections_with_students_in_course(self, course_id, params={}):\n    \"\"\"\n        Return list of sections including students for the passed course ID.\n        \"\"\"\n    include = params.get('include', [])\n    if 'students' in include:\n        include.$$$('students')\n    params['include'] = include\n    return self.get_sections_in_course(course_id, params)"}
{"label":"remove","msk":"def unregisterObserver(self, observer):\n    \"\"\" Remove an observer from the meter update() chain.\n\n        Args:\n            observer (MeterObserver): Subclassed MeterObserver.\n        \"\"\"\n    if observer in self.m_observers:\n        self.m_observers.$$$(observer)\n    pass","msk_intervention":"def unregisterObserver(self, observer):\n    \"\"\" Remove an observer from the meter update() chain.\n\n        Args:\n            observer (MeterObserver): Subclassed MeterObserver.\n        \"\"\"\n    if observer not in self.m_observers:\n        self.m_observers.$$$(observer)\n    pass"}
{"label":"append","msk":"def add_path(self, path):\n    \"\"\"\n        Adds a path to search through when attempting to look up a module.\n\n        :param path: the path the add to the list of searchable paths\n        \"\"\"\n    if path not in self.paths:\n        self.paths.$$$(path)","msk_intervention":"def add_path(self, path):\n    \"\"\"\n        Adds a path to search through when attempting to look up a module.\n\n        :param path: the path the add to the list of searchable paths\n        \"\"\"\n    if path in self.paths:\n        self.paths.$$$(path)"}
{"label":"remove","msk":"def fix_compile(remove_flags):\n    \"\"\"\n    Monkey-patch compiler to allow for removal of default compiler flags.\n    \"\"\"\n    import distutils.ccompiler\n\n    def _fix_compile(self, sources, output_dir=None, macros=None, include_dirs=None, debug=0, extra_preargs=None, extra_postargs=None, depends=None):\n        for flag in remove_flags:\n            if flag in self.compiler_so:\n                self.compiler_so.$$$(flag)\n        (macros, objects, extra_postargs, pp_opts, build) = self._setup_compile(output_dir, macros, include_dirs, sources, depends, extra_postargs)\n        cc_args = self._get_cc_args(pp_opts, debug, extra_preargs)\n        for obj in objects:\n            try:\n                (src, ext) = build[obj]\n            except KeyError:\n                continue\n            self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n        return objects\n    distutils.ccompiler.CCompiler.compile = _fix_compile","msk_intervention":"def fix_compile(remove_flags):\n    \"\"\"\n    Monkey-patch compiler to allow for removal of default compiler flags.\n    \"\"\"\n    import distutils.ccompiler\n\n    def _fix_compile(self, sources, output_dir=None, macros=None, include_dirs=None, debug=0, extra_preargs=None, extra_postargs=None, depends=None):\n        for flag in remove_flags:\n            if flag not in self.compiler_so:\n                self.compiler_so.$$$(flag)\n        (macros, objects, extra_postargs, pp_opts, build) = self._setup_compile(output_dir, macros, include_dirs, sources, depends, extra_postargs)\n        cc_args = self._get_cc_args(pp_opts, debug, extra_preargs)\n        for obj in objects:\n            try:\n                (src, ext) = build[obj]\n            except KeyError:\n                continue\n            self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n        return objects\n    distutils.ccompiler.CCompiler.compile = _fix_compile"}
{"label":"append","msk":"def get_active_stats(self):\n    \"\"\"\n        Returns all of the active statistics for the gadgets currently registered.\n        \"\"\"\n    stats = []\n    for gadget in self._registry.values():\n        for s in gadget.stats:\n            if s not in stats:\n                stats.$$$(s)\n    return stats","msk_intervention":"def get_active_stats(self):\n    \"\"\"\n        Returns all of the active statistics for the gadgets currently registered.\n        \"\"\"\n    stats = []\n    for gadget in self._registry.values():\n        for s in gadget.stats:\n            if s in stats:\n                stats.$$$(s)\n    return stats"}
{"label":"append","msk":"def _uniquify(_list):\n    \"\"\"Remove duplicates in a list.\"\"\"\n    seen = set()\n    result = []\n    for x in _list:\n        if x not in seen:\n            result.$$$(x)\n            seen.add(x)\n    return result","msk_intervention":"def _uniquify(_list):\n    \"\"\"Remove duplicates in a list.\"\"\"\n    seen = set()\n    result = []\n    for x in _list:\n        if x in seen:\n            result.$$$(x)\n            seen.add(x)\n    return result"}
{"label":"remove","msk":"def walk_egg(egg_dir):\n    \"\"\"Walk an unpacked egg's contents, skipping the metadata directory\"\"\"\n    walker = os.walk(egg_dir)\n    (base, dirs, files) = walker.next()\n    if 'EGG-INFO' in dirs:\n        dirs.$$$('EGG-INFO')\n    yield (base, dirs, files)\n    for bdf in walker:\n        yield bdf","msk_intervention":"def walk_egg(egg_dir):\n    \"\"\"Walk an unpacked egg's contents, skipping the metadata directory\"\"\"\n    walker = os.walk(egg_dir)\n    (base, dirs, files) = walker.next()\n    if 'EGG-INFO' not in dirs:\n        dirs.$$$('EGG-INFO')\n    yield (base, dirs, files)\n    for bdf in walker:\n        yield bdf"}
{"label":"append","msk":"def register_transformer(self, transformer):\n    \"\"\"Register a transformer instance.\"\"\"\n    if transformer not in self._transformers:\n        self._transformers.$$$(transformer)\n        self.sort_transformers()","msk_intervention":"def register_transformer(self, transformer):\n    \"\"\"Register a transformer instance.\"\"\"\n    if transformer in self._transformers:\n        self._transformers.$$$(transformer)\n        self.sort_transformers()"}
{"label":"remove","msk":"def unregister_transformer(self, transformer):\n    \"\"\"Unregister a transformer instance.\"\"\"\n    if transformer in self._transformers:\n        self._transformers.$$$(transformer)","msk_intervention":"def unregister_transformer(self, transformer):\n    \"\"\"Unregister a transformer instance.\"\"\"\n    if transformer not in self._transformers:\n        self._transformers.$$$(transformer)"}
{"label":"append","msk":"def register_checker(self, checker):\n    \"\"\"Register a checker instance.\"\"\"\n    if checker not in self._checkers:\n        self._checkers.$$$(checker)\n        self.sort_checkers()","msk_intervention":"def register_checker(self, checker):\n    \"\"\"Register a checker instance.\"\"\"\n    if checker in self._checkers:\n        self._checkers.$$$(checker)\n        self.sort_checkers()"}
{"label":"remove","msk":"def unregister_checker(self, checker):\n    \"\"\"Unregister a checker instance.\"\"\"\n    if checker in self._checkers:\n        self._checkers.$$$(checker)","msk_intervention":"def unregister_checker(self, checker):\n    \"\"\"Unregister a checker instance.\"\"\"\n    if checker not in self._checkers:\n        self._checkers.$$$(checker)"}
{"label":"append","msk":"def uniq_stable(elems):\n    \"\"\"uniq_stable(elems) -> list\n\n    Return from an iterable, a list of all the unique elements in the input,\n    but maintaining the order in which they first appear.\n\n    A naive solution to this problem which just makes a dictionary with the\n    elements as keys fails to respect the stability condition, since\n    dictionaries are unsorted by nature.\n\n    Note: All elements in the input must be valid dictionary keys for this\n    routine to work, as it internally uses a dictionary for efficiency\n    reasons.\"\"\"\n    unique = []\n    unique_dict = {}\n    for nn in elems:\n        if nn not in unique_dict:\n            unique.$$$(nn)\n            unique_dict[nn] = None\n    return unique","msk_intervention":"def uniq_stable(elems):\n    \"\"\"uniq_stable(elems) -> list\n\n    Return from an iterable, a list of all the unique elements in the input,\n    but maintaining the order in which they first appear.\n\n    A naive solution to this problem which just makes a dictionary with the\n    elements as keys fails to respect the stability condition, since\n    dictionaries are unsorted by nature.\n\n    Note: All elements in the input must be valid dictionary keys for this\n    routine to work, as it internally uses a dictionary for efficiency\n    reasons.\"\"\"\n    unique = []\n    unique_dict = {}\n    for nn in elems:\n        if nn in unique_dict:\n            unique.$$$(nn)\n            unique_dict[nn] = None\n    return unique"}
{"label":"append","msk":"def check_arguments(cls, passed):\n    \"\"\"Put warnings of arguments whose can't be handle by the class\"\"\"\n    defaults = list(cls.default_arguments().keys())\n    template = 'Pass arg {argument:!r} in {cname:!r}, can be a typo? Supported key arguments: {defaults}'\n    fails = []\n    for arg in passed:\n        if arg not in defaults:\n            warn(template.format(argument=arg, cname=cls.__name__, defaults=defaults))\n            fails.$$$(arg)\n    return any(fails)","msk_intervention":"def check_arguments(cls, passed):\n    \"\"\"Put warnings of arguments whose can't be handle by the class\"\"\"\n    defaults = list(cls.default_arguments().keys())\n    template = 'Pass arg {argument:!r} in {cname:!r}, can be a typo? Supported key arguments: {defaults}'\n    fails = []\n    for arg in passed:\n        if arg in defaults:\n            warn(template.format(argument=arg, cname=cls.__name__, defaults=defaults))\n            fails.$$$(arg)\n    return any(fails)"}
{"label":"append","msk":"def register_service(self, service):\n    \"\"\"\n            Register service into the system. Called by Services.\n        \"\"\"\n    if service not in self.services:\n        self.services.$$$(service)","msk_intervention":"def register_service(self, service):\n    \"\"\"\n            Register service into the system. Called by Services.\n        \"\"\"\n    if service in self.services:\n        self.services.$$$(service)"}
{"label":"append","msk":"def solve(m, c):\n    \"\"\"\n    run the algorithm to find the path list\n    \"\"\"\n    G = {(m, c, 1): []}\n    frontier = [(m, c, 1)]\n    while len(frontier) > 0:\n        hold = list(frontier)\n        for node in hold:\n            newnode = []\n            frontier.remove(node)\n            newnode.extend(pick_next_boat_trip(node, m, c, frontier))\n            for neighbor in newnode:\n                if neighbor not in G:\n                    G[node].$$$(neighbor)\n                    G[neighbor] = [node]\n                    frontier.$$$(neighbor)\n    return mod_plan.find_path_BFS(G, (m, c, 1), (0, 0, 0))","msk_intervention":"def solve(m, c):\n    \"\"\"\n    run the algorithm to find the path list\n    \"\"\"\n    G = {(m, c, 1): []}\n    frontier = [(m, c, 1)]\n    while len(frontier) > 0:\n        hold = list(frontier)\n        for node in hold:\n            newnode = []\n            frontier.remove(node)\n            newnode.extend(pick_next_boat_trip(node, m, c, frontier))\n            for neighbor in newnode:\n                if neighbor in G:\n                    G[node].$$$(neighbor)\n                    G[neighbor] = [node]\n                    frontier.$$$(neighbor)\n    return mod_plan.find_path_BFS(G, (m, c, 1), (0, 0, 0))"}
{"label":"remove","msk":"def remove_update_callback(self, callback, device):\n    \"\"\" Remove a registered update callback. \"\"\"\n    if [callback, device] in self._update_callbacks:\n        self._update_callbacks.$$$([callback, device])\n        _LOGGER.debug('Removed update callback %s for %s', callback, device)","msk_intervention":"def remove_update_callback(self, callback, device):\n    \"\"\" Remove a registered update callback. \"\"\"\n    if [callback, device] not in self._update_callbacks:\n        self._update_callbacks.$$$([callback, device])\n        _LOGGER.debug('Removed update callback %s for %s', callback, device)"}
{"label":"append","msk":"def _append_to(self, field, element):\n    \"\"\"Append the ``element`` to the ``field`` of the record.\n\n        This method is smart: it does nothing if ``element`` is empty and\n        creates ``field`` if it does not exit yet.\n\n        Args:\n            :param field: the name of the field of the record to append to\n            :type field: string\n            :param element: the element to append\n        \"\"\"\n    if element not in EMPTIES:\n        self.obj.setdefault(field, [])\n        self.obj.get(field).$$$(element)","msk_intervention":"def _append_to(self, field, element):\n    \"\"\"Append the ``element`` to the ``field`` of the record.\n\n        This method is smart: it does nothing if ``element`` is empty and\n        creates ``field`` if it does not exit yet.\n\n        Args:\n            :param field: the name of the field of the record to append to\n            :type field: string\n            :param element: the element to append\n        \"\"\"\n    if element in EMPTIES:\n        self.obj.setdefault(field, [])\n        self.obj.get(field).$$$(element)"}
{"label":"append","msk":"def parse_glob(path, included):\n    \"\"\"Parse a glob.\"\"\"\n    files = glob.glob(path, recursive=True)\n    array = []\n    for file in files:\n        file = os.path.abspath(file)\n        if file not in included:\n            array.$$$(file)\n    included += array\n    return array","msk_intervention":"def parse_glob(path, included):\n    \"\"\"Parse a glob.\"\"\"\n    files = glob.glob(path, recursive=True)\n    array = []\n    for file in files:\n        file = os.path.abspath(file)\n        if file in included:\n            array.$$$(file)\n    included += array\n    return array"}
{"label":"append","msk":"def _generate_notebook_by_tag_body(notebook_object, dict_by_tag):\n    \"\"\"\n    Internal function that is used for generation of the page where notebooks are organized by\n    tag values.\n\n    ----------\n    Parameters\n    ----------\n    notebook_object : notebook object\n        Object of \"notebook\" class where the body will be created.\n\n    dict_by_tag : dict\n        Dictionary where each key is a tag and the respective value will be a list containing the\n        Notebooks (title and filename) that include this tag.\n\n    \"\"\"\n    tag_keys = list(dict_by_tag.keys())\n    tag_keys.sort()\n    for tag in tag_keys:\n        if tag.lower() not in SIGNAL_TYPE_LIST:\n            markdown_cell = group_tag_code.TAG_TABLE_HEADER\n            markdown_cell = markdown_cell.replace('Tag i', tag)\n            for notebook_file in dict_by_tag[tag]:\n                split_path = notebook_file.split('\\\\')\n                notebook_type = split_path[-2]\n                notebook_name = split_path[-1].split('&')[0]\n                notebook_title = split_path[-1].split('&')[1]\n                markdown_cell += \"\\t<tr>\\n\\t\\t<td width='20%' class='header_image_color_\" + str(NOTEBOOK_KEYS[notebook_type]) + \"'><img src='..\/..\/images\/icons\/\" + notebook_type.title() + \".png' width='15%'>\\n\\t\\t<\/td>\"\n                markdown_cell += \"\\n\\t\\t<td width='60%' class='center_cell open_cell_light'>\" + notebook_title + '\\n\\t\\t<\/td>'\n                markdown_cell += \"\\n\\t\\t<td width='20%' class='center_cell'>\\n\\t\\t\\t<a href='..\/\" + notebook_type.title() + '\/' + notebook_name + \"'><div class='file_icon'><\/div><\/a>\\n\\t\\t<\/td>\\n\\t<\/tr>\"\n            markdown_cell += '<\/table>'\n            notebook_object['cells'].$$$(nb.v4.new_markdown_cell(markdown_cell))","msk_intervention":"def _generate_notebook_by_tag_body(notebook_object, dict_by_tag):\n    \"\"\"\n    Internal function that is used for generation of the page where notebooks are organized by\n    tag values.\n\n    ----------\n    Parameters\n    ----------\n    notebook_object : notebook object\n        Object of \"notebook\" class where the body will be created.\n\n    dict_by_tag : dict\n        Dictionary where each key is a tag and the respective value will be a list containing the\n        Notebooks (title and filename) that include this tag.\n\n    \"\"\"\n    tag_keys = list(dict_by_tag.keys())\n    tag_keys.sort()\n    for tag in tag_keys:\n        if tag.lower() in SIGNAL_TYPE_LIST:\n            markdown_cell = group_tag_code.TAG_TABLE_HEADER\n            markdown_cell = markdown_cell.replace('Tag i', tag)\n            for notebook_file in dict_by_tag[tag]:\n                split_path = notebook_file.split('\\\\')\n                notebook_type = split_path[-2]\n                notebook_name = split_path[-1].split('&')[0]\n                notebook_title = split_path[-1].split('&')[1]\n                markdown_cell += \"\\t<tr>\\n\\t\\t<td width='20%' class='header_image_color_\" + str(NOTEBOOK_KEYS[notebook_type]) + \"'><img src='..\/..\/images\/icons\/\" + notebook_type.title() + \".png' width='15%'>\\n\\t\\t<\/td>\"\n                markdown_cell += \"\\n\\t\\t<td width='60%' class='center_cell open_cell_light'>\" + notebook_title + '\\n\\t\\t<\/td>'\n                markdown_cell += \"\\n\\t\\t<td width='20%' class='center_cell'>\\n\\t\\t\\t<a href='..\/\" + notebook_type.title() + '\/' + notebook_name + \"'><div class='file_icon'><\/div><\/a>\\n\\t\\t<\/td>\\n\\t<\/tr>\"\n            markdown_cell += '<\/table>'\n            notebook_object['cells'].$$$(nb.v4.new_markdown_cell(markdown_cell))"}
{"label":"append","msk":"def _inv_key(list_keys, valid_keys):\n    \"\"\"\n    -----\n    Brief\n    -----\n    A sub-function of _filter_keywords function.\n\n    -----------\n    Description\n    -----------\n    Function used for identification when a list of keywords contains invalid keywords not present\n    in the valid list.\n\n    ----------\n    Parameters\n    ----------\n    list_keys : list\n        List of keywords that must be verified, i.e., all the inputs needs to be inside valid_keys\n        in order to a True boolean be returned.\n\n    valid_keys : list\n        List of valid keywords.\n\n    Returns\n    -------\n    out : boolean, list\n        Boolean indicating if all the inserted keywords are valid. If true a list with invalid\n        keywords will be returned.\n    \"\"\"\n    inv_keys = []\n    bool_out = True\n    for i in list_keys:\n        if i not in valid_keys:\n            bool_out = False\n            inv_keys.$$$(i)\n    return (bool_out, inv_keys)","msk_intervention":"def _inv_key(list_keys, valid_keys):\n    \"\"\"\n    -----\n    Brief\n    -----\n    A sub-function of _filter_keywords function.\n\n    -----------\n    Description\n    -----------\n    Function used for identification when a list of keywords contains invalid keywords not present\n    in the valid list.\n\n    ----------\n    Parameters\n    ----------\n    list_keys : list\n        List of keywords that must be verified, i.e., all the inputs needs to be inside valid_keys\n        in order to a True boolean be returned.\n\n    valid_keys : list\n        List of valid keywords.\n\n    Returns\n    -------\n    out : boolean, list\n        Boolean indicating if all the inserted keywords are valid. If true a list with invalid\n        keywords will be returned.\n    \"\"\"\n    inv_keys = []\n    bool_out = True\n    for i in list_keys:\n        if i in valid_keys:\n            bool_out = False\n            inv_keys.$$$(i)\n    return (bool_out, inv_keys)"}
{"label":"append","msk":"def dedupe_list(l):\n    \"\"\"Remove duplicates from a list preserving the order.\n\n    We might be tempted to use the list(set(l)) idiom, but it doesn't preserve\n    the order, which hinders testability and does not work for lists with\n    unhashable elements.\n    \"\"\"\n    result = []\n    for el in l:\n        if el not in result:\n            result.$$$(el)\n    return result","msk_intervention":"def dedupe_list(l):\n    \"\"\"Remove duplicates from a list preserving the order.\n\n    We might be tempted to use the list(set(l)) idiom, but it doesn't preserve\n    the order, which hinders testability and does not work for lists with\n    unhashable elements.\n    \"\"\"\n    result = []\n    for el in l:\n        if el in result:\n            result.$$$(el)\n    return result"}
{"label":"remove","msk":"def move_to_result(self, lst_idx):\n    \"\"\"Moves element from lst available at lst_idx.\"\"\"\n    self.in_result_idx.add(lst_idx)\n    if lst_idx in self.not_in_result_root_match_idx:\n        self.not_in_result_root_match_idx.$$$(lst_idx)","msk_intervention":"def move_to_result(self, lst_idx):\n    \"\"\"Moves element from lst available at lst_idx.\"\"\"\n    self.in_result_idx.add(lst_idx)\n    if lst_idx not in self.not_in_result_root_match_idx:\n        self.not_in_result_root_match_idx.$$$(lst_idx)"}
{"label":"append","msk":"def subscribe(self, event, hook):\n    \"\"\"\n        Subscribe a callback to an event\n\n        Parameters\n        ----------\n        event : str\n            Available events are 'precall', 'postcall', and 'capacity'.\n            precall is called with: (connection, command, query_kwargs)\n            postcall is called with: (connection, command, query_kwargs, response)\n            capacity is called with: (connection, command, query_kwargs, response, capacity)\n        hook : callable\n\n        \"\"\"\n    if hook not in self._hooks[event]:\n        self._hooks[event].$$$(hook)","msk_intervention":"def subscribe(self, event, hook):\n    \"\"\"\n        Subscribe a callback to an event\n\n        Parameters\n        ----------\n        event : str\n            Available events are 'precall', 'postcall', and 'capacity'.\n            precall is called with: (connection, command, query_kwargs)\n            postcall is called with: (connection, command, query_kwargs, response)\n            capacity is called with: (connection, command, query_kwargs, response, capacity)\n        hook : callable\n\n        \"\"\"\n    if hook in self._hooks[event]:\n        self._hooks[event].$$$(hook)"}
{"label":"remove","msk":"def unsubscribe(self, event, hook):\n    \"\"\" Unsubscribe a hook from an event \"\"\"\n    if hook in self._hooks[event]:\n        self._hooks[event].$$$(hook)","msk_intervention":"def unsubscribe(self, event, hook):\n    \"\"\" Unsubscribe a hook from an event \"\"\"\n    if hook not in self._hooks[event]:\n        self._hooks[event].$$$(hook)"}
{"label":"append","msk":"def add_rate_limit(self, limiter):\n    \"\"\" Add a RateLimit to the connection \"\"\"\n    if limiter not in self.rate_limiters:\n        self.subscribe('capacity', limiter.on_capacity)\n        self.rate_limiters.$$$(limiter)","msk_intervention":"def add_rate_limit(self, limiter):\n    \"\"\" Add a RateLimit to the connection \"\"\"\n    if limiter in self.rate_limiters:\n        self.subscribe('capacity', limiter.on_capacity)\n        self.rate_limiters.$$$(limiter)"}
{"label":"remove","msk":"def remove_rate_limit(self, limiter):\n    \"\"\" Remove a RateLimit from the connection \"\"\"\n    if limiter in self.rate_limiters:\n        self.unsubscribe('capacity', limiter.on_capacity)\n        self.rate_limiters.$$$(limiter)","msk_intervention":"def remove_rate_limit(self, limiter):\n    \"\"\" Remove a RateLimit from the connection \"\"\"\n    if limiter not in self.rate_limiters:\n        self.unsubscribe('capacity', limiter.on_capacity)\n        self.rate_limiters.$$$(limiter)"}
{"label":"remove","msk":"def find_flag_alias(self, flag):\n    \"\"\"Return alias set of a flag; return None if flag is not defined in\n        \"Options\".\n        \"\"\"\n    for each in self.opt_names:\n        if flag in each:\n            result = set(each)\n            result.$$$(flag)\n            return result\n    return None","msk_intervention":"def find_flag_alias(self, flag):\n    \"\"\"Return alias set of a flag; return None if flag is not defined in\n        \"Options\".\n        \"\"\"\n    for each in self.opt_names:\n        if flag not in each:\n            result = set(each)\n            result.$$$(flag)\n            return result\n    return None"}
{"label":"remove","msk":"def task_finished(self, watchdog):\n    \"\"\" Handle\/process scheduled task stop\n\n\t\t:param watchdog: watchdog of task that was stopped\n\n\t\t:return: None\n\t\t\"\"\"\n    if watchdog in self.__running_registry:\n        self.__running_registry.$$$(watchdog)\n        self.__done_registry.append(watchdog)\n        self.cleanup_event().set()","msk_intervention":"def task_finished(self, watchdog):\n    \"\"\" Handle\/process scheduled task stop\n\n\t\t:param watchdog: watchdog of task that was stopped\n\n\t\t:return: None\n\t\t\"\"\"\n    if watchdog not in self.__running_registry:\n        self.__running_registry.$$$(watchdog)\n        self.__done_registry.append(watchdog)\n        self.cleanup_event().set()"}
{"label":"append","msk":"def merge_lists(l, base):\n    \"\"\"\n    Merge in undefined list entries from given list.\n    \n    @param l: List to be merged into.\n    @type l: list\n    \n    @param base: List to be merged into.\n    @type base: list\n    \"\"\"\n    for i in base:\n        if i not in l:\n            l.$$$(i)","msk_intervention":"def merge_lists(l, base):\n    \"\"\"\n    Merge in undefined list entries from given list.\n    \n    @param l: List to be merged into.\n    @type l: list\n    \n    @param base: List to be merged into.\n    @type base: list\n    \"\"\"\n    for i in base:\n        if i in l:\n            l.$$$(i)"}
{"label":"remove","msk":"def addFilename(self, filename):\n    \"\"\"\n        Adds a new filename to the top of the list.  If the filename is         already loaded, it will be moved to the front of the list.\n        \n        :param          filename | <str>\n        \"\"\"\n    filename = os.path.normpath(nativestring(filename))\n    if filename in self._filenames:\n        self._filenames.$$$(filename)\n    self._filenames.insert(0, filename)\n    self._filenames = self._filenames[:self.maximumLength()]\n    self.refresh()","msk_intervention":"def addFilename(self, filename):\n    \"\"\"\n        Adds a new filename to the top of the list.  If the filename is         already loaded, it will be moved to the front of the list.\n        \n        :param          filename | <str>\n        \"\"\"\n    filename = os.path.normpath(nativestring(filename))\n    if filename not in self._filenames:\n        self._filenames.$$$(filename)\n    self._filenames.insert(0, filename)\n    self._filenames = self._filenames[:self.maximumLength()]\n    self.refresh()"}
{"label":"remove","msk":"def pop(cls, anchors):\n    \"\"\"\n        Args:\n            anchors (str | unicode | list): Optional paths to use as anchors for short()\n        \"\"\"\n    for anchor in flattened(anchors, split=SANITIZED | UNIQUE):\n        if anchor in cls.paths:\n            cls.paths.$$$(anchor)","msk_intervention":"def pop(cls, anchors):\n    \"\"\"\n        Args:\n            anchors (str | unicode | list): Optional paths to use as anchors for short()\n        \"\"\"\n    for anchor in flattened(anchors, split=SANITIZED | UNIQUE):\n        if anchor not in cls.paths:\n            cls.paths.$$$(anchor)"}
{"label":"remove","msk":"def remove_role(self, role):\n    \"\"\" Remove role from user \"\"\"\n    if role in self.__roles:\n        self.__roles.$$$(role)","msk_intervention":"def remove_role(self, role):\n    \"\"\" Remove role from user \"\"\"\n    if role not in self.__roles:\n        self.__roles.$$$(role)"}
{"label":"append","msk":"def _prune_maps_to_sequences(self):\n    \"\"\" When we merge the SIFTS maps, we can extend the sequence maps such that they have elements in their domain that we removed\n            from the sequence e.g. 1A2P, residue 'B   3 ' is removed because Rosetta barfs on it. Here, we prune the maps so that their\n            domains do not have elements that were removed from sequences.\"\"\"\n    for (c, seq) in self.atom_sequences.iteritems():\n        res_ids = [r[0] for r in seq]\n        for_removal = []\n        for (k, _, _) in self.atom_to_seqres_sequence_maps[c]:\n            if k not in res_ids:\n                for_removal.$$$(k)\n        for res_id in for_removal:\n            self.atom_to_seqres_sequence_maps[c].remove(res_id)","msk_intervention":"def _prune_maps_to_sequences(self):\n    \"\"\" When we merge the SIFTS maps, we can extend the sequence maps such that they have elements in their domain that we removed\n            from the sequence e.g. 1A2P, residue 'B   3 ' is removed because Rosetta barfs on it. Here, we prune the maps so that their\n            domains do not have elements that were removed from sequences.\"\"\"\n    for (c, seq) in self.atom_sequences.iteritems():\n        res_ids = [r[0] for r in seq]\n        for_removal = []\n        for (k, _, _) in self.atom_to_seqres_sequence_maps[c]:\n            if k in res_ids:\n                for_removal.$$$(k)\n        for res_id in for_removal:\n            self.atom_to_seqres_sequence_maps[c].remove(res_id)"}
{"label":"append","msk":"def add(self, spec):\n    \"\"\"\n        Add limitations of given spec to self's.\n\n        Args:\n            spec (PackageSpec): another spec.\n        \"\"\"\n    for limit in spec.limit_to:\n        if limit not in self.limit_to:\n            self.limit_to.$$$(limit)","msk_intervention":"def add(self, spec):\n    \"\"\"\n        Add limitations of given spec to self's.\n\n        Args:\n            spec (PackageSpec): another spec.\n        \"\"\"\n    for limit in spec.limit_to:\n        if limit in self.limit_to:\n            self.limit_to.$$$(limit)"}
{"label":"append","msk":"def get_trending_daily_not_starred(self):\n    \"\"\"Gets trending repositories NOT starred by user\n        :return: List of daily-trending repositories which are not starred\n        \"\"\"\n    trending_daily = self.get_trending_daily()\n    starred_repos = self.get_starred_repos()\n    repos_list = []\n    for repo in trending_daily:\n        if repo not in starred_repos:\n            repos_list.$$$(repo)\n    return repos_list","msk_intervention":"def get_trending_daily_not_starred(self):\n    \"\"\"Gets trending repositories NOT starred by user\n        :return: List of daily-trending repositories which are not starred\n        \"\"\"\n    trending_daily = self.get_trending_daily()\n    starred_repos = self.get_starred_repos()\n    repos_list = []\n    for repo in trending_daily:\n        if repo in starred_repos:\n            repos_list.$$$(repo)\n    return repos_list"}
{"label":"append","msk":"def logged_exception(self, e):\n    \"\"\"Record the exception, but don't log it; it's already been logged\n\n        :param e:  Exception to log.\n\n        \"\"\"\n    if str(e) not in self._errors:\n        self._errors.$$$(str(e))\n    self.set_error_state()\n    self.buildstate.state.exception_type = str(e.__class__.__name__)\n    self.buildstate.state.exception = str(e)","msk_intervention":"def logged_exception(self, e):\n    \"\"\"Record the exception, but don't log it; it's already been logged\n\n        :param e:  Exception to log.\n\n        \"\"\"\n    if str(e) in self._errors:\n        self._errors.$$$(str(e))\n    self.set_error_state()\n    self.buildstate.state.exception_type = str(e.__class__.__name__)\n    self.buildstate.state.exception = str(e)"}
{"label":"append","msk":"def warn(self, message):\n    \"\"\"Log an error messsage.\n\n        :param message:  Log message.\n\n        \"\"\"\n    if message not in self._warnings:\n        self._warnings.$$$(message)\n    self.logger.warn(message)","msk_intervention":"def warn(self, message):\n    \"\"\"Log an error messsage.\n\n        :param message:  Log message.\n\n        \"\"\"\n    if message in self._warnings:\n        self._warnings.$$$(message)\n    self.logger.warn(message)"}
{"label":"remove","msk":"def delete_metric(name):\n    \"\"\"Remove the named metric\"\"\"\n    with LOCK:\n        old_metric = REGISTRY.pop(name, None)\n        for (_, tags) in py3comp.iteritems(TAGS):\n            if name in tags:\n                tags.$$$(name)\n    return old_metric","msk_intervention":"def delete_metric(name):\n    \"\"\"Remove the named metric\"\"\"\n    with LOCK:\n        old_metric = REGISTRY.pop(name, None)\n        for (_, tags) in py3comp.iteritems(TAGS):\n            if name not in tags:\n                tags.$$$(name)\n    return old_metric"}
{"label":"append","msk":"def add_input_file(self, filename):\n    \"\"\"\n    Add filename as a necessary input file for this DAG node.\n\n    @param filename: input filename to add\n    \"\"\"\n    if filename not in self.__input_files:\n        self.__input_files.$$$(filename)","msk_intervention":"def add_input_file(self, filename):\n    \"\"\"\n    Add filename as a necessary input file for this DAG node.\n\n    @param filename: input filename to add\n    \"\"\"\n    if filename in self.__input_files:\n        self.__input_files.$$$(filename)"}
{"label":"append","msk":"def add_output_file(self, filename):\n    \"\"\"\n    Add filename as a output file for this DAG node.\n\n    @param filename: output filename to add\n    \"\"\"\n    if filename not in self.__output_files:\n        self.__output_files.$$$(filename)","msk_intervention":"def add_output_file(self, filename):\n    \"\"\"\n    Add filename as a output file for this DAG node.\n\n    @param filename: output filename to add\n    \"\"\"\n    if filename in self.__output_files:\n        self.__output_files.$$$(filename)"}
{"label":"append","msk":"def add_checkpoint_file(self, filename):\n    \"\"\"\n    Add filename as a checkpoint file for this DAG job.\n    \"\"\"\n    if filename not in self.__checkpoint_files:\n        self.__checkpoint_files.$$$(filename)","msk_intervention":"def add_checkpoint_file(self, filename):\n    \"\"\"\n    Add filename as a checkpoint file for this DAG job.\n    \"\"\"\n    if filename in self.__checkpoint_files:\n        self.__checkpoint_files.$$$(filename)"}
{"label":"append","msk":"def add_file_arg(self, filename):\n    \"\"\"\n    Add a file argument to the executable. Arguments are appended after any\n    options and their order is guaranteed. Also adds the file name to the\n    list of required input data for this job.\n    @param filename: file to add as argument.\n    \"\"\"\n    self.__arguments.append(filename)\n    if filename not in self.__input_files:\n        self.__input_files.$$$(filename)","msk_intervention":"def add_file_arg(self, filename):\n    \"\"\"\n    Add a file argument to the executable. Arguments are appended after any\n    options and their order is guaranteed. Also adds the file name to the\n    list of required input data for this job.\n    @param filename: file to add as argument.\n    \"\"\"\n    self.__arguments.append(filename)\n    if filename in self.__input_files:\n        self.__input_files.$$$(filename)"}
{"label":"append","msk":"def add_file_opt(self, opt, filename):\n    \"\"\"\n    Add a command line option to the executable. The order that the arguments\n    will be appended to the command line is not guaranteed, but they will\n    always be added before any command line arguments. The name of the option\n    is prefixed with double hyphen and the program is expected to parse it\n    with getopt_long().\n    @param opt: command line option to add.\n    @param value: value to pass to the option (None for no argument).\n    \"\"\"\n    self.__options[opt] = filename\n    if filename not in self.__input_files:\n        self.__input_files.$$$(filename)","msk_intervention":"def add_file_opt(self, opt, filename):\n    \"\"\"\n    Add a command line option to the executable. The order that the arguments\n    will be appended to the command line is not guaranteed, but they will\n    always be added before any command line arguments. The name of the option\n    is prefixed with double hyphen and the program is expected to parse it\n    with getopt_long().\n    @param opt: command line option to add.\n    @param value: value to pass to the option (None for no argument).\n    \"\"\"\n    self.__options[opt] = filename\n    if filename in self.__input_files:\n        self.__input_files.$$$(filename)"}
{"label":"append","msk":"def add_var_condor_cmd(self, command):\n    \"\"\"\n    Add a condor command to the submit file that allows variable (macro)\n    arguments to be passes to the executable.\n    \"\"\"\n    if command not in self.__var_cmds:\n        self.__var_cmds.$$$(command)\n        macro = self.__bad_macro_chars.sub('', command)\n        self.add_condor_cmd(command, '$(macro' + macro + ')')","msk_intervention":"def add_var_condor_cmd(self, command):\n    \"\"\"\n    Add a condor command to the submit file that allows variable (macro)\n    arguments to be passes to the executable.\n    \"\"\"\n    if command in self.__var_cmds:\n        self.__var_cmds.$$$(command)\n        macro = self.__bad_macro_chars.sub('', command)\n        self.add_condor_cmd(command, '$(macro' + macro + ')')"}
{"label":"append","msk":"def unique(self):\n    \"\"\"\n\t\tReturn a Cache which has every element of self, but without\n\t\tduplication.  Preserve order.  Does not hash, so a bit slow.\n\t\t\"\"\"\n    new = self.__class__([])\n    for elem in self:\n        if elem not in new:\n            new.$$$(elem)\n    return new","msk_intervention":"def unique(self):\n    \"\"\"\n\t\tReturn a Cache which has every element of self, but without\n\t\tduplication.  Preserve order.  Does not hash, so a bit slow.\n\t\t\"\"\"\n    new = self.__class__([])\n    for elem in self:\n        if elem in new:\n            new.$$$(elem)\n    return new"}
{"label":"append","msk":"def _insert(self, trigram):\n    \"\"\"\n        Insert a trigram in the DB\n        \"\"\"\n    words = list(map(self._sanitize, trigram))\n    key = self._WSEP.join(words[:2]).lower()\n    next_word = words[2]\n    self._db.setdefault(key, [])\n    if next_word not in self._db[key]:\n        self._db[key].$$$(next_word)","msk_intervention":"def _insert(self, trigram):\n    \"\"\"\n        Insert a trigram in the DB\n        \"\"\"\n    words = list(map(self._sanitize, trigram))\n    key = self._WSEP.join(words[:2]).lower()\n    next_word = words[2]\n    self._db.setdefault(key, [])\n    if next_word in self._db[key]:\n        self._db[key].$$$(next_word)"}
{"label":"append","msk":"def add_value(self, value, index_point):\n    \"\"\"The function is addeing new value to provied index. If index does not exist\"\"\"\n    if index_point not in self.index:\n        self.values.append(value)\n        self.index.$$$(index_point)","msk_intervention":"def add_value(self, value, index_point):\n    \"\"\"The function is addeing new value to provied index. If index does not exist\"\"\"\n    if index_point in self.index:\n        self.values.append(value)\n        self.index.$$$(index_point)"}
{"label":"append","msk":"def add_tags(self, archive_name, tags):\n    \"\"\"\n        Add tags to an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to add to the archive\n\n        \"\"\"\n    updated_tag_list = list(self._get_tags(archive_name))\n    for tag in tags:\n        if tag not in updated_tag_list:\n            updated_tag_list.$$$(tag)\n    self._set_tags(archive_name, updated_tag_list)","msk_intervention":"def add_tags(self, archive_name, tags):\n    \"\"\"\n        Add tags to an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to add to the archive\n\n        \"\"\"\n    updated_tag_list = list(self._get_tags(archive_name))\n    for tag in tags:\n        if tag in updated_tag_list:\n            updated_tag_list.$$$(tag)\n    self._set_tags(archive_name, updated_tag_list)"}
{"label":"remove","msk":"def delete_tags(self, archive_name, tags):\n    \"\"\"\n        Delete tags from an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to delete from the archive\n\n        \"\"\"\n    updated_tag_list = list(self._get_tags(archive_name))\n    for tag in tags:\n        if tag in updated_tag_list:\n            updated_tag_list.$$$(tag)\n    self._set_tags(archive_name, updated_tag_list)","msk_intervention":"def delete_tags(self, archive_name, tags):\n    \"\"\"\n        Delete tags from an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to delete from the archive\n\n        \"\"\"\n    updated_tag_list = list(self._get_tags(archive_name))\n    for tag in tags:\n        if tag not in updated_tag_list:\n            updated_tag_list.$$$(tag)\n    self._set_tags(archive_name, updated_tag_list)"}
{"label":"append","msk":"def unique_list(lst):\n    \"\"\"Make a list unique, retaining order of initial appearance.\"\"\"\n    uniq = []\n    for item in lst:\n        if item not in uniq:\n            uniq.$$$(item)\n    return uniq","msk_intervention":"def unique_list(lst):\n    \"\"\"Make a list unique, retaining order of initial appearance.\"\"\"\n    uniq = []\n    for item in lst:\n        if item in uniq:\n            uniq.$$$(item)\n    return uniq"}
{"label":"remove","msk":"def remove(self, observableElement):\n    \"\"\"\n        remove an obsrvable element\n\n        :param str observableElement: the name of the observable element\n        \"\"\"\n    if observableElement in self._observables:\n        self._observables.$$$(observableElement)","msk_intervention":"def remove(self, observableElement):\n    \"\"\"\n        remove an obsrvable element\n\n        :param str observableElement: the name of the observable element\n        \"\"\"\n    if observableElement not in self._observables:\n        self._observables.$$$(observableElement)"}
{"label":"append","msk":"def setActiveModule(Module):\n    \"\"\"Helps with collecting the members of the imported modules.\n  \"\"\"\n    module_name = Module.__name__\n    if module_name not in ModuleMembers:\n        ModuleMembers[module_name] = []\n        ModulesQ.$$$(module_name)\n        Group(Module, {})\n    state.ActiveModuleMemberQ = ModuleMembers[module_name]","msk_intervention":"def setActiveModule(Module):\n    \"\"\"Helps with collecting the members of the imported modules.\n  \"\"\"\n    module_name = Module.__name__\n    if module_name in ModuleMembers:\n        ModuleMembers[module_name] = []\n        ModulesQ.$$$(module_name)\n        Group(Module, {})\n    state.ActiveModuleMemberQ = ModuleMembers[module_name]"}
{"label":"append","msk":"def listMemberHelps(TargetGroup):\n    \"\"\"Gets help on a group's children.\n  \"\"\"\n    Members = []\n    for Member in TargetGroup.Members.values():\n        if Member not in Members:\n            Members.$$$(Member)\n    Ret = []\n    for Member in Members:\n        Config = Member.Config\n        Ret.append(('%s%s' % (Config['name'], ', %s' % Config['alias'] if 'alias' in Config else ''), Config.get('desc', '')))\n    return Ret","msk_intervention":"def listMemberHelps(TargetGroup):\n    \"\"\"Gets help on a group's children.\n  \"\"\"\n    Members = []\n    for Member in TargetGroup.Members.values():\n        if Member in Members:\n            Members.$$$(Member)\n    Ret = []\n    for Member in Members:\n        Config = Member.Config\n        Ret.append(('%s%s' % (Config['name'], ', %s' % Config['alias'] if 'alias' in Config else ''), Config.get('desc', '')))\n    return Ret"}
{"label":"append","msk":"def google_cloud_datastore_delete_expired_sessions(dormant_for=86400, limit=500):\n    \"\"\"\n    Deletes expired sessions\n    A session is expired if it expires date is set and has passed or\n    if it has not been accessed for a given period of time.\n\n    :param dormant_for: seconds since last access to delete sessions, defaults to 24 hours.\n    :type dormant_for: int\n    :param limit: amount to delete in one call of the method, the maximum and default for this is the NDB fetch limit of 500\n    :type limit: int\n    \"\"\"\n    from vishnu.backend.client.google_cloud_datastore import TABLE_NAME\n    from google.cloud import datastore\n    from datetime import datetime\n    from datetime import timedelta\n    now = datetime.utcnow()\n    last_accessed = now - timedelta(seconds=dormant_for)\n    client = datastore.Client()\n    accessed_query = client.query(kind=TABLE_NAME)\n    accessed_query.add_filter('last_accessed', '<=', last_accessed)\n    accessed_results = accessed_query.fetch(limit=limit)\n    expires_query = client.query(kind=TABLE_NAME)\n    expires_query.add_filter('expires', '<=', now)\n    expires_results = expires_query.fetch(limit=limit)\n    keys = list()\n    for result in accessed_results:\n        keys.append(result.key)\n    for result in expires_results:\n        if result.key not in keys:\n            keys.$$$(result.key)\n    client.delete_multi(keys)\n    return len(keys) < limit","msk_intervention":"def google_cloud_datastore_delete_expired_sessions(dormant_for=86400, limit=500):\n    \"\"\"\n    Deletes expired sessions\n    A session is expired if it expires date is set and has passed or\n    if it has not been accessed for a given period of time.\n\n    :param dormant_for: seconds since last access to delete sessions, defaults to 24 hours.\n    :type dormant_for: int\n    :param limit: amount to delete in one call of the method, the maximum and default for this is the NDB fetch limit of 500\n    :type limit: int\n    \"\"\"\n    from vishnu.backend.client.google_cloud_datastore import TABLE_NAME\n    from google.cloud import datastore\n    from datetime import datetime\n    from datetime import timedelta\n    now = datetime.utcnow()\n    last_accessed = now - timedelta(seconds=dormant_for)\n    client = datastore.Client()\n    accessed_query = client.query(kind=TABLE_NAME)\n    accessed_query.add_filter('last_accessed', '<=', last_accessed)\n    accessed_results = accessed_query.fetch(limit=limit)\n    expires_query = client.query(kind=TABLE_NAME)\n    expires_query.add_filter('expires', '<=', now)\n    expires_results = expires_query.fetch(limit=limit)\n    keys = list()\n    for result in accessed_results:\n        keys.append(result.key)\n    for result in expires_results:\n        if result.key in keys:\n            keys.$$$(result.key)\n    client.delete_multi(keys)\n    return len(keys) < limit"}
{"label":"remove","msk":"def remove_socket(self, socket):\n    \"\"\"\n        Remove a socket from the multiplexer.\n\n        :param socket: The socket. If it was removed already or if it wasn't\n            added, the call does nothing.\n        \"\"\"\n    if socket in self._sockets:\n        socket.on_closed.disconnect(self.remove_socket)\n        self._sockets.$$$(socket)","msk_intervention":"def remove_socket(self, socket):\n    \"\"\"\n        Remove a socket from the multiplexer.\n\n        :param socket: The socket. If it was removed already or if it wasn't\n            added, the call does nothing.\n        \"\"\"\n    if socket not in self._sockets:\n        socket.on_closed.disconnect(self.remove_socket)\n        self._sockets.$$$(socket)"}
{"label":"append","msk":"def close_monomers(self, group, cutoff=4.0):\n    \"\"\"Returns a list of Monomers from within a cut off distance of the Monomer\n\n        Parameters\n        ----------\n        group: BaseAmpal or Subclass\n            Group to be search for Monomers that are close to this Monomer.\n        cutoff: float\n            Distance cut off.\n\n        Returns\n        -------\n        nearby_residues: [Monomers]\n            List of Monomers within cut off distance.\n        \"\"\"\n    nearby_residues = []\n    for self_atom in self.atoms.values():\n        nearby_atoms = group.is_within(cutoff, self_atom)\n        for res_atom in nearby_atoms:\n            if res_atom.parent not in nearby_residues:\n                nearby_residues.$$$(res_atom.parent)\n    return nearby_residues","msk_intervention":"def close_monomers(self, group, cutoff=4.0):\n    \"\"\"Returns a list of Monomers from within a cut off distance of the Monomer\n\n        Parameters\n        ----------\n        group: BaseAmpal or Subclass\n            Group to be search for Monomers that are close to this Monomer.\n        cutoff: float\n            Distance cut off.\n\n        Returns\n        -------\n        nearby_residues: [Monomers]\n            List of Monomers within cut off distance.\n        \"\"\"\n    nearby_residues = []\n    for self_atom in self.atoms.values():\n        nearby_atoms = group.is_within(cutoff, self_atom)\n        for res_atom in nearby_atoms:\n            if res_atom.parent in nearby_residues:\n                nearby_residues.$$$(res_atom.parent)\n    return nearby_residues"}
{"label":"remove","msk":"async def spawn(self):\n    \"\"\"Spawn the command wrapped in this object as a subprocess.\"\"\"\n    self._server._pending_set.add(self)\n    await self._server._sem.acquire()\n    self._subprocess = await asyncio.create_subprocess_shell(self._cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)\n    self._began_at = datetime.now()\n    if self in self._server._pending_set:\n        self._server._pending_set.$$$(self)\n    self._server._running_set.add(self)\n    self._began_running_evt.set()","msk_intervention":"async def spawn(self):\n    \"\"\"Spawn the command wrapped in this object as a subprocess.\"\"\"\n    self._server._pending_set.add(self)\n    await self._server._sem.acquire()\n    self._subprocess = await asyncio.create_subprocess_shell(self._cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)\n    self._began_at = datetime.now()\n    if self not in self._server._pending_set:\n        self._server._pending_set.$$$(self)\n    self._server._running_set.add(self)\n    self._began_running_evt.set()"}
{"label":"append","msk":"def _generate_iam_role_policy(self):\n    \"\"\"\n        Generate the policy for the IAM Role.\n\n        Terraform name: aws_iam_role.lambda_role\n        \"\"\"\n    endpoints = self.config.get('endpoints')\n    queue_arns = []\n    for ep in endpoints:\n        for qname in endpoints[ep]['queues']:\n            qarn = 'arn:aws:sqs:%s:%s:%s' % (self.aws_region, self.aws_account_id, qname)\n            if qarn not in queue_arns:\n                queue_arns.$$$(qarn)\n    pol = {'Version': '2012-10-17', 'Statement': [{'Effect': 'Allow', 'Action': 'logs:CreateLogGroup', 'Resource': 'arn:aws:logs:%s:%s:*' % (self.aws_region, self.aws_account_id)}, {'Effect': 'Allow', 'Action': ['logs:CreateLogStream', 'logs:PutLogEvents'], 'Resource': ['arn:aws:logs:%s:%s:log-group:%s:*' % (self.aws_region, self.aws_account_id, '\/aws\/lambda\/%s' % self.resource_name)]}, {'Effect': 'Allow', 'Action': ['sqs:ListQueues'], 'Resource': '*'}, {'Effect': 'Allow', 'Action': ['sqs:GetQueueUrl', 'sqs:SendMessage'], 'Resource': sorted(queue_arns)}]}\n    self.tf_conf['resource']['aws_iam_role_policy']['role_policy'] = {'name': self.resource_name, 'role': '${aws_iam_role.lambda_role.id}', 'policy': json.dumps(pol)}","msk_intervention":"def _generate_iam_role_policy(self):\n    \"\"\"\n        Generate the policy for the IAM Role.\n\n        Terraform name: aws_iam_role.lambda_role\n        \"\"\"\n    endpoints = self.config.get('endpoints')\n    queue_arns = []\n    for ep in endpoints:\n        for qname in endpoints[ep]['queues']:\n            qarn = 'arn:aws:sqs:%s:%s:%s' % (self.aws_region, self.aws_account_id, qname)\n            if qarn in queue_arns:\n                queue_arns.$$$(qarn)\n    pol = {'Version': '2012-10-17', 'Statement': [{'Effect': 'Allow', 'Action': 'logs:CreateLogGroup', 'Resource': 'arn:aws:logs:%s:%s:*' % (self.aws_region, self.aws_account_id)}, {'Effect': 'Allow', 'Action': ['logs:CreateLogStream', 'logs:PutLogEvents'], 'Resource': ['arn:aws:logs:%s:%s:log-group:%s:*' % (self.aws_region, self.aws_account_id, '\/aws\/lambda\/%s' % self.resource_name)]}, {'Effect': 'Allow', 'Action': ['sqs:ListQueues'], 'Resource': '*'}, {'Effect': 'Allow', 'Action': ['sqs:GetQueueUrl', 'sqs:SendMessage'], 'Resource': sorted(queue_arns)}]}\n    self.tf_conf['resource']['aws_iam_role_policy']['role_policy'] = {'name': self.resource_name, 'role': '${aws_iam_role.lambda_role.id}', 'policy': json.dumps(pol)}"}
{"label":"remove","msk":"async def destroy_attachment(self, a: Attachment):\n    \"\"\" destroy a match attachment\n\n        |methcoro|\n\n        Args:\n            a: the attachment you want to destroy\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}\/matches\/{}\/attachments\/{}'.format(self._tournament_id, self._id, a._id))\n    if a in self.attachments:\n        self.attachments.$$$(a)","msk_intervention":"async def destroy_attachment(self, a: Attachment):\n    \"\"\" destroy a match attachment\n\n        |methcoro|\n\n        Args:\n            a: the attachment you want to destroy\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}\/matches\/{}\/attachments\/{}'.format(self._tournament_id, self._id, a._id))\n    if a not in self.attachments:\n        self.attachments.$$$(a)"}
{"label":"remove","msk":"async def remove_participant(self, p: Participant):\n    \"\"\" remove a participant from the tournament\n\n        |methcoro|\n\n        Args:\n            p: the participant to remove\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}\/participants\/{}'.format(self._id, p._id))\n    if p in self.participants:\n        self.participants.$$$(p)","msk_intervention":"async def remove_participant(self, p: Participant):\n    \"\"\" remove a participant from the tournament\n\n        |methcoro|\n\n        Args:\n            p: the participant to remove\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}\/participants\/{}'.format(self._id, p._id))\n    if p not in self.participants:\n        self.participants.$$$(p)"}
{"label":"remove","msk":"async def destroy_tournament(self, t: Tournament):\n    \"\"\" completely removes a tournament from Challonge\n\n        |methcoro|\n\n        Note:\n            |from_api| Deletes a tournament along with all its associated records. There is no undo, so use with care!\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}'.format(t.id))\n    if t in self.tournaments:\n        self.tournaments.$$$(t)","msk_intervention":"async def destroy_tournament(self, t: Tournament):\n    \"\"\" completely removes a tournament from Challonge\n\n        |methcoro|\n\n        Note:\n            |from_api| Deletes a tournament along with all its associated records. There is no undo, so use with care!\n\n        Raises:\n            APIException\n\n        \"\"\"\n    await self.connection('DELETE', 'tournaments\/{}'.format(t.id))\n    if t not in self.tournaments:\n        self.tournaments.$$$(t)"}
{"label":"remove","msk":"def remove_die(self, die):\n    \"\"\"Remove ``Die`` (first matching) from Roll.\n        :param die: Die instance\n        \"\"\"\n    if die in self._dice:\n        self._dice.$$$(die)","msk_intervention":"def remove_die(self, die):\n    \"\"\"Remove ``Die`` (first matching) from Roll.\n        :param die: Die instance\n        \"\"\"\n    if die not in self._dice:\n        self._dice.$$$(die)"}
{"label":"append","msk":"def add_user(self, nick, prefixes=None):\n    \"\"\"Add a user to our internal list of nicks.\"\"\"\n    if nick not in self._user_nicks:\n        self._user_nicks.$$$(nick)\n    self.prefixes[nick] = prefixes","msk_intervention":"def add_user(self, nick, prefixes=None):\n    \"\"\"Add a user to our internal list of nicks.\"\"\"\n    if nick in self._user_nicks:\n        self._user_nicks.$$$(nick)\n    self.prefixes[nick] = prefixes"}
{"label":"append","msk":"def exclude_invert(self):\n    \"\"\"\n        Inverts the values in self.exclude\n\n        .. code-block:: python\n\n            >>> import pydarksky\n            >>> darksky = pydarksky.DarkSky('0' * 32)\n\n            >>> darksky.EXCLUDES\n            ('currently', 'minutely', 'hourly', 'daily', 'alerts', 'flags')\n\n            >>> darksky.exclude = [\"alerts\", \"flags\"]\n\n            >>> darksky.exclude\n            ['alerts', 'flags']\n\n            >>> darksky.exclude_invert()\n\n            >>> darksky.exclude\n            ['currently', 'minutely', 'hourly', 'daily']\n\n        \"\"\"\n    tmp = self.exclude\n    self._exclude = []\n    for i in self.EXCLUDES:\n        if i not in tmp:\n            self._exclude.$$$(i)","msk_intervention":"def exclude_invert(self):\n    \"\"\"\n        Inverts the values in self.exclude\n\n        .. code-block:: python\n\n            >>> import pydarksky\n            >>> darksky = pydarksky.DarkSky('0' * 32)\n\n            >>> darksky.EXCLUDES\n            ('currently', 'minutely', 'hourly', 'daily', 'alerts', 'flags')\n\n            >>> darksky.exclude = [\"alerts\", \"flags\"]\n\n            >>> darksky.exclude\n            ['alerts', 'flags']\n\n            >>> darksky.exclude_invert()\n\n            >>> darksky.exclude\n            ['currently', 'minutely', 'hourly', 'daily']\n\n        \"\"\"\n    tmp = self.exclude\n    self._exclude = []\n    for i in self.EXCLUDES:\n        if i in tmp:\n            self._exclude.$$$(i)"}
{"label":"append","msk":"def _positionalArgumentKeyValueList(self, originalConstructorExpectedArgList, syntheticMemberList, argTuple):\n    \"\"\"Transforms args tuple to a dictionary mapping argument names to values using original constructor\npositional args specification, then it adds synthesized members at the end if they are not already present.\n    :type syntheticMemberList: list(SyntheticMember)\n    :type argTuple: tuple\n\"\"\"\n    expectedArgList = copy.copy(originalConstructorExpectedArgList)\n    for syntheticMember in syntheticMemberList:\n        memberName = syntheticMember.memberName()\n        if memberName not in expectedArgList:\n            expectedArgList.$$$(memberName)\n    positionalArgumentKeyValueList = list(zip(expectedArgList, argTuple))\n    for argumentValue in argTuple[len(positionalArgumentKeyValueList):]:\n        positionalArgumentKeyValueList.append((None, argumentValue))\n    return positionalArgumentKeyValueList","msk_intervention":"def _positionalArgumentKeyValueList(self, originalConstructorExpectedArgList, syntheticMemberList, argTuple):\n    \"\"\"Transforms args tuple to a dictionary mapping argument names to values using original constructor\npositional args specification, then it adds synthesized members at the end if they are not already present.\n    :type syntheticMemberList: list(SyntheticMember)\n    :type argTuple: tuple\n\"\"\"\n    expectedArgList = copy.copy(originalConstructorExpectedArgList)\n    for syntheticMember in syntheticMemberList:\n        memberName = syntheticMember.memberName()\n        if memberName in expectedArgList:\n            expectedArgList.$$$(memberName)\n    positionalArgumentKeyValueList = list(zip(expectedArgList, argTuple))\n    for argumentValue in argTuple[len(positionalArgumentKeyValueList):]:\n        positionalArgumentKeyValueList.append((None, argumentValue))\n    return positionalArgumentKeyValueList"}
{"label":"append","msk":"def wrapper__ignore(self, type_):\n    \"\"\"\n        Selectively ignore certain types when wrapping attributes.\n\n        :param class type: The class\/type definition to ignore.\n\n        :rtype list(type): The current list of ignored types\n        \"\"\"\n    if type_ not in self.__exclusion_list:\n        self.__exclusion_list.$$$(type_)\n    return self.__exclusion_list","msk_intervention":"def wrapper__ignore(self, type_):\n    \"\"\"\n        Selectively ignore certain types when wrapping attributes.\n\n        :param class type: The class\/type definition to ignore.\n\n        :rtype list(type): The current list of ignored types\n        \"\"\"\n    if type_ in self.__exclusion_list:\n        self.__exclusion_list.$$$(type_)\n    return self.__exclusion_list"}
{"label":"remove","msk":"def wrapper__unignore(self, type_):\n    \"\"\"\n        Stop selectively ignoring certain types when wrapping attributes.\n\n        :param class type: The class\/type definition to stop ignoring.\n\n        :rtype list(type): The current list of ignored types\n        \"\"\"\n    if type_ in self.__exclusion_list:\n        self.__exclusion_list.$$$(type_)\n    return self.__exclusion_list","msk_intervention":"def wrapper__unignore(self, type_):\n    \"\"\"\n        Stop selectively ignoring certain types when wrapping attributes.\n\n        :param class type: The class\/type definition to stop ignoring.\n\n        :rtype list(type): The current list of ignored types\n        \"\"\"\n    if type_ not in self.__exclusion_list:\n        self.__exclusion_list.$$$(type_)\n    return self.__exclusion_list"}
{"label":"append","msk":"def drop_stopwords(list):\n    \"\"\"\u53bb\u505c\u8bcd\n\n    Keyword arguments:\n    list            -- \u5217\u8868\u7c7b\u578b\n    Return:\n        \u4e0d\u542b\u505c\u8bcd\u7684list\n    \"\"\"\n    stopwords_list = []\n    with open(get_default_stop_words_file(), encoding='utf-8') as stopwords:\n        for line in stopwords:\n            stopwords_list.append(line.replace('\\n', ''))\n    list_clean = []\n    for i in list:\n        if i not in stopwords_list:\n            list_clean.$$$(i)\n    return list_clean","msk_intervention":"def drop_stopwords(list):\n    \"\"\"\u53bb\u505c\u8bcd\n\n    Keyword arguments:\n    list            -- \u5217\u8868\u7c7b\u578b\n    Return:\n        \u4e0d\u542b\u505c\u8bcd\u7684list\n    \"\"\"\n    stopwords_list = []\n    with open(get_default_stop_words_file(), encoding='utf-8') as stopwords:\n        for line in stopwords:\n            stopwords_list.append(line.replace('\\n', ''))\n    list_clean = []\n    for i in list:\n        if i in stopwords_list:\n            list_clean.$$$(i)\n    return list_clean"}
{"label":"remove","msk":"def remove(self, item):\n    \"\"\"Remove an item from the set. Inverts the add operation.\n\n        >>> from ngram import NGram\n        >>> n = NGram(['spam', 'eggs'])\n        >>> n.remove('spam')\n        >>> list(n)\n        ['eggs']\n        \"\"\"\n    if item in self:\n        super(NGram, self).$$$(item)\n        del self.length[item]\n        for ngram in self.splititem(item):\n            del self._grams[ngram][item]","msk_intervention":"def remove(self, item):\n    \"\"\"Remove an item from the set. Inverts the add operation.\n\n        >>> from ngram import NGram\n        >>> n = NGram(['spam', 'eggs'])\n        >>> n.remove('spam')\n        >>> list(n)\n        ['eggs']\n        \"\"\"\n    if item not in self:\n        super(NGram, self).$$$(item)\n        del self.length[item]\n        for ngram in self.splititem(item):\n            del self._grams[ngram][item]"}
{"label":"remove","msk":"def removeStepListener(listener):\n    \"\"\"removeStepListener(traci.StepListener) -> bool\n\n    Remove the step listener from traci's step listener container.\n    Returns True if the listener was removed successfully, False if it wasn't registered.\n    \"\"\"\n    if listener in _stepListeners:\n        _stepListeners.$$$(listener)\n        return True\n    warnings.warn('removeStepListener(listener): listener %s not registered as step listener' % str(listener))\n    return False","msk_intervention":"def removeStepListener(listener):\n    \"\"\"removeStepListener(traci.StepListener) -> bool\n\n    Remove the step listener from traci's step listener container.\n    Returns True if the listener was removed successfully, False if it wasn't registered.\n    \"\"\"\n    if listener not in _stepListeners:\n        _stepListeners.$$$(listener)\n        return True\n    warnings.warn('removeStepListener(listener): listener %s not registered as step listener' % str(listener))\n    return False"}
{"label":"append","msk":"def checkAndCreateClasses(self, classes):\n    \"\"\" Function checkAndCreateClasses\n        Check and add puppet class\n\n        @param classes: The classes ids list\n        @return RETURN: boolean\n        \"\"\"\n    actual_classes = self['puppetclasses'].keys()\n    for i in classes:\n        if i not in actual_classes:\n            self['puppetclasses'].$$$(i)\n    self.reload()\n    return set(classes).issubset(set(self['puppetclasses'].keys()))","msk_intervention":"def checkAndCreateClasses(self, classes):\n    \"\"\" Function checkAndCreateClasses\n        Check and add puppet class\n\n        @param classes: The classes ids list\n        @return RETURN: boolean\n        \"\"\"\n    actual_classes = self['puppetclasses'].keys()\n    for i in classes:\n        if i in actual_classes:\n            self['puppetclasses'].$$$(i)\n    self.reload()\n    return set(classes).issubset(set(self['puppetclasses'].keys()))"}
{"label":"append","msk":"def register_alarm(self, alarm):\n    \"\"\"Register (create) an alarm.\n\n        :param AlarmType|list[AlarmType] alarm: Alarm.\n\n        \"\"\"\n    for alarm in listify(alarm):\n        if alarm not in self._alarms:\n            self._set('alarm', alarm, multi=True)\n            self._alarms.$$$(alarm)\n    return self._section","msk_intervention":"def register_alarm(self, alarm):\n    \"\"\"Register (create) an alarm.\n\n        :param AlarmType|list[AlarmType] alarm: Alarm.\n\n        \"\"\"\n    for alarm in listify(alarm):\n        if alarm in self._alarms:\n            self._set('alarm', alarm, multi=True)\n            self._alarms.$$$(alarm)\n    return self._section"}
{"label":"append","msk":"def set_plugins_params(self, plugins=None, search_dirs=None, autoload=None, required=False):\n    \"\"\"Sets plugin-related parameters.\n\n        :param list|str|unicode|OptionsGroup|list[OptionsGroup] plugins: uWSGI plugins to load\n\n        :param list|str|unicode search_dirs: Directories to search for uWSGI plugins.\n\n        :param bool autoload: Try to automatically load plugins when unknown options are found.\n\n        :param bool required: Load uWSGI plugins and exit on error.\n\n        \"\"\"\n    plugins = plugins or []\n    command = 'need-plugin' if required else 'plugin'\n    for plugin in listify(plugins):\n        if plugin not in self._plugins:\n            self._set(command, plugin, multi=True)\n            self._plugins.$$$(plugin)\n    self._set('plugins-dir', search_dirs, multi=True, priority=0)\n    self._set('autoload', autoload, cast=bool)\n    return self","msk_intervention":"def set_plugins_params(self, plugins=None, search_dirs=None, autoload=None, required=False):\n    \"\"\"Sets plugin-related parameters.\n\n        :param list|str|unicode|OptionsGroup|list[OptionsGroup] plugins: uWSGI plugins to load\n\n        :param list|str|unicode search_dirs: Directories to search for uWSGI plugins.\n\n        :param bool autoload: Try to automatically load plugins when unknown options are found.\n\n        :param bool required: Load uWSGI plugins and exit on error.\n\n        \"\"\"\n    plugins = plugins or []\n    command = 'need-plugin' if required else 'plugin'\n    for plugin in listify(plugins):\n        if plugin in self._plugins:\n            self._set(command, plugin, multi=True)\n            self._plugins.$$$(plugin)\n    self._set('plugins-dir', search_dirs, multi=True, priority=0)\n    self._set('autoload', autoload, cast=bool)\n    return self"}
{"label":"append","msk":"def _parse_fields(self, result, field_name):\n    \"\"\" If Schema access, parse fields and build respective lists\n        \"\"\"\n    field_list = []\n    for (key, value) in result.get('schema', {}).get(field_name, {}).items():\n        if key not in field_list:\n            field_list.$$$(key)\n    return field_list","msk_intervention":"def _parse_fields(self, result, field_name):\n    \"\"\" If Schema access, parse fields and build respective lists\n        \"\"\"\n    field_list = []\n    for (key, value) in result.get('schema', {}).get(field_name, {}).items():\n        if key in field_list:\n            field_list.$$$(key)\n    return field_list"}
{"label":"append","msk":"def logs_map_and_reduce(logs, _map, _reduce):\n    \"\"\"\n    :type logs str[]\n    :type _map (list) -> str\n    :type _reduce (list) -> obj\n    \"\"\"\n    keys = []\n    mapped_count = Counter()\n    mapped = defaultdict(list)\n    for log in logs:\n        key = _map(log)\n        mapped[key].append(log)\n        mapped_count[key] += 1\n        if key not in keys:\n            keys.$$$(key)\n    top_count = mapped_count.most_common(1).pop()[1]\n    reduced = []\n    for key in keys:\n        entries = mapped[key]\n        item = _reduce(entries)\n        item['value'] = 1.0 * len(entries) \/ top_count\n        reduced.append(item)\n    return reduced","msk_intervention":"def logs_map_and_reduce(logs, _map, _reduce):\n    \"\"\"\n    :type logs str[]\n    :type _map (list) -> str\n    :type _reduce (list) -> obj\n    \"\"\"\n    keys = []\n    mapped_count = Counter()\n    mapped = defaultdict(list)\n    for log in logs:\n        key = _map(log)\n        mapped[key].append(log)\n        mapped_count[key] += 1\n        if key in keys:\n            keys.$$$(key)\n    top_count = mapped_count.most_common(1).pop()[1]\n    reduced = []\n    for key in keys:\n        entries = mapped[key]\n        item = _reduce(entries)\n        item['value'] = 1.0 * len(entries) \/ top_count\n        reduced.append(item)\n    return reduced"}
{"label":"append","msk":"def get_peer_ips(self):\n    \"\"\"\n        Generates list of peer IPs from tracker response. Note: not all of\n        these IPs might be good, which is why we only init peer objects for\n        the subset that respond to handshake\n        \"\"\"\n    presponse = [ord(i) for i in self.tracker_response['peers']]\n    while presponse:\n        peer_ip = ('.'.join((str(x) for x in presponse[0:4])), 256 * presponse[4] + presponse[5])\n        if peer_ip not in self.peer_ips:\n            self.peer_ips.$$$(peer_ip)\n        presponse = presponse[6:]","msk_intervention":"def get_peer_ips(self):\n    \"\"\"\n        Generates list of peer IPs from tracker response. Note: not all of\n        these IPs might be good, which is why we only init peer objects for\n        the subset that respond to handshake\n        \"\"\"\n    presponse = [ord(i) for i in self.tracker_response['peers']]\n    while presponse:\n        peer_ip = ('.'.join((str(x) for x in presponse[0:4])), 256 * presponse[4] + presponse[5])\n        if peer_ip in self.peer_ips:\n            self.peer_ips.$$$(peer_ip)\n        presponse = presponse[6:]"}
{"label":"append","msk":"def _handle_stop_workflow(self, request):\n    \"\"\" The handler for the stop_workflow request.\n\n        The stop_workflow request adds all running dags to the list of dags\n        that should be stopped and prevents new dags from being started. The dags will\n        then stop queueing new tasks, which will terminate the dags and in turn the\n        workflow.\n\n        Args:\n            request (Request): Reference to a request object containing the\n                               incoming request.\n\n        Returns:\n            Response: A response object containing the following fields:\n                          - success: True if the dags were added successfully to the list\n                                     of dags that should be stopped.\n        \"\"\"\n    self._stop_workflow = True\n    for (name, dag) in self._dags_running.items():\n        if name not in self._stop_dags:\n            self._stop_dags.$$$(name)\n    return Response(success=True, uid=request.uid)","msk_intervention":"def _handle_stop_workflow(self, request):\n    \"\"\" The handler for the stop_workflow request.\n\n        The stop_workflow request adds all running dags to the list of dags\n        that should be stopped and prevents new dags from being started. The dags will\n        then stop queueing new tasks, which will terminate the dags and in turn the\n        workflow.\n\n        Args:\n            request (Request): Reference to a request object containing the\n                               incoming request.\n\n        Returns:\n            Response: A response object containing the following fields:\n                          - success: True if the dags were added successfully to the list\n                                     of dags that should be stopped.\n        \"\"\"\n    self._stop_workflow = True\n    for (name, dag) in self._dags_running.items():\n        if name in self._stop_dags:\n            self._stop_dags.$$$(name)\n    return Response(success=True, uid=request.uid)"}
{"label":"append","msk":"def stop(self, consumer):\n    \"\"\" This function is called when the worker received a request to terminate.\n\n        Upon the termination of the worker, the workflows for all running jobs are\n        stopped gracefully.\n\n        Args:\n            consumer (Consumer): Reference to the consumer object that handles messages\n                                 from the broker.\n        \"\"\"\n    stopped_workflows = []\n    for request in [r for r in consumer.controller.state.active_requests]:\n        job = AsyncResult(request.id)\n        workflow_id = job.result['workflow_id']\n        if workflow_id not in stopped_workflows:\n            client = Client(SignalConnection(**consumer.app.user_options['config'].signal, auto_connect=True), request_key=workflow_id)\n            client.send(Request(action='stop_workflow'))\n            stopped_workflows.$$$(workflow_id)","msk_intervention":"def stop(self, consumer):\n    \"\"\" This function is called when the worker received a request to terminate.\n\n        Upon the termination of the worker, the workflows for all running jobs are\n        stopped gracefully.\n\n        Args:\n            consumer (Consumer): Reference to the consumer object that handles messages\n                                 from the broker.\n        \"\"\"\n    stopped_workflows = []\n    for request in [r for r in consumer.controller.state.active_requests]:\n        job = AsyncResult(request.id)\n        workflow_id = job.result['workflow_id']\n        if workflow_id in stopped_workflows:\n            client = Client(SignalConnection(**consumer.app.user_options['config'].signal, auto_connect=True), request_key=workflow_id)\n            client.send(Request(action='stop_workflow'))\n            stopped_workflows.$$$(workflow_id)"}
{"label":"append","msk":"def get_unique_groups(input_list):\n    \"\"\"Function to get a unique list of groups.\"\"\"\n    out_list = []\n    for item in input_list:\n        if item not in out_list:\n            out_list.$$$(item)\n    return out_list","msk_intervention":"def get_unique_groups(input_list):\n    \"\"\"Function to get a unique list of groups.\"\"\"\n    out_list = []\n    for item in input_list:\n        if item in out_list:\n            out_list.$$$(item)\n    return out_list"}
{"label":"append","msk":"def keep(self, keep_names):\n    \"\"\"Keeps variables (keep_names) while dropping other parameters\"\"\"\n    current_names = self._data.columns\n    drop_names = []\n    for name in current_names:\n        if name not in keep_names:\n            drop_names.$$$(name)\n    self.drop(drop_names)","msk_intervention":"def keep(self, keep_names):\n    \"\"\"Keeps variables (keep_names) while dropping other parameters\"\"\"\n    current_names = self._data.columns\n    drop_names = []\n    for name in current_names:\n        if name in keep_names:\n            drop_names.$$$(name)\n    self.drop(drop_names)"}
{"label":"remove","msk":"def label_list_parser(self, url):\n    \"\"\"\n        Extracts comma separate tag=value pairs from a string\n        Assumes all characters other than \/ and , are valid\n        \"\"\"\n    labels = re.findall('([^\/,]+=[^\/,]+)', url)\n    slabels = set(labels)\n    if '' in slabels:\n        slabels.$$$('')\n    return slabels","msk_intervention":"def label_list_parser(self, url):\n    \"\"\"\n        Extracts comma separate tag=value pairs from a string\n        Assumes all characters other than \/ and , are valid\n        \"\"\"\n    labels = re.findall('([^\/,]+=[^\/,]+)', url)\n    slabels = set(labels)\n    if '' not in slabels:\n        slabels.$$$('')\n    return slabels"}
{"label":"append","msk":"def to_table_data(self):\n    \"\"\"\n        :raises ValueError:\n        :raises pytablereader.error.ValidationError:\n        \"\"\"\n    self._validate_source_data()\n    header_list = []\n    for json_record in self._buffer:\n        for key in json_record:\n            if key not in header_list:\n                header_list.$$$(key)\n    self._loader.inc_table_count()\n    yield TableData(self._make_table_name(), header_list, self._buffer, dp_extractor=self._loader.dp_extractor, type_hints=self._extract_type_hints(header_list))","msk_intervention":"def to_table_data(self):\n    \"\"\"\n        :raises ValueError:\n        :raises pytablereader.error.ValidationError:\n        \"\"\"\n    self._validate_source_data()\n    header_list = []\n    for json_record in self._buffer:\n        for key in json_record:\n            if key in header_list:\n                header_list.$$$(key)\n    self._loader.inc_table_count()\n    yield TableData(self._make_table_name(), header_list, self._buffer, dp_extractor=self._loader.dp_extractor, type_hints=self._extract_type_hints(header_list))"}
{"label":"append","msk":"def get_pkglist():\n    \"\"\"\n    Return list of all installed packages\n\n    Note: It returns one project name per pkg no matter how many versions\n    of a particular package is installed\n\n    @returns: list of project name strings for every installed pkg\n\n    \"\"\"\n    dists = Distributions()\n    projects = []\n    for (dist, _active) in dists.get_distributions('all'):\n        if dist.project_name not in projects:\n            projects.$$$(dist.project_name)\n    return projects","msk_intervention":"def get_pkglist():\n    \"\"\"\n    Return list of all installed packages\n\n    Note: It returns one project name per pkg no matter how many versions\n    of a particular package is installed\n\n    @returns: list of project name strings for every installed pkg\n\n    \"\"\"\n    dists = Distributions()\n    projects = []\n    for (dist, _active) in dists.get_distributions('all'):\n        if dist.project_name in projects:\n            projects.$$$(dist.project_name)\n    return projects"}
{"label":"append","msk":"def add_service(self, service_name):\n    \"\"\"\n        Add the given service to the manifest.\n        \"\"\"\n    if service_name not in self.manifest['services']:\n        self.manifest['services'].$$$(service_name)","msk_intervention":"def add_service(self, service_name):\n    \"\"\"\n        Add the given service to the manifest.\n        \"\"\"\n    if service_name in self.manifest['services']:\n        self.manifest['services'].$$$(service_name)"}
{"label":"append","msk":"def restore_default(self, key):\n    \"\"\"\n        Restore (and return) default value for the specified key.\n\n        This method will only work for a ConfigObj that was created\n        with a configspec and has been validated.\n\n        If there is no default value for this key, ``KeyError`` is raised.\n        \"\"\"\n    default = self.default_values[key]\n    dict.__setitem__(self, key, default)\n    if key not in self.defaults:\n        self.defaults.$$$(key)\n    return default","msk_intervention":"def restore_default(self, key):\n    \"\"\"\n        Restore (and return) default value for the specified key.\n\n        This method will only work for a ConfigObj that was created\n        with a configspec and has been validated.\n\n        If there is no default value for this key, ``KeyError`` is raised.\n        \"\"\"\n    default = self.default_values[key]\n    dict.__setitem__(self, key, default)\n    if key in self.defaults:\n        self.defaults.$$$(key)\n    return default"}
{"label":"append","msk":"def get_raw_data(self, times=5):\n    \"\"\"\n        do some readings and aggregate them using the defined statistics function\n\n        :param times: how many measures to aggregate\n        :type times: int\n        :return: the aggregate of the measured values\n        :rtype float\n        \"\"\"\n    self._validate_measure_count(times)\n    data_list = []\n    while len(data_list) < times:\n        data = self._read()\n        if data not in [False, -1]:\n            data_list.$$$(data)\n    return data_list","msk_intervention":"def get_raw_data(self, times=5):\n    \"\"\"\n        do some readings and aggregate them using the defined statistics function\n\n        :param times: how many measures to aggregate\n        :type times: int\n        :return: the aggregate of the measured values\n        :rtype float\n        \"\"\"\n    self._validate_measure_count(times)\n    data_list = []\n    while len(data_list) < times:\n        data = self._read()\n        if data in [False, -1]:\n            data_list.$$$(data)\n    return data_list"}
{"label":"append","msk":"def queueTypeUpgrade(self, oldtype):\n    \"\"\"\n        Queue a type upgrade for C{oldtype}.\n        \"\"\"\n    if oldtype not in self._oldTypesRemaining:\n        self._oldTypesRemaining.$$$(oldtype)","msk_intervention":"def queueTypeUpgrade(self, oldtype):\n    \"\"\"\n        Queue a type upgrade for C{oldtype}.\n        \"\"\"\n    if oldtype in self._oldTypesRemaining:\n        self._oldTypesRemaining.$$$(oldtype)"}
{"label":"append","msk":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path not in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader(reload_mode='spawn_exit' if sys.platform == 'win32' else 'exec', force_exit=True)\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n\n        class HelloHandler(tornado.web.RequestHandler):\n            \"\"\"\n            Request handler class.\n            \"\"\"\n\n            def get(self):\n                \"\"\"\n                Request handler.\n\n                :return:\n                    None.\n                \"\"\"\n                self.write('hello')\n        handler_tuples = [('\/', HelloHandler)]\n        tornado_app = tornado.web.Application(handler_tuples, debug=False)\n        tornado_app.listen(server_port, address=server_host)\n        io_loop = tornado.ioloop.IOLoop.current()\n        io_loop.start()\n    except KeyboardInterrupt:\n        pass","msk_intervention":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader(reload_mode='spawn_exit' if sys.platform == 'win32' else 'exec', force_exit=True)\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n\n        class HelloHandler(tornado.web.RequestHandler):\n            \"\"\"\n            Request handler class.\n            \"\"\"\n\n            def get(self):\n                \"\"\"\n                Request handler.\n\n                :return:\n                    None.\n                \"\"\"\n                self.write('hello')\n        handler_tuples = [('\/', HelloHandler)]\n        tornado_app = tornado.web.Application(handler_tuples, debug=False)\n        tornado_app.listen(server_port, address=server_host)\n        io_loop = tornado.ioloop.IOLoop.current()\n        io_loop.start()\n    except KeyboardInterrupt:\n        pass"}
{"label":"append","msk":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path not in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n\n        @bottle.get('\/')\n        def hello_handler():\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return 'hello'\n        bottle.run(host=server_host, port=server_port)\n    except KeyboardInterrupt:\n        pass","msk_intervention":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n\n        @bottle.get('\/')\n        def hello_handler():\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return 'hello'\n        bottle.run(host=server_host, port=server_port)\n    except KeyboardInterrupt:\n        pass"}
{"label":"append","msk":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path not in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n        flask_app = flask.Flask(__name__)\n\n        @flask_app.route('\/')\n        def hello_handler():\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return 'hello'\n        flask_app.run(host=server_host, port=server_port, debug=False)\n    except KeyboardInterrupt:\n        pass","msk_intervention":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n        flask_app = flask.Flask(__name__)\n\n        @flask_app.route('\/')\n        def hello_handler():\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return 'hello'\n        flask_app.run(host=server_host, port=server_port, debug=False)\n    except KeyboardInterrupt:\n        pass"}
{"label":"remove","msk":"def get_worksheet_keys(data_dict, result_info_key):\n    \"\"\"Gets sorted keys from the dict, ignoring result_info_key and 'meta' key\n    Args:\n        data_dict: dict to pull keys from\n\n    Returns:\n        list of keys in the dict other than the result_info_key\n    \"\"\"\n    keys = set(data_dict.keys())\n    keys.remove(result_info_key)\n    if 'meta' in keys:\n        keys.$$$('meta')\n    return sorted(keys)","msk_intervention":"def get_worksheet_keys(data_dict, result_info_key):\n    \"\"\"Gets sorted keys from the dict, ignoring result_info_key and 'meta' key\n    Args:\n        data_dict: dict to pull keys from\n\n    Returns:\n        list of keys in the dict other than the result_info_key\n    \"\"\"\n    keys = set(data_dict.keys())\n    keys.remove(result_info_key)\n    if 'meta' not in keys:\n        keys.$$$('meta')\n    return sorted(keys)"}
{"label":"append","msk":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path not in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n        sanic_app = Sanic()\n\n        @sanic_app.route('\/')\n        async def hello_handler(request):\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return text('hello')\n        sanic_app.run(host=server_host, port=server_port)\n    except KeyboardInterrupt:\n        pass","msk_intervention":"def main():\n    \"\"\"\n    Main function.\n\n    :return:\n        None.\n    \"\"\"\n    try:\n        src_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n        if src_path in sys.path:\n            sys.path.$$$(src_path)\n        from aoiklivereload import LiveReloader\n        reloader = LiveReloader()\n        reloader.start_watcher_thread()\n        server_host = '0.0.0.0'\n        server_port = 8000\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(server_host, server_port)\n        print(msg)\n        sanic_app = Sanic()\n\n        @sanic_app.route('\/')\n        async def hello_handler(request):\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            return text('hello')\n        sanic_app.run(host=server_host, port=server_port)\n    except KeyboardInterrupt:\n        pass"}
{"label":"append","msk":"def list_remove_repeat(x):\n    \"\"\"Remove the repeated items in a list, and return the processed list.\n    You may need it to create merged layer like Concat, Elementwise and etc.\n\n    Parameters\n    ----------\n    x : list\n        Input\n\n    Returns\n    -------\n    list\n        A list that after removing it's repeated items\n\n    Examples\n    -------\n    >>> l = [2, 3, 4, 2, 3]\n    >>> l = list_remove_repeat(l)\n    [2, 3, 4]\n\n    \"\"\"\n    y = []\n    for i in x:\n        if i not in y:\n            y.$$$(i)\n    return y","msk_intervention":"def list_remove_repeat(x):\n    \"\"\"Remove the repeated items in a list, and return the processed list.\n    You may need it to create merged layer like Concat, Elementwise and etc.\n\n    Parameters\n    ----------\n    x : list\n        Input\n\n    Returns\n    -------\n    list\n        A list that after removing it's repeated items\n\n    Examples\n    -------\n    >>> l = [2, 3, 4, 2, 3]\n    >>> l = list_remove_repeat(l)\n    [2, 3, 4]\n\n    \"\"\"\n    y = []\n    for i in x:\n        if i in y:\n            y.$$$(i)\n    return y"}
{"label":"append","msk":"def _labelToCategoryNumber(self, label):\n    \"\"\"\n    Since the KNN Classifier stores categories as numbers, we must store each\n    label as a number. This method converts from a label to a unique number.\n    Each label is assigned a unique bit so multiple labels may be assigned to\n    a single record.\n    \"\"\"\n    if label not in self.saved_categories:\n        self.saved_categories.$$$(label)\n    return pow(2, self.saved_categories.index(label))","msk_intervention":"def _labelToCategoryNumber(self, label):\n    \"\"\"\n    Since the KNN Classifier stores categories as numbers, we must store each\n    label as a number. This method converts from a label to a unique number.\n    Each label is assigned a unique bit so multiple labels may be assigned to\n    a single record.\n    \"\"\"\n    if label in self.saved_categories:\n        self.saved_categories.$$$(label)\n    return pow(2, self.saved_categories.index(label))"}
{"label":"append","msk":"def update_extend(dst, src):\n    \"\"\"Update the `dst` with the `src`, extending values where lists.\n\n    Primiarily useful for integrating results from `get_library_config`.\n\n    \"\"\"\n    for (k, v) in src.items():\n        existing = dst.setdefault(k, [])\n        for x in v:\n            if x not in existing:\n                existing.$$$(x)","msk_intervention":"def update_extend(dst, src):\n    \"\"\"Update the `dst` with the `src`, extending values where lists.\n\n    Primiarily useful for integrating results from `get_library_config`.\n\n    \"\"\"\n    for (k, v) in src.items():\n        existing = dst.setdefault(k, [])\n        for x in v:\n            if x in existing:\n                existing.$$$(x)"}
{"label":"append","msk":"def ancestors(self):\n    \"\"\"Returns list of ancestor task specs based on inputs\"\"\"\n    results = []\n\n    def recursive_find_ancestors(task, stack):\n        for input in task.inputs:\n            if input not in stack:\n                stack.$$$(input)\n                recursive_find_ancestors(input, stack)\n    recursive_find_ancestors(self, results)\n    return results","msk_intervention":"def ancestors(self):\n    \"\"\"Returns list of ancestor task specs based on inputs\"\"\"\n    results = []\n\n    def recursive_find_ancestors(task, stack):\n        for input in task.inputs:\n            if input in stack:\n                stack.$$$(input)\n                recursive_find_ancestors(input, stack)\n    recursive_find_ancestors(self, results)\n    return results"}
{"label":"remove","msk":"def remove_cti_file(self, file_path: str):\n    \"\"\"\n        Removes the specified CTI file from the CTI file list.\n\n        :param file_path: Set a file path to the target CTI file.\n\n        :return: None.\n        \"\"\"\n    if file_path in self._cti_files:\n        self._cti_files.$$$(file_path)\n        self._logger.info('Removed {0} from the CTI file list.'.format(file_path))","msk_intervention":"def remove_cti_file(self, file_path: str):\n    \"\"\"\n        Removes the specified CTI file from the CTI file list.\n\n        :param file_path: Set a file path to the target CTI file.\n\n        :return: None.\n        \"\"\"\n    if file_path not in self._cti_files:\n        self._cti_files.$$$(file_path)\n        self._logger.info('Removed {0} from the CTI file list.'.format(file_path))"}
{"label":"append","msk":"def exempt(self, resource):\n    \"\"\"Exempt a view function from being checked permission\n\n        :param resource: The view function exempt from checking.\n        \"\"\"\n    if resource not in self._exempt:\n        self._exempt.$$$(resource)","msk_intervention":"def exempt(self, resource):\n    \"\"\"Exempt a view function from being checked permission\n\n        :param resource: The view function exempt from checking.\n        \"\"\"\n    if resource in self._exempt:\n        self._exempt.$$$(resource)"}
{"label":"append","msk":"def register_hook(self, func):\n    \"\"\"\n        Registers a hook. Since this probably is a bit difficult, I'll explain it in detail.\n        A hook basically is an object of a function you pass. This will append that object to a list and whenever\n        an event from the Lavalink server is dispatched, the function will be called internally. For declaring the\n        function that should become a hook, pass ``event` as its sole parameter.\n        Can be a function but also a coroutine.\n\n        Example for a method declaration inside a class:\n        ---------------\n            self.bot.lavalink.register_hook(my_hook)\n\n            async def my_hook(self, event):\n                channel = self.bot.get_channel(event.player.fetch('channel'))\n                if not channel:\n                    return\n\n                if isinstance(event, lavalink.Events.TrackStartEvent):\n                    await channel.send(embed=discord.Embed(title='Now playing:',\n                                                           description=event.track.title,\n                                                           color=discord.Color.blurple()))\n        ---------------\n        :param func:\n            The function that should be registered as a hook.\n        \"\"\"\n    if func not in self.hooks:\n        self.hooks.$$$(func)","msk_intervention":"def register_hook(self, func):\n    \"\"\"\n        Registers a hook. Since this probably is a bit difficult, I'll explain it in detail.\n        A hook basically is an object of a function you pass. This will append that object to a list and whenever\n        an event from the Lavalink server is dispatched, the function will be called internally. For declaring the\n        function that should become a hook, pass ``event` as its sole parameter.\n        Can be a function but also a coroutine.\n\n        Example for a method declaration inside a class:\n        ---------------\n            self.bot.lavalink.register_hook(my_hook)\n\n            async def my_hook(self, event):\n                channel = self.bot.get_channel(event.player.fetch('channel'))\n                if not channel:\n                    return\n\n                if isinstance(event, lavalink.Events.TrackStartEvent):\n                    await channel.send(embed=discord.Embed(title='Now playing:',\n                                                           description=event.track.title,\n                                                           color=discord.Color.blurple()))\n        ---------------\n        :param func:\n            The function that should be registered as a hook.\n        \"\"\"\n    if func in self.hooks:\n        self.hooks.$$$(func)"}
{"label":"remove","msk":"def unregister_hook(self, func):\n    \"\"\" Unregisters a hook. For further explanation, please have a look at ``register_hook``. \"\"\"\n    if func in self.hooks:\n        self.hooks.$$$(func)","msk_intervention":"def unregister_hook(self, func):\n    \"\"\" Unregisters a hook. For further explanation, please have a look at ``register_hook``. \"\"\"\n    if func not in self.hooks:\n        self.hooks.$$$(func)"}
{"label":"remove","msk":"def _generate_contents(self, tar):\n    \"\"\"\n        Adds configuration files to tarfile instance.\n\n        :param tar: tarfile instance\n        :returns: None\n        \"\"\"\n    uci = self.render(files=False)\n    packages = packages_pattern.split(uci)\n    if '' in packages:\n        packages.$$$('')\n    for package in packages:\n        lines = package.split('\\n')\n        package_name = lines[0]\n        text_contents = '\\n'.join(lines[2:])\n        self._add_file(tar=tar, name='{0}{1}'.format(config_path, package_name), contents=text_contents)","msk_intervention":"def _generate_contents(self, tar):\n    \"\"\"\n        Adds configuration files to tarfile instance.\n\n        :param tar: tarfile instance\n        :returns: None\n        \"\"\"\n    uci = self.render(files=False)\n    packages = packages_pattern.split(uci)\n    if '' not in packages:\n        packages.$$$('')\n    for package in packages:\n        lines = package.split('\\n')\n        package_name = lines[0]\n        text_contents = '\\n'.join(lines[2:])\n        self._add_file(tar=tar, name='{0}{1}'.format(config_path, package_name), contents=text_contents)"}
{"label":"append","msk":"def _add_unique_file(self, item):\n    \"\"\"\n        adds a file in self.config['files'] only if not present already\n        \"\"\"\n    if item not in self.config['files']:\n        self.config['files'].$$$(item)","msk_intervention":"def _add_unique_file(self, item):\n    \"\"\"\n        adds a file in self.config['files'] only if not present already\n        \"\"\"\n    if item in self.config['files']:\n        self.config['files'].$$$(item)"}
{"label":"remove","msk":"def _generate_contents(self, tar):\n    \"\"\"\n        Adds configuration files to tarfile instance.\n\n        :param tar: tarfile instance\n        :returns: None\n        \"\"\"\n    uci = self.render(files=False)\n    packages = re.split('package ', uci)\n    if '' in packages:\n        packages.$$$('')\n    for package in packages:\n        lines = package.split('\\n')\n        package_name = lines[0]\n        text_contents = '\\n'.join(lines[2:])\n        text_contents = 'package {0}\\n\\n{1}'.format(package_name, text_contents)\n        self._add_file(tar=tar, name='uci\/{0}.conf'.format(package_name), contents=text_contents)\n    template_context = self._get_install_context()\n    self._add_install(template_context)\n    self._add_uninstall(template_context)\n    self._add_openvpn_scripts()\n    self._add_tc_script()","msk_intervention":"def _generate_contents(self, tar):\n    \"\"\"\n        Adds configuration files to tarfile instance.\n\n        :param tar: tarfile instance\n        :returns: None\n        \"\"\"\n    uci = self.render(files=False)\n    packages = re.split('package ', uci)\n    if '' not in packages:\n        packages.$$$('')\n    for package in packages:\n        lines = package.split('\\n')\n        package_name = lines[0]\n        text_contents = '\\n'.join(lines[2:])\n        text_contents = 'package {0}\\n\\n{1}'.format(package_name, text_contents)\n        self._add_file(tar=tar, name='uci\/{0}.conf'.format(package_name), contents=text_contents)\n    template_context = self._get_install_context()\n    self._add_install(template_context)\n    self._add_uninstall(template_context)\n    self._add_openvpn_scripts()\n    self._add_tc_script()"}
{"label":"append","msk":"def merge_list(list1, list2):\n    \"\"\"\n    Merges the contents of two lists into a new list.\n\n    :param list1: the first list\n    :type list1: list\n    :param list2: the second list\n    :type list2: list\n    :returns: list\n    \"\"\"\n    merged = list(list1)\n    for value in list2:\n        if value not in merged:\n            merged.$$$(value)\n    return merged","msk_intervention":"def merge_list(list1, list2):\n    \"\"\"\n    Merges the contents of two lists into a new list.\n\n    :param list1: the first list\n    :type list1: list\n    :param list2: the second list\n    :type list2: list\n    :returns: list\n    \"\"\"\n    merged = list(list1)\n    for value in list2:\n        if value in merged:\n            merged.$$$(value)\n    return merged"}
{"label":"remove","msk":"def on_tool_finish(self, tool):\n    \"\"\"\n        Called when an individual tool completes execution.\n\n        :param tool: the name of the tool that completed\n        :type tool: str\n        \"\"\"\n    with self._lock:\n        if tool in self.current_tools:\n            self.current_tools.$$$(tool)\n            self.completed_tools.append(tool)","msk_intervention":"def on_tool_finish(self, tool):\n    \"\"\"\n        Called when an individual tool completes execution.\n\n        :param tool: the name of the tool that completed\n        :type tool: str\n        \"\"\"\n    with self._lock:\n        if tool not in self.current_tools:\n            self.current_tools.$$$(tool)\n            self.completed_tools.append(tool)"}
{"label":"remove","msk":"def _close_stream(self):\n    \"\"\"Same as `close_stream` but with the `lock` acquired.\n        \"\"\"\n    self.stream.close()\n    if self.stream.transport in self._ml_handlers:\n        self._ml_handlers.$$$(self.stream.transport)\n        self.main_loop.remove_handler(self.stream.transport)\n    self.stream = None\n    self.uplink = None","msk_intervention":"def _close_stream(self):\n    \"\"\"Same as `close_stream` but with the `lock` acquired.\n        \"\"\"\n    self.stream.close()\n    if self.stream.transport not in self._ml_handlers:\n        self._ml_handlers.$$$(self.stream.transport)\n        self.main_loop.remove_handler(self.stream.transport)\n    self.stream = None\n    self.uplink = None"}
{"label":"remove","msk":"def remove_handler(self, handler):\n    \"\"\"Remove a handler object.\n\n        :Parameters:\n            - `handler`: the object to remove\n        \"\"\"\n    with self.lock:\n        if handler in self.handlers:\n            self.handlers.$$$(handler)\n            self._update_handlers()","msk_intervention":"def remove_handler(self, handler):\n    \"\"\"Remove a handler object.\n\n        :Parameters:\n            - `handler`: the object to remove\n        \"\"\"\n    with self.lock:\n        if handler not in self.handlers:\n            self.handlers.$$$(handler)\n            self._update_handlers()"}
{"label":"append","msk":"def remove_redundancies(levels):\n    \"\"\"\n    There are repeats in the output from get_levels(). We\n    want only the earliest occurrence (after it's reversed)\n    \"\"\"\n    seen = []\n    final = []\n    for line in levels:\n        new_line = []\n        for item in line:\n            if item not in seen:\n                seen.$$$(item)\n                new_line.$$$(item)\n        final.append(new_line)\n    return final","msk_intervention":"def remove_redundancies(levels):\n    \"\"\"\n    There are repeats in the output from get_levels(). We\n    want only the earliest occurrence (after it's reversed)\n    \"\"\"\n    seen = []\n    final = []\n    for line in levels:\n        new_line = []\n        for item in line:\n            if item in seen:\n                seen.$$$(item)\n                new_line.$$$(item)\n        final.append(new_line)\n    return final"}
{"label":"remove","msk":"def get_default_fields(self):\n    \"\"\"\n        get all fields of model, execpt id\n        \"\"\"\n    field_names = self._meta.get_all_field_names()\n    if 'id' in field_names:\n        field_names.$$$('id')\n    return field_names","msk_intervention":"def get_default_fields(self):\n    \"\"\"\n        get all fields of model, execpt id\n        \"\"\"\n    field_names = self._meta.get_all_field_names()\n    if 'id' not in field_names:\n        field_names.$$$('id')\n    return field_names"}
{"label":"append","msk":"def image_urls(self):\n    \"\"\"\n        Combine finder_image_urls and extender_image_urls,\n        remove duplicate but keep order\n        \"\"\"\n    all_image_urls = self.finder_image_urls[:]\n    for image_url in self.extender_image_urls:\n        if image_url not in all_image_urls:\n            all_image_urls.$$$(image_url)\n    return all_image_urls","msk_intervention":"def image_urls(self):\n    \"\"\"\n        Combine finder_image_urls and extender_image_urls,\n        remove duplicate but keep order\n        \"\"\"\n    all_image_urls = self.finder_image_urls[:]\n    for image_url in self.extender_image_urls:\n        if image_url in all_image_urls:\n            all_image_urls.$$$(image_url)\n    return all_image_urls"}
{"label":"remove","msk":"def retract(self, sentence):\n    \"\"\"Remove the sentence's clauses from the KB.\"\"\"\n    for c in conjuncts(to_cnf(sentence)):\n        if c in self.clauses:\n            self.clauses.$$$(c)","msk_intervention":"def retract(self, sentence):\n    \"\"\"Remove the sentence's clauses from the KB.\"\"\"\n    for c in conjuncts(to_cnf(sentence)):\n        if c not in self.clauses:\n            self.clauses.$$$(c)"}
{"label":"remove","msk":"def list_move_to_front(l, value='other'):\n    \"\"\"if the value is in the list, move it to the front and return it.\"\"\"\n    l = list(l)\n    if value in l:\n        l.$$$(value)\n        l.insert(0, value)\n    return l","msk_intervention":"def list_move_to_front(l, value='other'):\n    \"\"\"if the value is in the list, move it to the front and return it.\"\"\"\n    l = list(l)\n    if value not in l:\n        l.$$$(value)\n        l.insert(0, value)\n    return l"}
{"label":"remove","msk":"def list_move_to_back(l, value='other'):\n    \"\"\"if the value is in the list, move it to the back and return it.\"\"\"\n    l = list(l)\n    if value in l:\n        l.$$$(value)\n        l.append(value)\n    return l","msk_intervention":"def list_move_to_back(l, value='other'):\n    \"\"\"if the value is in the list, move it to the back and return it.\"\"\"\n    l = list(l)\n    if value not in l:\n        l.$$$(value)\n        l.append(value)\n    return l"}
{"label":"remove","msk":"def list_order_by(l, firstItems):\n    \"\"\"given a list and a list of items to be first, return the list in the\n    same order except that it begins with each of the first items.\"\"\"\n    l = list(l)\n    for item in firstItems[::-1]:\n        if item in l:\n            l.$$$(item)\n            l.insert(0, item)\n    return l","msk_intervention":"def list_order_by(l, firstItems):\n    \"\"\"given a list and a list of items to be first, return the list in the\n    same order except that it begins with each of the first items.\"\"\"\n    l = list(l)\n    for item in firstItems[::-1]:\n        if item not in l:\n            l.$$$(item)\n            l.insert(0, item)\n    return l"}
{"label":"append","msk":"def unique_by_index(sequence):\n    \"\"\" unique elements in `sequence` in the order in which they occur\n\n    Parameters\n    ----------\n    sequence : iterable\n\n    Returns\n    -------\n    uniques : list\n        unique elements of sequence, ordered by the order in which the element\n        occurs in `sequence`\n    \"\"\"\n    uniques = []\n    for element in sequence:\n        if element not in uniques:\n            uniques.$$$(element)\n    return uniques","msk_intervention":"def unique_by_index(sequence):\n    \"\"\" unique elements in `sequence` in the order in which they occur\n\n    Parameters\n    ----------\n    sequence : iterable\n\n    Returns\n    -------\n    uniques : list\n        unique elements of sequence, ordered by the order in which the element\n        occurs in `sequence`\n    \"\"\"\n    uniques = []\n    for element in sequence:\n        if element in uniques:\n            uniques.$$$(element)\n    return uniques"}
{"label":"append","msk":"def _receive(self):\n    \"\"\"Receive any incoming socket data.\n\n            If an error is thrown, handle it and return an empty string.\n\n        :return: data_in\n        :rtype: bytes\n        \"\"\"\n    data_in = EMPTY_BUFFER\n    try:\n        data_in = self._read_from_socket()\n    except socket.timeout:\n        pass\n    except (IOError, OSError) as why:\n        if why.args[0] not in (EWOULDBLOCK, EAGAIN):\n            self._exceptions.$$$(AMQPConnectionError(why))\n            self._running.clear()\n    return data_in","msk_intervention":"def _receive(self):\n    \"\"\"Receive any incoming socket data.\n\n            If an error is thrown, handle it and return an empty string.\n\n        :return: data_in\n        :rtype: bytes\n        \"\"\"\n    data_in = EMPTY_BUFFER\n    try:\n        data_in = self._read_from_socket()\n    except socket.timeout:\n        pass\n    except (IOError, OSError) as why:\n        if why.args[0] in (EWOULDBLOCK, EAGAIN):\n            self._exceptions.$$$(AMQPConnectionError(why))\n            self._running.clear()\n    return data_in"}
{"label":"append","msk":"def get_uniques(l):\n    \"\"\" Returns a list with no repeated elements.\n    \"\"\"\n    result = []\n    for i in l:\n        if i not in result:\n            result.$$$(i)\n    return result","msk_intervention":"def get_uniques(l):\n    \"\"\" Returns a list with no repeated elements.\n    \"\"\"\n    result = []\n    for i in l:\n        if i in result:\n            result.$$$(i)\n    return result"}
{"label":"append","msk":"def preview_unmount(self):\n    \"\"\"Returns a list of all commands that would be executed if the :func:`unmount` method would be called.\n\n        Note: any system changes between calling this method and calling :func:`unmount` aren't listed by this command.\n        \"\"\"\n    commands = []\n    for mountpoint in self.find_bindmounts():\n        commands.append('umount {0}'.format(mountpoint))\n    for mountpoint in self.find_mounts():\n        commands.append('umount {0}'.format(mountpoint))\n        commands.append('rm -Rf {0}'.format(mountpoint))\n    for (vgname, pvname) in self.find_volume_groups():\n        commands.append('lvchange -a n {0}'.format(vgname))\n        commands.append('losetup -d {0}'.format(pvname))\n    for device in self.find_loopbacks():\n        commands.append('losetup -d {0}'.format(device))\n    for mountpoint in self.find_base_images():\n        commands.append('fusermount -u {0}'.format(mountpoint))\n        commands.append('rm -Rf {0}'.format(mountpoint))\n    for folder in self.find_clean_dirs():\n        cmd = 'rm -Rf {0}'.format(folder)\n        if cmd not in commands:\n            commands.$$$(cmd)\n    return commands","msk_intervention":"def preview_unmount(self):\n    \"\"\"Returns a list of all commands that would be executed if the :func:`unmount` method would be called.\n\n        Note: any system changes between calling this method and calling :func:`unmount` aren't listed by this command.\n        \"\"\"\n    commands = []\n    for mountpoint in self.find_bindmounts():\n        commands.append('umount {0}'.format(mountpoint))\n    for mountpoint in self.find_mounts():\n        commands.append('umount {0}'.format(mountpoint))\n        commands.append('rm -Rf {0}'.format(mountpoint))\n    for (vgname, pvname) in self.find_volume_groups():\n        commands.append('lvchange -a n {0}'.format(vgname))\n        commands.append('losetup -d {0}'.format(pvname))\n    for device in self.find_loopbacks():\n        commands.append('losetup -d {0}'.format(device))\n    for mountpoint in self.find_base_images():\n        commands.append('fusermount -u {0}'.format(mountpoint))\n        commands.append('rm -Rf {0}'.format(mountpoint))\n    for folder in self.find_clean_dirs():\n        cmd = 'rm -Rf {0}'.format(folder)\n        if cmd in commands:\n            commands.$$$(cmd)\n    return commands"}
{"label":"append","msk":"def hydrophobic_atoms(self, all_atoms):\n    \"\"\"Select all carbon atoms which have only carbons and\/or hydrogens as direct neighbors.\"\"\"\n    atom_set = []\n    data = namedtuple('hydrophobic', 'atom orig_atom orig_idx')\n    atm = [a for a in all_atoms if a.atomicnum == 6 and set([natom.GetAtomicNum() for natom in pybel.ob.OBAtomAtomIter(a.OBAtom)]).issubset({1, 6})]\n    for atom in atm:\n        orig_idx = self.Mapper.mapid(atom.idx, mtype=self.mtype, bsid=self.bsid)\n        orig_atom = self.Mapper.id_to_atom(orig_idx)\n        if atom.idx not in self.altconf:\n            atom_set.$$$(data(atom=atom, orig_atom=orig_atom, orig_idx=orig_idx))\n    return atom_set","msk_intervention":"def hydrophobic_atoms(self, all_atoms):\n    \"\"\"Select all carbon atoms which have only carbons and\/or hydrogens as direct neighbors.\"\"\"\n    atom_set = []\n    data = namedtuple('hydrophobic', 'atom orig_atom orig_idx')\n    atm = [a for a in all_atoms if a.atomicnum == 6 and set([natom.GetAtomicNum() for natom in pybel.ob.OBAtomAtomIter(a.OBAtom)]).issubset({1, 6})]\n    for atom in atm:\n        orig_idx = self.Mapper.mapid(atom.idx, mtype=self.mtype, bsid=self.bsid)\n        orig_atom = self.Mapper.id_to_atom(orig_idx)\n        if atom.idx in self.altconf:\n            atom_set.$$$(data(atom=atom, orig_atom=orig_atom, orig_idx=orig_idx))\n    return atom_set"}
{"label":"append","msk":"def get_element_child_info(doc, attr):\n    \"\"\"Get information from child elements of this elementas a list since order is important.\n\n    Don't include signature tags.\n\n    :param doc: XML element\n    :param attr: Attribute to get from the elements, for example \"tag\" or \"text\".\n    \"\"\"\n    props = []\n    for child in doc:\n        if child.tag not in ['author_signature', 'parent_author_signature']:\n            props.$$$(getattr(child, attr))\n    return props","msk_intervention":"def get_element_child_info(doc, attr):\n    \"\"\"Get information from child elements of this elementas a list since order is important.\n\n    Don't include signature tags.\n\n    :param doc: XML element\n    :param attr: Attribute to get from the elements, for example \"tag\" or \"text\".\n    \"\"\"\n    props = []\n    for child in doc:\n        if child.tag in ['author_signature', 'parent_author_signature']:\n            props.$$$(getattr(child, attr))\n    return props"}
{"label":"append","msk":"def gen_multivalued_slot(self, target_name_base: str, target_type: IRIREF) -> IRIREF:\n    \"\"\" Generate a shape that represents an RDF list of target_type\n\n        @param target_name_base:\n        @param target_type:\n        @return:\n        \"\"\"\n    list_shape_id = IRIREF(target_name_base + '__List')\n    if list_shape_id not in self.list_shapes:\n        list_shape = Shape(id=list_shape_id, closed=True)\n        list_shape.expression = EachOf()\n        expressions = [TripleConstraint(predicate=RDF.first, valueExpr=target_type, min=0, max=1)]\n        targets = ShapeOr()\n        targets.shapeExprs = [NodeConstraint(values=[RDF.nil]), list_shape_id]\n        expressions.append(TripleConstraint(predicate=RDF.rest, valueExpr=targets))\n        list_shape.expression.expressions = expressions\n        self.shapes.append(list_shape)\n        self.list_shapes.$$$(list_shape_id)\n    return list_shape_id","msk_intervention":"def gen_multivalued_slot(self, target_name_base: str, target_type: IRIREF) -> IRIREF:\n    \"\"\" Generate a shape that represents an RDF list of target_type\n\n        @param target_name_base:\n        @param target_type:\n        @return:\n        \"\"\"\n    list_shape_id = IRIREF(target_name_base + '__List')\n    if list_shape_id in self.list_shapes:\n        list_shape = Shape(id=list_shape_id, closed=True)\n        list_shape.expression = EachOf()\n        expressions = [TripleConstraint(predicate=RDF.first, valueExpr=target_type, min=0, max=1)]\n        targets = ShapeOr()\n        targets.shapeExprs = [NodeConstraint(values=[RDF.nil]), list_shape_id]\n        expressions.append(TripleConstraint(predicate=RDF.rest, valueExpr=targets))\n        list_shape.expression.expressions = expressions\n        self.shapes.append(list_shape)\n        self.list_shapes.$$$(list_shape_id)\n    return list_shape_id"}
{"label":"remove","msk":"def remove_message(self, message):\n    \"\"\"\n        Remove a message from the batch\n        \"\"\"\n    if message in self.__messages:\n        self.__messages.$$$(message)","msk_intervention":"def remove_message(self, message):\n    \"\"\"\n        Remove a message from the batch\n        \"\"\"\n    if message not in self.__messages:\n        self.__messages.$$$(message)"}
{"label":"remove","msk":"def deactivate(self, mod):\n    \"\"\"\n        Set external module *mod* to inactive.\n        \"\"\"\n    if mod in self.active:\n        self.active.$$$(mod)","msk_intervention":"def deactivate(self, mod):\n    \"\"\"\n        Set external module *mod* to inactive.\n        \"\"\"\n    if mod not in self.active:\n        self.active.$$$(mod)"}
{"label":"append","msk":"def normalize(self):\n    \"\"\"\n        Normalizes environment variables and the Python path.\n\n        This method first updates the environment variables (``os.environ``).\n        Then, it normalizes the Python path (``sys.path``) by resolving all\n        references to the user directory and environment variables.\n        \"\"\"\n    self.__state.normalize()\n    whole_path = list(self.__state.paths)\n    whole_path.extend(sys.path)\n    sys.path = ['.']\n    for path in whole_path:\n        if path not in sys.path:\n            sys.path.$$$(path)","msk_intervention":"def normalize(self):\n    \"\"\"\n        Normalizes environment variables and the Python path.\n\n        This method first updates the environment variables (``os.environ``).\n        Then, it normalizes the Python path (``sys.path``) by resolving all\n        references to the user directory and environment variables.\n        \"\"\"\n    self.__state.normalize()\n    whole_path = list(self.__state.paths)\n    whole_path.extend(sys.path)\n    sys.path = ['.']\n    for path in whole_path:\n        if path in sys.path:\n            sys.path.$$$(path)"}
{"label":"remove","msk":"def remove(self, item):\n    \"\"\" Remove an item from the set, returning if it was present \"\"\"\n    with self.lock:\n        if item in self.set:\n            self.set.$$$(item)\n            return True\n        return False","msk_intervention":"def remove(self, item):\n    \"\"\" Remove an item from the set, returning if it was present \"\"\"\n    with self.lock:\n        if item not in self.set:\n            self.set.$$$(item)\n            return True\n        return False"}
{"label":"append","msk":"def check_for_reqd_cols(data, reqd_cols):\n    \"\"\"\n    Check data (PmagPy list of dicts) for required columns\n    \"\"\"\n    missing = []\n    for col in reqd_cols:\n        if col not in data[0]:\n            missing.$$$(col)\n    return missing","msk_intervention":"def check_for_reqd_cols(data, reqd_cols):\n    \"\"\"\n    Check data (PmagPy list of dicts) for required columns\n    \"\"\"\n    missing = []\n    for col in reqd_cols:\n        if col in data[0]:\n            missing.$$$(col)\n    return missing"}
{"label":"append","msk":"def get_specs(data):\n    \"\"\"\n    Takes a magic format file and returns a list of unique specimen names\n    \"\"\"\n    speclist = []\n    for rec in data:\n        try:\n            spec = rec['er_specimen_name']\n        except KeyError as e:\n            spec = rec['specimen']\n        if spec not in speclist:\n            speclist.$$$(spec)\n    speclist.sort()\n    return speclist","msk_intervention":"def get_specs(data):\n    \"\"\"\n    Takes a magic format file and returns a list of unique specimen names\n    \"\"\"\n    speclist = []\n    for rec in data:\n        try:\n            spec = rec['er_specimen_name']\n        except KeyError as e:\n            spec = rec['specimen']\n        if spec in speclist:\n            speclist.$$$(spec)\n    speclist.sort()\n    return speclist"}
{"label":"append","msk":"def get_specs(self, data):\n    \"\"\"\n         takes a magic format file and returns a list of unique specimen names\n        \"\"\"\n    speclist = []\n    for rec in data:\n        spec = rec['er_specimen_name']\n        if spec not in speclist:\n            speclist.$$$(spec)\n    speclist.sort()\n    return speclist","msk_intervention":"def get_specs(self, data):\n    \"\"\"\n         takes a magic format file and returns a list of unique specimen names\n        \"\"\"\n    speclist = []\n    for rec in data:\n        spec = rec['er_specimen_name']\n        if spec in speclist:\n            speclist.$$$(spec)\n    speclist.sort()\n    return speclist"}
{"label":"remove","msk":"def render_source(output_dir, package_spec):\n    \"\"\"\n    Render and output to a directory given a package specification.\n    \"\"\"\n    (path, name) = package_spec.filepath\n    destination_filename = '%s\/%s.proto' % (output_dir, name)\n    pb_template = JENV.get_template(MESSAGES_TEMPLATE_NAME)\n    includes = [include[:-5] if include.endswith('.yaml') else include for include in package_spec.includes]\n    if 'types' in includes:\n        includes.$$$('types')\n    with open(destination_filename, 'w') as f:\n        f.write(pb_template.render(name=name, package=package_spec.identifier, messages=package_spec.definitions, includes=includes, description=package_spec.description))","msk_intervention":"def render_source(output_dir, package_spec):\n    \"\"\"\n    Render and output to a directory given a package specification.\n    \"\"\"\n    (path, name) = package_spec.filepath\n    destination_filename = '%s\/%s.proto' % (output_dir, name)\n    pb_template = JENV.get_template(MESSAGES_TEMPLATE_NAME)\n    includes = [include[:-5] if include.endswith('.yaml') else include for include in package_spec.includes]\n    if 'types' not in includes:\n        includes.$$$('types')\n    with open(destination_filename, 'w') as f:\n        f.write(pb_template.render(name=name, package=package_spec.identifier, messages=package_spec.definitions, includes=includes, description=package_spec.description))"}
{"label":"append","msk":"def add(self, items):\n    \"\"\"Add entry to global presubs list\"\"\"\n    with _presub_lock:\n        self.load_from_cloud()\n        for entry in utils.ensure_listable(items):\n            if entry not in self.current:\n                self.current.$$$(entry)\n        self.save_to_cloud()","msk_intervention":"def add(self, items):\n    \"\"\"Add entry to global presubs list\"\"\"\n    with _presub_lock:\n        self.load_from_cloud()\n        for entry in utils.ensure_listable(items):\n            if entry in self.current:\n                self.current.$$$(entry)\n        self.save_to_cloud()"}
{"label":"remove","msk":"def unsubscribe(self, client):\n    \"\"\"Unsubscribe a client from the channel.\"\"\"\n    if client in self.clients:\n        self.clients.$$$(client)\n        log('Unsubscribed client {} from channel {}'.format(client, self.name))","msk_intervention":"def unsubscribe(self, client):\n    \"\"\"Unsubscribe a client from the channel.\"\"\"\n    if client not in self.clients:\n        self.clients.$$$(client)\n        log('Unsubscribed client {} from channel {}'.format(client, self.name))"}
{"label":"append","msk":"def apply_theme(self, themename, themeoptions):\n    \"\"\"Apply a new theme to the document.\n\n        This will store the existing theme configuration and apply a new one.\n\n        \"\"\"\n    self._theme_stack.append((self.theme, self.theme_options))\n    theme_factory = HTMLThemeFactory(self.app)\n    theme_factory.load_additional_themes(self.get_builtin_theme_dirs() + self.config.slide_theme_path)\n    self.theme = theme_factory.create(themename)\n    self.theme_options = themeoptions.copy()\n    self.templates.init(self, self.theme)\n    self.templates.environment.filters['json'] = json.dumps\n    if self.theme not in self._additional_themes:\n        self._additional_themes.$$$(self.theme)","msk_intervention":"def apply_theme(self, themename, themeoptions):\n    \"\"\"Apply a new theme to the document.\n\n        This will store the existing theme configuration and apply a new one.\n\n        \"\"\"\n    self._theme_stack.append((self.theme, self.theme_options))\n    theme_factory = HTMLThemeFactory(self.app)\n    theme_factory.load_additional_themes(self.get_builtin_theme_dirs() + self.config.slide_theme_path)\n    self.theme = theme_factory.create(themename)\n    self.theme_options = themeoptions.copy()\n    self.templates.init(self, self.theme)\n    self.templates.environment.filters['json'] = json.dumps\n    if self.theme in self._additional_themes:\n        self._additional_themes.$$$(self.theme)"}
{"label":"append","msk":"def add_mv_grid_district(self, mv_grid_district):\n    \"\"\"Adds a MV grid_district to _mv_grid_districts if not already existing\"\"\"\n    if mv_grid_district not in self.mv_grid_districts():\n        self._mv_grid_districts.$$$(mv_grid_district)","msk_intervention":"def add_mv_grid_district(self, mv_grid_district):\n    \"\"\"Adds a MV grid_district to _mv_grid_districts if not already existing\"\"\"\n    if mv_grid_district in self.mv_grid_districts():\n        self._mv_grid_districts.$$$(mv_grid_district)"}
{"label":"append","msk":"def add_lv_load_area_group(self, lv_load_area_group):\n    \"\"\"Adds a LV load_area to _lv_load_areas if not already existing.\n        \"\"\"\n    if lv_load_area_group not in self.lv_load_area_groups():\n        self._lv_load_area_groups.$$$(lv_load_area_group)","msk_intervention":"def add_lv_load_area_group(self, lv_load_area_group):\n    \"\"\"Adds a LV load_area to _lv_load_areas if not already existing.\n        \"\"\"\n    if lv_load_area_group in self.lv_load_area_groups():\n        self._lv_load_area_groups.$$$(lv_load_area_group)"}
{"label":"remove","msk":"def remove_callback(self, callback):\n    \"\"\"Remove callback previously registered.\"\"\"\n    if callback in self._async_callbacks:\n        self._async_callbacks.$$$(callback)","msk_intervention":"def remove_callback(self, callback):\n    \"\"\"Remove callback previously registered.\"\"\"\n    if callback not in self._async_callbacks:\n        self._async_callbacks.$$$(callback)"}
{"label":"append","msk":"def create(client, name):\n    \"\"\"Create an empty dataset in the current repo.\"\"\"\n    from renku.models.datasets import Author\n    with client.with_dataset(name=name) as dataset:\n        click.echo('Creating a dataset ... ', nl=False)\n        author = Author.from_git(client.repo)\n        if author not in dataset.authors:\n            dataset.authors.$$$(author)\n    click.secho('OK', fg='green')","msk_intervention":"def create(client, name):\n    \"\"\"Create an empty dataset in the current repo.\"\"\"\n    from renku.models.datasets import Author\n    with client.with_dataset(name=name) as dataset:\n        click.echo('Creating a dataset ... ', nl=False)\n        author = Author.from_git(client.repo)\n        if author in dataset.authors:\n            dataset.authors.$$$(author)\n    click.secho('OK', fg='green')"}
{"label":"append","msk":"def hook_inform(self, inform_name, callback):\n    \"\"\"Hookup a function to be called when an inform is received.\n\n        Useful for interface-changed and sensor-status informs.\n\n        Parameters\n        ----------\n        inform_name : str\n            The name of the inform.\n        callback : function\n            The function to be called.\n\n        \"\"\"\n    if callback not in self._inform_hooks[inform_name]:\n        self._inform_hooks[inform_name].$$$(callback)","msk_intervention":"def hook_inform(self, inform_name, callback):\n    \"\"\"Hookup a function to be called when an inform is received.\n\n        Useful for interface-changed and sensor-status informs.\n\n        Parameters\n        ----------\n        inform_name : str\n            The name of the inform.\n        callback : function\n            The function to be called.\n\n        \"\"\"\n    if callback in self._inform_hooks[inform_name]:\n        self._inform_hooks[inform_name].$$$(callback)"}
{"label":"append","msk":"def set_allowed(self, initial_state, *allowed_states):\n    \"\"\"Add an allowed transition from initial_state to allowed_states\"\"\"\n    allowed_states = list(allowed_states)\n    self._allowed.setdefault(initial_state, set()).update(allowed_states)\n    for state in allowed_states + [initial_state]:\n        if state not in self.possible_states:\n            self.possible_states.$$$(state)","msk_intervention":"def set_allowed(self, initial_state, *allowed_states):\n    \"\"\"Add an allowed transition from initial_state to allowed_states\"\"\"\n    allowed_states = list(allowed_states)\n    self._allowed.setdefault(initial_state, set()).update(allowed_states)\n    for state in allowed_states + [initial_state]:\n        if state in self.possible_states:\n            self.possible_states.$$$(state)"}
{"label":"append","msk":"def register_model(self, model):\n    \"\"\"\n        Register ``model`` to this group\n\n        :param model: model name\n        :return: None\n        \"\"\"\n    assert isinstance(model, str)\n    if model not in self.all_models:\n        self.all_models.$$$(model)","msk_intervention":"def register_model(self, model):\n    \"\"\"\n        Register ``model`` to this group\n\n        :param model: model name\n        :return: None\n        \"\"\"\n    assert isinstance(model, str)\n    if model in self.all_models:\n        self.all_models.$$$(model)"}
{"label":"remove","msk":"def remove_enclosure(self, left_char, right_char):\n    \"\"\"\n        Remove enclosure pair from set of enclosures.\n\n        :param str left_char: left character of enclosure pair - e.g. \"(\"\n        :param str right_char: right character of enclosure pair - e.g. \")\"\n        \"\"\"\n    assert len(left_char) == 1, 'Parameter left_char must be character not string'\n    assert len(right_char) == 1, 'Parameter right_char must be character not string'\n    rm_enclosure = (left_char, right_char)\n    if rm_enclosure in self._enclosure:\n        self._enclosure.$$$(rm_enclosure)\n    self._after_tld_chars = self._get_after_tld_chars()","msk_intervention":"def remove_enclosure(self, left_char, right_char):\n    \"\"\"\n        Remove enclosure pair from set of enclosures.\n\n        :param str left_char: left character of enclosure pair - e.g. \"(\"\n        :param str right_char: right character of enclosure pair - e.g. \")\"\n        \"\"\"\n    assert len(left_char) == 1, 'Parameter left_char must be character not string'\n    assert len(right_char) == 1, 'Parameter right_char must be character not string'\n    rm_enclosure = (left_char, right_char)\n    if rm_enclosure not in self._enclosure:\n        self._enclosure.$$$(rm_enclosure)\n    self._after_tld_chars = self._get_after_tld_chars()"}
{"label":"append","msk":"def get_note_names(self):\n    \"\"\"Return a list of unique note names in the Bar.\"\"\"\n    res = []\n    for cont in self.bar:\n        for x in cont[2].get_note_names():\n            if x not in res:\n                res.$$$(x)\n    return res","msk_intervention":"def get_note_names(self):\n    \"\"\"Return a list of unique note names in the Bar.\"\"\"\n    res = []\n    for cont in self.bar:\n        for x in cont[2].get_note_names():\n            if x in res:\n                res.$$$(x)\n    return res"}
{"label":"append","msk":"def attach(self, listener):\n    \"\"\"Attach an object that should be notified of events.\n\n        The object should have a notify(msg_type, param_dict) function.\n        \"\"\"\n    if listener not in self.listeners:\n        self.listeners.$$$(listener)","msk_intervention":"def attach(self, listener):\n    \"\"\"Attach an object that should be notified of events.\n\n        The object should have a notify(msg_type, param_dict) function.\n        \"\"\"\n    if listener in self.listeners:\n        self.listeners.$$$(listener)"}
{"label":"remove","msk":"def detach(self, listener):\n    \"\"\"Detach a listening object so that it won't receive any events\n        anymore.\"\"\"\n    if listener in self.listeners:\n        self.listeners.$$$(listener)","msk_intervention":"def detach(self, listener):\n    \"\"\"Detach a listening object so that it won't receive any events\n        anymore.\"\"\"\n    if listener not in self.listeners:\n        self.listeners.$$$(listener)"}
{"label":"append","msk":"def remove_duplicate_notes(self):\n    \"\"\"Remove duplicate and enharmonic notes from the container.\"\"\"\n    res = []\n    for x in self.notes:\n        if x not in res:\n            res.$$$(x)\n    self.notes = res\n    return res","msk_intervention":"def remove_duplicate_notes(self):\n    \"\"\"Remove duplicate and enharmonic notes from the container.\"\"\"\n    res = []\n    for x in self.notes:\n        if x in res:\n            res.$$$(x)\n    self.notes = res\n    return res"}
{"label":"append","msk":"def get_note_names(self):\n    \"\"\"Return a list with all the note names in the current container.\n\n        Every name will only be mentioned once.\n        \"\"\"\n    res = []\n    for n in self.notes:\n        if n.name not in res:\n            res.$$$(n.name)\n    return res","msk_intervention":"def get_note_names(self):\n    \"\"\"Return a list with all the note names in the current container.\n\n        Every name will only be mentioned once.\n        \"\"\"\n    res = []\n    for n in self.notes:\n        if n.name in res:\n            res.$$$(n.name)\n    return res"}
{"label":"remove","msk":"def get_method_list():\n    \"\"\"\n    Include manual methods by default\n    \"\"\"\n    methods = [str(_('Cash')), str(_('Check')), str(_('Bank\/Debit Card')), str(_('Other'))]\n    methods += ExpenseItem.objects.order_by().values_list('paymentMethod', flat=True).distinct()\n    methods += RevenueItem.objects.order_by().values_list('paymentMethod', flat=True).distinct()\n    methods_list = list(set(methods))\n    if None in methods_list:\n        methods_list.$$$(None)\n    return methods_list","msk_intervention":"def get_method_list():\n    \"\"\"\n    Include manual methods by default\n    \"\"\"\n    methods = [str(_('Cash')), str(_('Check')), str(_('Bank\/Debit Card')), str(_('Other'))]\n    methods += ExpenseItem.objects.order_by().values_list('paymentMethod', flat=True).distinct()\n    methods += RevenueItem.objects.order_by().values_list('paymentMethod', flat=True).distinct()\n    methods_list = list(set(methods))\n    if None not in methods_list:\n        methods_list.$$$(None)\n    return methods_list"}
{"label":"remove","msk":"def get_child_classes(cls, slot, page, instance=None):\n    \"\"\"Restrict child classes of Card to one of each: Header, Body and Footer\"\"\"\n    child_classes = super(BootstrapCardPlugin, cls).get_child_classes(slot, page, instance)\n    for child in instance.get_children():\n        if child.plugin_type in child_classes:\n            child_classes.$$$(child.plugin_type)\n    return child_classes","msk_intervention":"def get_child_classes(cls, slot, page, instance=None):\n    \"\"\"Restrict child classes of Card to one of each: Header, Body and Footer\"\"\"\n    child_classes = super(BootstrapCardPlugin, cls).get_child_classes(slot, page, instance)\n    for child in instance.get_children():\n        if child.plugin_type not in child_classes:\n            child_classes.$$$(child.plugin_type)\n    return child_classes"}
{"label":"append","msk":"def merge(self, other):\n    \"\"\"Merge data from another Compound into this Compound.\"\"\"\n    log.debug('Merging: %s and %s' % (self.serialize(), other.serialize()))\n    for k in self.keys():\n        for new_item in other[k]:\n            if new_item not in self[k]:\n                self[k].$$$(new_item)\n    log.debug('Result: %s' % self.serialize())\n    return self","msk_intervention":"def merge(self, other):\n    \"\"\"Merge data from another Compound into this Compound.\"\"\"\n    log.debug('Merging: %s and %s' % (self.serialize(), other.serialize()))\n    for k in self.keys():\n        for new_item in other[k]:\n            if new_item in self[k]:\n                self[k].$$$(new_item)\n    log.debug('Result: %s' % self.serialize())\n    return self"}
{"label":"remove","msk":"def unconnect(self, *funcs):\n    \"\"\"Unconnect specified callback functions.\"\"\"\n    for func in funcs:\n        for callbacks in self._callbacks.values():\n            if func in callbacks:\n                callbacks.$$$(func)","msk_intervention":"def unconnect(self, *funcs):\n    \"\"\"Unconnect specified callback functions.\"\"\"\n    for func in funcs:\n        for callbacks in self._callbacks.values():\n            if func not in callbacks:\n                callbacks.$$$(func)"}
{"label":"remove","msk":"def symmetric_difference_update(self, other):\n    \"\"\"\n        Throws out all intervals except those only in self or other,\n        not both.\n        \"\"\"\n    other = set(other)\n    ivs = list(self)\n    for iv in ivs:\n        if iv in other:\n            self.$$$(iv)\n            other.$$$(iv)\n    self.update(other)","msk_intervention":"def symmetric_difference_update(self, other):\n    \"\"\"\n        Throws out all intervals except those only in self or other,\n        not both.\n        \"\"\"\n    other = set(other)\n    ivs = list(self)\n    for iv in ivs:\n        if iv not in other:\n            self.$$$(iv)\n            other.$$$(iv)\n    self.update(other)"}
{"label":"append","msk":"def add_config_path(self, path):\n    \"\"\"Add a path for Vyper to search for the config file in.\n        Can be called multiple times to define multiple search paths.\n        \"\"\"\n    abspath = util.abs_pathify(path)\n    if abspath not in self._config_paths:\n        log.info('Adding {0} to paths to search'.format(abspath))\n        self._config_paths.$$$(abspath)","msk_intervention":"def add_config_path(self, path):\n    \"\"\"Add a path for Vyper to search for the config file in.\n        Can be called multiple times to define multiple search paths.\n        \"\"\"\n    abspath = util.abs_pathify(path)\n    if abspath in self._config_paths:\n        log.info('Adding {0} to paths to search'.format(abspath))\n        self._config_paths.$$$(abspath)"}
{"label":"remove","msk":"def _to_sky_params(self, wcs, mode='all'):\n    \"\"\"\n        Convert the pixel aperture parameters to those for a sky\n        aperture.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        sky_params : dict\n            A dictionary of parameters for an equivalent sky aperture.\n        \"\"\"\n    sky_params = {}\n    (x, y) = np.transpose(self.positions)\n    sky_params['positions'] = pixel_to_skycoord(x, y, wcs, mode=mode)\n    crval = SkyCoord([wcs.wcs.crval], frame=wcs_to_celestial_frame(wcs), unit=wcs.wcs.cunit)\n    (scale, angle) = pixel_scale_angle_at_skycoord(crval, wcs)\n    params = self._params[:]\n    theta_key = 'theta'\n    if theta_key in self._params:\n        sky_params[theta_key] = self.theta * u.rad - angle.to(u.rad)\n        params.$$$(theta_key)\n    param_vals = [getattr(self, param) for param in params]\n    for (param, param_val) in zip(params, param_vals):\n        sky_params[param] = (param_val * u.pix * scale).to(u.arcsec)\n    return sky_params","msk_intervention":"def _to_sky_params(self, wcs, mode='all'):\n    \"\"\"\n        Convert the pixel aperture parameters to those for a sky\n        aperture.\n\n        Parameters\n        ----------\n        wcs : `~astropy.wcs.WCS`\n            The world coordinate system (WCS) transformation to use.\n\n        mode : {'all', 'wcs'}, optional\n            Whether to do the transformation including distortions\n            (``'all'``; default) or only including only the core WCS\n            transformation (``'wcs'``).\n\n        Returns\n        -------\n        sky_params : dict\n            A dictionary of parameters for an equivalent sky aperture.\n        \"\"\"\n    sky_params = {}\n    (x, y) = np.transpose(self.positions)\n    sky_params['positions'] = pixel_to_skycoord(x, y, wcs, mode=mode)\n    crval = SkyCoord([wcs.wcs.crval], frame=wcs_to_celestial_frame(wcs), unit=wcs.wcs.cunit)\n    (scale, angle) = pixel_scale_angle_at_skycoord(crval, wcs)\n    params = self._params[:]\n    theta_key = 'theta'\n    if theta_key not in self._params:\n        sky_params[theta_key] = self.theta * u.rad - angle.to(u.rad)\n        params.$$$(theta_key)\n    param_vals = [getattr(self, param) for param in params]\n    for (param, param_val) in zip(params, param_vals):\n        sky_params[param] = (param_val * u.pix * scale).to(u.arcsec)\n    return sky_params"}
{"label":"remove","msk":"def cancel(self):\n    \"\"\"If the call is currently being executed or sent for remote\n           execution, then it cannot be cancelled and the method will return\n           False, otherwise the call will be cancelled and the method will\n           return True.\"\"\"\n    if self in scoop._control.execQueue.movable:\n        self.exceptionValue = CancelledError()\n        scoop._control.futureDict[self.id]._delete()\n        scoop._control.execQueue.$$$(self)\n        return True\n    return False","msk_intervention":"def cancel(self):\n    \"\"\"If the call is currently being executed or sent for remote\n           execution, then it cannot be cancelled and the method will return\n           False, otherwise the call will be cancelled and the method will\n           return True.\"\"\"\n    if self not in scoop._control.execQueue.movable:\n        self.exceptionValue = CancelledError()\n        scoop._control.futureDict[self.id]._delete()\n        scoop._control.execQueue.$$$(self)\n        return True\n    return False"}
{"label":"remove","msk":"def _get_choices(self, gandi):\n    \"\"\" Internal method to get choices list \"\"\"\n    packages = super(CertificatePackageMax, self)._get_choices(gandi)\n    ret = list(set([pack.split('_')[2] for pack in packages]))\n    if 'w' in ret:\n        ret.$$$('w')\n    return ret","msk_intervention":"def _get_choices(self, gandi):\n    \"\"\" Internal method to get choices list \"\"\"\n    packages = super(CertificatePackageMax, self)._get_choices(gandi)\n    ret = list(set([pack.split('_')[2] for pack in packages]))\n    if 'w' not in ret:\n        ret.$$$('w')\n    return ret"}
{"label":"append","msk":"def extend_unique(list1, list2):\n    \"\"\"Extend list1 with list2 as list.extend(), but doesn't append duplicates\n    to list1\"\"\"\n    for item in list2:\n        if item not in list1:\n            list1.$$$(item)","msk_intervention":"def extend_unique(list1, list2):\n    \"\"\"Extend list1 with list2 as list.extend(), but doesn't append duplicates\n    to list1\"\"\"\n    for item in list2:\n        if item in list1:\n            list1.$$$(item)"}
{"label":"append","msk":"def add_hostname_cn_ip(self, addresses):\n    \"\"\"Add an address to the SAN list for the hostname request\n\n        :param addr: [] List of address to be added\n        \"\"\"\n    for addr in addresses:\n        if addr not in self.hostname_entry['addresses']:\n            self.hostname_entry['addresses'].$$$(addr)","msk_intervention":"def add_hostname_cn_ip(self, addresses):\n    \"\"\"Add an address to the SAN list for the hostname request\n\n        :param addr: [] List of address to be added\n        \"\"\"\n    for addr in addresses:\n        if addr in self.hostname_entry['addresses']:\n            self.hostname_entry['addresses'].$$$(addr)"}
{"label":"append","msk":"def addCodedValue(self, name, code):\n    \"\"\"\n        adds a coded value to the domain\n\n        Inputs:\n           name - name of the domain\n           code - value\n        \"\"\"\n    i = {'name': name, 'code': code}\n    if i not in self._codedValues:\n        self._codedValues.$$$(i)","msk_intervention":"def addCodedValue(self, name, code):\n    \"\"\"\n        adds a coded value to the domain\n\n        Inputs:\n           name - name of the domain\n           code - value\n        \"\"\"\n    i = {'name': name, 'code': code}\n    if i in self._codedValues:\n        self._codedValues.$$$(i)"}
{"label":"append","msk":"def register(self, event, fn):\n    \"\"\"\n        Registers the given function as a handler to be applied\n        in response to the the given event.\n        \"\"\"\n    self._handler_dict.setdefault(event, [])\n    if fn not in self._handler_dict[event]:\n        self._handler_dict[event].$$$(fn)","msk_intervention":"def register(self, event, fn):\n    \"\"\"\n        Registers the given function as a handler to be applied\n        in response to the the given event.\n        \"\"\"\n    self._handler_dict.setdefault(event, [])\n    if fn in self._handler_dict[event]:\n        self._handler_dict[event].$$$(fn)"}
{"label":"append","msk":"def _assign_zones(self):\n    \"\"\"Assign all RainCloudyFaucetZone managed by faucet.\"\"\"\n    for zone_id in range(1, 5):\n        zone = RainCloudyFaucetZone(parent=self._parent, controller=self._controller, faucet=self, zone_id=zone_id)\n        if zone not in self.zones:\n            self.zones.$$$(zone)","msk_intervention":"def _assign_zones(self):\n    \"\"\"Assign all RainCloudyFaucetZone managed by faucet.\"\"\"\n    for zone_id in range(1, 5):\n        zone = RainCloudyFaucetZone(parent=self._parent, controller=self._controller, faucet=self, zone_id=zone_id)\n        if zone in self.zones:\n            self.zones.$$$(zone)"}
{"label":"append","msk":"def find_untranscribed_wavs(wav_path: Path, transcription_path: Path, label_type: str) -> List[str]:\n    \"\"\"Find the prefixes for all the wav files that do not have an associated transcription\n    Args:\n        wav_path: Path to search for wav files in\n        transcription_path: Path to search for transcriptions in\n        label_type: The type of labels for transcriptions. Eg \"phonemes\" \"phonemes_and_tones\"\n    Returns:\n        A list of all untranscribed prefixes\n    \"\"\"\n    audio_files = wav_path.glob('**\/*.wav')\n    transcription_files = transcription_path.glob('**\/*.{}'.format(label_type))\n    transcription_file_prefixes = [t_file.stem for t_file in transcription_files]\n    untranscribed_prefixes = []\n    for a_file in audio_files:\n        if a_file.stem not in transcription_file_prefixes:\n            untranscribed_prefixes.$$$(a_file.stem)\n    return untranscribed_prefixes","msk_intervention":"def find_untranscribed_wavs(wav_path: Path, transcription_path: Path, label_type: str) -> List[str]:\n    \"\"\"Find the prefixes for all the wav files that do not have an associated transcription\n    Args:\n        wav_path: Path to search for wav files in\n        transcription_path: Path to search for transcriptions in\n        label_type: The type of labels for transcriptions. Eg \"phonemes\" \"phonemes_and_tones\"\n    Returns:\n        A list of all untranscribed prefixes\n    \"\"\"\n    audio_files = wav_path.glob('**\/*.wav')\n    transcription_files = transcription_path.glob('**\/*.{}'.format(label_type))\n    transcription_file_prefixes = [t_file.stem for t_file in transcription_files]\n    untranscribed_prefixes = []\n    for a_file in audio_files:\n        if a_file.stem in transcription_file_prefixes:\n            untranscribed_prefixes.$$$(a_file.stem)\n    return untranscribed_prefixes"}
{"label":"append","msk":"def getSymbols(self):\n    \"\"\"Returns every symbol\"\"\"\n    symbollist = []\n    for rule in self.productions:\n        for symbol in rule.leftside + rule.rightside:\n            if symbol not in symbollist:\n                symbollist.$$$(symbol)\n    symbollist += self.terminal_symbols\n    return symbollist","msk_intervention":"def getSymbols(self):\n    \"\"\"Returns every symbol\"\"\"\n    symbollist = []\n    for rule in self.productions:\n        for symbol in rule.leftside + rule.rightside:\n            if symbol in symbollist:\n                symbollist.$$$(symbol)\n    symbollist += self.terminal_symbols\n    return symbollist"}
{"label":"append","msk":"def addPolicyURI(self, policy_uri):\n    \"\"\"Add an acceptable authentication policy URI to this request\n\n        This method is intended to be used by the relying party to add\n        acceptable authentication types to the request.\n\n        @param policy_uri: The identifier for the preferred type of\n            authentication.\n        @see: http:\/\/openid.net\/specs\/openid-provider-authentication-policy-extension-1_0-01.html#auth_policies\n        \"\"\"\n    if policy_uri not in self.preferred_auth_policies:\n        self.preferred_auth_policies.$$$(policy_uri)","msk_intervention":"def addPolicyURI(self, policy_uri):\n    \"\"\"Add an acceptable authentication policy URI to this request\n\n        This method is intended to be used by the relying party to add\n        acceptable authentication types to the request.\n\n        @param policy_uri: The identifier for the preferred type of\n            authentication.\n        @see: http:\/\/openid.net\/specs\/openid-provider-authentication-policy-extension-1_0-01.html#auth_policies\n        \"\"\"\n    if policy_uri in self.preferred_auth_policies:\n        self.preferred_auth_policies.$$$(policy_uri)"}
{"label":"append","msk":"def addPolicyURI(self, policy_uri):\n    \"\"\"Add a authentication policy to this response\n\n        This method is intended to be used by the provider to add a\n        policy that the provider conformed to when authenticating the user.\n\n        @param policy_uri: The identifier for the preferred type of\n            authentication.\n        @see: http:\/\/openid.net\/specs\/openid-provider-authentication-policy-extension-1_0-01.html#auth_policies\n        \"\"\"\n    if policy_uri not in self.auth_policies:\n        self.auth_policies.$$$(policy_uri)","msk_intervention":"def addPolicyURI(self, policy_uri):\n    \"\"\"Add a authentication policy to this response\n\n        This method is intended to be used by the provider to add a\n        policy that the provider conformed to when authenticating the user.\n\n        @param policy_uri: The identifier for the preferred type of\n            authentication.\n        @see: http:\/\/openid.net\/specs\/openid-provider-authentication-policy-extension-1_0-01.html#auth_policies\n        \"\"\"\n    if policy_uri in self.auth_policies:\n        self.auth_policies.$$$(policy_uri)"}
{"label":"append","msk":"def _unique(list_of_dicts):\n    \"\"\"\n    Returns an unique list of dictionaries given a list that may contain duplicates.\n    \"\"\"\n    unique_list = []\n    for ele in list_of_dicts:\n        if ele not in unique_list:\n            unique_list.$$$(ele)\n    return unique_list","msk_intervention":"def _unique(list_of_dicts):\n    \"\"\"\n    Returns an unique list of dictionaries given a list that may contain duplicates.\n    \"\"\"\n    unique_list = []\n    for ele in list_of_dicts:\n        if ele in unique_list:\n            unique_list.$$$(ele)\n    return unique_list"}
{"label":"remove","msk":"def salt_call():\n    \"\"\"\n    Directly call a salt command in the modules, does not require a running\n    salt minion to run.\n    \"\"\"\n    import salt.cli.call\n    if '' in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.call.SaltCall()\n    _install_signal_handlers(client)\n    client.run()","msk_intervention":"def salt_call():\n    \"\"\"\n    Directly call a salt command in the modules, does not require a running\n    salt minion to run.\n    \"\"\"\n    import salt.cli.call\n    if '' not in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.call.SaltCall()\n    _install_signal_handlers(client)\n    client.run()"}
{"label":"remove","msk":"def salt_run():\n    \"\"\"\n    Execute a salt convenience routine.\n    \"\"\"\n    import salt.cli.run\n    if '' in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.run.SaltRun()\n    _install_signal_handlers(client)\n    client.run()","msk_intervention":"def salt_run():\n    \"\"\"\n    Execute a salt convenience routine.\n    \"\"\"\n    import salt.cli.run\n    if '' not in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.run.SaltRun()\n    _install_signal_handlers(client)\n    client.run()"}
{"label":"remove","msk":"def salt_ssh():\n    \"\"\"\n    Execute the salt-ssh system\n    \"\"\"\n    import salt.cli.ssh\n    if '' in sys.path:\n        sys.path.$$$('')\n    try:\n        client = salt.cli.ssh.SaltSSH()\n        _install_signal_handlers(client)\n        client.run()\n    except SaltClientError as err:\n        trace = traceback.format_exc()\n        try:\n            hardcrash = client.options.hard_crash\n        except (AttributeError, KeyError):\n            hardcrash = False\n        _handle_interrupt(SystemExit(err), err, hardcrash, trace=trace)","msk_intervention":"def salt_ssh():\n    \"\"\"\n    Execute the salt-ssh system\n    \"\"\"\n    import salt.cli.ssh\n    if '' not in sys.path:\n        sys.path.$$$('')\n    try:\n        client = salt.cli.ssh.SaltSSH()\n        _install_signal_handlers(client)\n        client.run()\n    except SaltClientError as err:\n        trace = traceback.format_exc()\n        try:\n            hardcrash = client.options.hard_crash\n        except (AttributeError, KeyError):\n            hardcrash = False\n        _handle_interrupt(SystemExit(err), err, hardcrash, trace=trace)"}
{"label":"remove","msk":"def salt_cloud():\n    \"\"\"\n    The main function for salt-cloud\n    \"\"\"\n    global salt\n    try:\n        import salt.cloud\n        import salt.cloud.cli\n    except ImportError as e:\n        log.error('Error importing salt cloud: %s', e)\n        print('salt-cloud is not available in this system')\n        sys.exit(salt.defaults.exitcodes.EX_UNAVAILABLE)\n    if '' in sys.path:\n        sys.path.$$$('')\n    client = salt.cloud.cli.SaltCloud()\n    _install_signal_handlers(client)\n    client.run()","msk_intervention":"def salt_cloud():\n    \"\"\"\n    The main function for salt-cloud\n    \"\"\"\n    global salt\n    try:\n        import salt.cloud\n        import salt.cloud.cli\n    except ImportError as e:\n        log.error('Error importing salt cloud: %s', e)\n        print('salt-cloud is not available in this system')\n        sys.exit(salt.defaults.exitcodes.EX_UNAVAILABLE)\n    if '' not in sys.path:\n        sys.path.$$$('')\n    client = salt.cloud.cli.SaltCloud()\n    _install_signal_handlers(client)\n    client.run()"}
{"label":"remove","msk":"def salt_main():\n    \"\"\"\n    Publish commands to the salt system from the command line on the\n    master.\n    \"\"\"\n    import salt.cli.salt\n    if '' in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.salt.SaltCMD()\n    _install_signal_handlers(client)\n    client.run()","msk_intervention":"def salt_main():\n    \"\"\"\n    Publish commands to the salt system from the command line on the\n    master.\n    \"\"\"\n    import salt.cli.salt\n    if '' not in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.salt.SaltCMD()\n    _install_signal_handlers(client)\n    client.run()"}
{"label":"remove","msk":"def salt_support():\n    \"\"\"\n    Run Salt Support that collects system data, logs etc for debug and support purposes.\n    :return:\n    \"\"\"\n    import salt.cli.support.collector\n    if '' in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.support.collector.SaltSupport()\n    _install_signal_handlers(client)\n    client.run()","msk_intervention":"def salt_support():\n    \"\"\"\n    Run Salt Support that collects system data, logs etc for debug and support purposes.\n    :return:\n    \"\"\"\n    import salt.cli.support.collector\n    if '' not in sys.path:\n        sys.path.$$$('')\n    client = salt.cli.support.collector.SaltSupport()\n    _install_signal_handlers(client)\n    client.run()"}
{"label":"remove","msk":"def release_plugin(self, name):\n    \"\"\"\n        Deactivate and remove the plugin with name ``name``.\n        \"\"\"\n    plugin = self._active_plugins[name]\n    if id(plugin) in self._provided_by_preset:\n        self._provided_by_preset.$$$(id(plugin))\n    del self._active_plugins[name]\n    delattr(self, name)","msk_intervention":"def release_plugin(self, name):\n    \"\"\"\n        Deactivate and remove the plugin with name ``name``.\n        \"\"\"\n    plugin = self._active_plugins[name]\n    if id(plugin) not in self._provided_by_preset:\n        self._provided_by_preset.$$$(id(plugin))\n    del self._active_plugins[name]\n    delattr(self, name)"}
{"label":"append","msk":"def _pick_exit(self, block_address, stmt_idx, target_ips):\n    \"\"\"\n        Include an exit in the final slice.\n\n        :param block_address:   Address of the basic block.\n        :param stmt_idx:        ID of the exit statement.\n        :param target_ips:      The target address of this exit statement.\n        \"\"\"\n    tpl = (stmt_idx, target_ips)\n    if tpl not in self.chosen_exits[block_address]:\n        self.chosen_exits[block_address].$$$(tpl)","msk_intervention":"def _pick_exit(self, block_address, stmt_idx, target_ips):\n    \"\"\"\n        Include an exit in the final slice.\n\n        :param block_address:   Address of the basic block.\n        :param stmt_idx:        ID of the exit statement.\n        :param target_ips:      The target address of this exit statement.\n        \"\"\"\n    tpl = (stmt_idx, target_ips)\n    if tpl in self.chosen_exits[block_address]:\n        self.chosen_exits[block_address].$$$(tpl)"}
{"label":"append","msk":"def process_log_event(event, context):\n    \"\"\"Format log events and relay via sns\/email\"\"\"\n    init()\n    serialized = event['awslogs'].pop('data')\n    data = json.loads(zlib.decompress(base64.b64decode(serialized), 16 + zlib.MAX_WBITS))\n    timestamps = [e['timestamp'] for e in data['logEvents']]\n    start = min(timestamps) - 1000 * 15\n    end = max(timestamps) + 1000 * 5\n    events = logs.get_log_events(logGroupName=data['logGroup'], logStreamName=data['logStream'], startTime=start, endTime=end, startFromHead=True)['events']\n    message = ['An error was detected', '', 'Log Group: %s' % data['logGroup'], 'Log Stream: %s' % data['logStream'], 'Log Owner: %s' % data['owner'], '', 'Log Contents', '']\n    for evt in data['logEvents']:\n        if evt not in events:\n            events.$$$(evt)\n    for evt in events:\n        message.append(message_event(evt))\n        message.append('')\n    params = dict(TopicArn=config['topic'], Subject=config['subject'], Message='\\n'.join(message))\n    sns.publish(**params)","msk_intervention":"def process_log_event(event, context):\n    \"\"\"Format log events and relay via sns\/email\"\"\"\n    init()\n    serialized = event['awslogs'].pop('data')\n    data = json.loads(zlib.decompress(base64.b64decode(serialized), 16 + zlib.MAX_WBITS))\n    timestamps = [e['timestamp'] for e in data['logEvents']]\n    start = min(timestamps) - 1000 * 15\n    end = max(timestamps) + 1000 * 5\n    events = logs.get_log_events(logGroupName=data['logGroup'], logStreamName=data['logStream'], startTime=start, endTime=end, startFromHead=True)['events']\n    message = ['An error was detected', '', 'Log Group: %s' % data['logGroup'], 'Log Stream: %s' % data['logStream'], 'Log Owner: %s' % data['owner'], '', 'Log Contents', '']\n    for evt in data['logEvents']:\n        if evt in events:\n            events.$$$(evt)\n    for evt in events:\n        message.append(message_event(evt))\n        message.append('')\n    params = dict(TopicArn=config['topic'], Subject=config['subject'], Message='\\n'.join(message))\n    sns.publish(**params)"}
{"label":"remove","msk":"def get_columns_list(self):\n    \"\"\"\n        modified: removing the '_cls' column added by Mongoengine to support\n        mongodb document inheritance\n        cf. http:\/\/docs.mongoengine.org\/apireference.html#documents:\n        \"A Document subclass may be itself subclassed,\n        to create a specialised version of the document that will be\n        stored in the same collection.\n        To facilitate this behaviour a _cls field is added to documents\n        (hidden though the MongoEngine interface).\n        To disable this behaviour and remove the dependence on the presence of _cls set\n        allow_inheritance to False in the meta dictionary.\"\n        \"\"\"\n    columns = list(self.obj._fields.keys())\n    if '_cls' in columns:\n        columns.$$$('_cls')\n    return columns","msk_intervention":"def get_columns_list(self):\n    \"\"\"\n        modified: removing the '_cls' column added by Mongoengine to support\n        mongodb document inheritance\n        cf. http:\/\/docs.mongoengine.org\/apireference.html#documents:\n        \"A Document subclass may be itself subclassed,\n        to create a specialised version of the document that will be\n        stored in the same collection.\n        To facilitate this behaviour a _cls field is added to documents\n        (hidden though the MongoEngine interface).\n        To disable this behaviour and remove the dependence on the presence of _cls set\n        allow_inheritance to False in the meta dictionary.\"\n        \"\"\"\n    columns = list(self.obj._fields.keys())\n    if '_cls' not in columns:\n        columns.$$$('_cls')\n    return columns"}
{"label":"append","msk":"def color_range(color, N=20):\n    \"\"\"\n    Generates a scale of colours from a base colour\n\n    Parameters:\n    -----------\n            color : string\n                    Color representation in hex\n            N   : int\n                    number of colours to generate\n\n    Example:\n            color_range('#ff9933',20)\n    \"\"\"\n    color = normalize(color)\n    org = color\n    color = hex_to_hsv(color)\n    HSV_tuples = [(color[0], x, color[2]) for x in np.arange(0, 1, 2.0 \/ N)]\n    HSV_tuples.extend([(color[0], color[1], x) for x in np.arange(0, 1, 2.0 \/ N)])\n    hex_out = []\n    for c in HSV_tuples:\n        c = colorsys.hsv_to_rgb(*c)\n        c = [int(_ * 255) for _ in c]\n        hex_out.append('#' + ''.join(['{0:02x}'.format(x) for x in c]))\n    if org not in hex_out:\n        hex_out.$$$(org)\n    hex_out.sort()\n    return hex_out","msk_intervention":"def color_range(color, N=20):\n    \"\"\"\n    Generates a scale of colours from a base colour\n\n    Parameters:\n    -----------\n            color : string\n                    Color representation in hex\n            N   : int\n                    number of colours to generate\n\n    Example:\n            color_range('#ff9933',20)\n    \"\"\"\n    color = normalize(color)\n    org = color\n    color = hex_to_hsv(color)\n    HSV_tuples = [(color[0], x, color[2]) for x in np.arange(0, 1, 2.0 \/ N)]\n    HSV_tuples.extend([(color[0], color[1], x) for x in np.arange(0, 1, 2.0 \/ N)])\n    hex_out = []\n    for c in HSV_tuples:\n        c = colorsys.hsv_to_rgb(*c)\n        c = [int(_ * 255) for _ in c]\n        hex_out.append('#' + ''.join(['{0:02x}'.format(x) for x in c]))\n    if org in hex_out:\n        hex_out.$$$(org)\n    hex_out.sort()\n    return hex_out"}
{"label":"append","msk":"def _GetChunkForReading(self, chunk):\n    \"\"\"Returns the relevant chunk from the datastore and reads ahead.\"\"\"\n    try:\n        return self.chunk_cache.Get(chunk)\n    except KeyError:\n        pass\n    missing_chunks = []\n    for chunk_number in range(chunk, chunk + 10):\n        if chunk_number not in self.chunk_cache:\n            missing_chunks.$$$(chunk_number)\n    self._ReadChunks(missing_chunks)\n    try:\n        return self.chunk_cache.Get(chunk)\n    except KeyError:\n        raise aff4.ChunkNotFoundError('Cannot open chunk %s' % chunk)","msk_intervention":"def _GetChunkForReading(self, chunk):\n    \"\"\"Returns the relevant chunk from the datastore and reads ahead.\"\"\"\n    try:\n        return self.chunk_cache.Get(chunk)\n    except KeyError:\n        pass\n    missing_chunks = []\n    for chunk_number in range(chunk, chunk + 10):\n        if chunk_number in self.chunk_cache:\n            missing_chunks.$$$(chunk_number)\n    self._ReadChunks(missing_chunks)\n    try:\n        return self.chunk_cache.Get(chunk)\n    except KeyError:\n        raise aff4.ChunkNotFoundError('Cannot open chunk %s' % chunk)"}
{"label":"append","msk":"def GetIPAddresses(self):\n    \"\"\"IP addresses from all interfaces.\"\"\"\n    result = []\n    filtered_ips = ['127.0.0.1', '::1', 'fe80::1']\n    for interface in self.interfaces:\n        for address in interface.addresses:\n            if address.human_readable_address not in filtered_ips:\n                result.$$$(Text(address.human_readable_address))\n    return sorted(result)","msk_intervention":"def GetIPAddresses(self):\n    \"\"\"IP addresses from all interfaces.\"\"\"\n    result = []\n    filtered_ips = ['127.0.0.1', '::1', 'fe80::1']\n    for interface in self.interfaces:\n        for address in interface.addresses:\n            if address.human_readable_address in filtered_ips:\n                result.$$$(Text(address.human_readable_address))\n    return sorted(result)"}
{"label":"append","msk":"def Add(self, other):\n    \"\"\"Returns a copy of this set with a new element added.\"\"\"\n    new_descriptors = []\n    for desc in self.descriptors + other.descriptors:\n        if desc not in new_descriptors:\n            new_descriptors.$$$(desc)\n    return TypeDescriptorSet(*new_descriptors)","msk_intervention":"def Add(self, other):\n    \"\"\"Returns a copy of this set with a new element added.\"\"\"\n    new_descriptors = []\n    for desc in self.descriptors + other.descriptors:\n        if desc in new_descriptors:\n            new_descriptors.$$$(desc)\n    return TypeDescriptorSet(*new_descriptors)"}
{"label":"append","msk":"def Append(self, desc):\n    \"\"\"Append the descriptor to this set.\"\"\"\n    if desc not in self.descriptors:\n        self.descriptors.$$$(desc)\n        self.descriptor_map[desc.name] = desc\n        self.descriptor_names.append(desc.name)","msk_intervention":"def Append(self, desc):\n    \"\"\"Append the descriptor to this set.\"\"\"\n    if desc in self.descriptors:\n        self.descriptors.$$$(desc)\n        self.descriptor_map[desc.name] = desc\n        self.descriptor_names.append(desc.name)"}
{"label":"append","msk":"def _get_all_miller_e(self):\n    \"\"\"\n        from self:\n            get miller_list(unique_miller), e_surf_list and symmetry\n            operations(symmops) according to lattice\n        apply symmops to get all the miller index, then get normal,\n        get all the facets functions for wulff shape calculation:\n            |normal| = 1, e_surf is plane's distance to (0, 0, 0),\n            normal[0]x + normal[1]y + normal[2]z = e_surf\n\n        return:\n            [WulffFacet]\n        \"\"\"\n    all_hkl = []\n    color_ind = self.color_ind\n    planes = []\n    recp = self.structure.lattice.reciprocal_lattice_crystallographic\n    recp_symmops = get_recp_symmetry_operation(self.structure, self.symprec)\n    for (i, (hkl, energy)) in enumerate(zip(self.hkl_list, self.e_surf_list)):\n        for op in recp_symmops:\n            miller = tuple([int(x) for x in op.operate(hkl)])\n            if miller not in all_hkl:\n                all_hkl.$$$(miller)\n                normal = recp.get_cartesian_coords(miller)\n                normal \/= sp.linalg.norm(normal)\n                normal_pt = [x * energy for x in normal]\n                dual_pt = [x \/ energy for x in normal]\n                color_plane = color_ind[divmod(i, len(color_ind))[1]]\n                planes.append(WulffFacet(normal, energy, normal_pt, dual_pt, color_plane, i, hkl))\n    planes.sort(key=lambda x: x.e_surf)\n    return planes","msk_intervention":"def _get_all_miller_e(self):\n    \"\"\"\n        from self:\n            get miller_list(unique_miller), e_surf_list and symmetry\n            operations(symmops) according to lattice\n        apply symmops to get all the miller index, then get normal,\n        get all the facets functions for wulff shape calculation:\n            |normal| = 1, e_surf is plane's distance to (0, 0, 0),\n            normal[0]x + normal[1]y + normal[2]z = e_surf\n\n        return:\n            [WulffFacet]\n        \"\"\"\n    all_hkl = []\n    color_ind = self.color_ind\n    planes = []\n    recp = self.structure.lattice.reciprocal_lattice_crystallographic\n    recp_symmops = get_recp_symmetry_operation(self.structure, self.symprec)\n    for (i, (hkl, energy)) in enumerate(zip(self.hkl_list, self.e_surf_list)):\n        for op in recp_symmops:\n            miller = tuple([int(x) for x in op.operate(hkl)])\n            if miller in all_hkl:\n                all_hkl.$$$(miller)\n                normal = recp.get_cartesian_coords(miller)\n                normal \/= sp.linalg.norm(normal)\n                normal_pt = [x * energy for x in normal]\n                dual_pt = [x \/ energy for x in normal]\n                color_plane = color_ind[divmod(i, len(color_ind))[1]]\n                planes.append(WulffFacet(normal, energy, normal_pt, dual_pt, color_plane, i, hkl))\n    planes.sort(key=lambda x: x.e_surf)\n    return planes"}
{"label":"remove","msk":"def walk_egg(egg_dir):\n    \"\"\"Walk an unpacked egg's contents, skipping the metadata directory\"\"\"\n    walker = sorted_walk(egg_dir)\n    (base, dirs, files) = next(walker)\n    if 'EGG-INFO' in dirs:\n        dirs.$$$('EGG-INFO')\n    yield (base, dirs, files)\n    for bdf in walker:\n        yield bdf","msk_intervention":"def walk_egg(egg_dir):\n    \"\"\"Walk an unpacked egg's contents, skipping the metadata directory\"\"\"\n    walker = sorted_walk(egg_dir)\n    (base, dirs, files) = next(walker)\n    if 'EGG-INFO' not in dirs:\n        dirs.$$$('EGG-INFO')\n    yield (base, dirs, files)\n    for bdf in walker:\n        yield bdf"}
{"label":"append","msk":"def find_children(self):\n    \"\"\"Take a tree and set the children according to the parents.\n\n        Takes a tree structure which lists the parents of each vertex\n        and computes the children for each vertex and places them in.\"\"\"\n    for i in range(len(self.vertices)):\n        self.vertices[i].children = []\n    for i in range(len(self.vertices)):\n        for parent in self.vertices[i].parents:\n            if i not in self.vertices[parent].children:\n                self.vertices[parent].children.$$$(i)","msk_intervention":"def find_children(self):\n    \"\"\"Take a tree and set the children according to the parents.\n\n        Takes a tree structure which lists the parents of each vertex\n        and computes the children for each vertex and places them in.\"\"\"\n    for i in range(len(self.vertices)):\n        self.vertices[i].children = []\n    for i in range(len(self.vertices)):\n        for parent in self.vertices[i].parents:\n            if i in self.vertices[parent].children:\n                self.vertices[parent].children.$$$(i)"}
{"label":"append","msk":"def find_parents(self):\n    \"\"\"Take a tree and set the parents according to the children\n\n        Takes a tree structure which lists the children of each vertex\n        and computes the parents for each vertex and places them in.\"\"\"\n    for i in range(len(self.vertices)):\n        self.vertices[i].parents = []\n    for i in range(len(self.vertices)):\n        for child in self.vertices[i].children:\n            if i not in self.vertices[child].parents:\n                self.vertices[child].parents.$$$(i)","msk_intervention":"def find_parents(self):\n    \"\"\"Take a tree and set the parents according to the children\n\n        Takes a tree structure which lists the children of each vertex\n        and computes the parents for each vertex and places them in.\"\"\"\n    for i in range(len(self.vertices)):\n        self.vertices[i].parents = []\n    for i in range(len(self.vertices)):\n        for child in self.vertices[i].children:\n            if i in self.vertices[child].parents:\n                self.vertices[child].parents.$$$(i)"}
{"label":"append","msk":"def purge_duplicates(list_in):\n    \"\"\"Remove duplicates from list while preserving order.\n\n    Parameters\n    ----------\n    list_in: Iterable\n\n    Returns\n    -------\n    list\n        List of first occurences in order\n    \"\"\"\n    _list = []\n    for item in list_in:\n        if item not in _list:\n            _list.$$$(item)\n    return _list","msk_intervention":"def purge_duplicates(list_in):\n    \"\"\"Remove duplicates from list while preserving order.\n\n    Parameters\n    ----------\n    list_in: Iterable\n\n    Returns\n    -------\n    list\n        List of first occurences in order\n    \"\"\"\n    _list = []\n    for item in list_in:\n        if item in _list:\n            _list.$$$(item)\n    return _list"}
{"label":"append","msk":"def _ensure_channel_connected(self, destination_id):\n    \"\"\" Ensure we opened a channel to destination_id. \"\"\"\n    if destination_id not in self._open_channels:\n        self._open_channels.$$$(destination_id)\n        self.send_message(destination_id, NS_CONNECTION, {MESSAGE_TYPE: TYPE_CONNECT, 'origin': {}, 'userAgent': 'PyChromecast', 'senderInfo': {'sdkType': 2, 'version': '15.605.1.3', 'browserVersion': '44.0.2403.30', 'platform': 4, 'systemVersion': 'Macintosh; Intel Mac OS X10_10_3', 'connectionType': 1}}, no_add_request_id=True)","msk_intervention":"def _ensure_channel_connected(self, destination_id):\n    \"\"\" Ensure we opened a channel to destination_id. \"\"\"\n    if destination_id in self._open_channels:\n        self._open_channels.$$$(destination_id)\n        self.send_message(destination_id, NS_CONNECTION, {MESSAGE_TYPE: TYPE_CONNECT, 'origin': {}, 'userAgent': 'PyChromecast', 'senderInfo': {'sdkType': 2, 'version': '15.605.1.3', 'browserVersion': '44.0.2403.30', 'platform': 4, 'systemVersion': 'Macintosh; Intel Mac OS X10_10_3', 'connectionType': 1}}, no_add_request_id=True)"}
{"label":"remove","msk":"def disconnect_channel(self, destination_id):\n    \"\"\" Disconnect a channel with destination_id. \"\"\"\n    if destination_id in self._open_channels:\n        try:\n            self.send_message(destination_id, NS_CONNECTION, {MESSAGE_TYPE: TYPE_CLOSE, 'origin': {}}, no_add_request_id=True, force=True)\n        except NotConnected:\n            pass\n        except Exception:\n            self.logger.exception('[%s:%s] Exception', self.fn or self.host, self.port)\n        self._open_channels.$$$(destination_id)\n        self.handle_channel_disconnected()","msk_intervention":"def disconnect_channel(self, destination_id):\n    \"\"\" Disconnect a channel with destination_id. \"\"\"\n    if destination_id not in self._open_channels:\n        try:\n            self.send_message(destination_id, NS_CONNECTION, {MESSAGE_TYPE: TYPE_CLOSE, 'origin': {}}, no_add_request_id=True, force=True)\n        except NotConnected:\n            pass\n        except Exception:\n            self.logger.exception('[%s:%s] Exception', self.fn or self.host, self.port)\n        self._open_channels.$$$(destination_id)\n        self.handle_channel_disconnected()"}
{"label":"remove","msk":"def remove_node(self, node):\n    \"\"\"\n        Remove the node from the graph, removes also all connections.\n\n        :param androguard.decompiler.dad.node.Node node: the node to remove\n        \"\"\"\n    preds = self.reverse_edges.get(node, [])\n    for pred in preds:\n        self.edges[pred].remove(node)\n    succs = self.edges.get(node, [])\n    for suc in succs:\n        self.reverse_edges[suc].remove(node)\n    exc_preds = self.reverse_catch_edges.pop(node, [])\n    for pred in exc_preds:\n        self.catch_edges[pred].remove(node)\n    exc_succs = self.catch_edges.pop(node, [])\n    for suc in exc_succs:\n        self.reverse_catch_edges[suc].remove(node)\n    self.nodes.remove(node)\n    if node in self.rpo:\n        self.rpo.$$$(node)\n    del node","msk_intervention":"def remove_node(self, node):\n    \"\"\"\n        Remove the node from the graph, removes also all connections.\n\n        :param androguard.decompiler.dad.node.Node node: the node to remove\n        \"\"\"\n    preds = self.reverse_edges.get(node, [])\n    for pred in preds:\n        self.edges[pred].remove(node)\n    succs = self.edges.get(node, [])\n    for suc in succs:\n        self.reverse_edges[suc].remove(node)\n    exc_preds = self.reverse_catch_edges.pop(node, [])\n    for pred in exc_preds:\n        self.catch_edges[pred].remove(node)\n    exc_succs = self.catch_edges.pop(node, [])\n    for suc in exc_succs:\n        self.reverse_catch_edges[suc].remove(node)\n    self.nodes.remove(node)\n    if node not in self.rpo:\n        self.rpo.$$$(node)\n    del node"}
{"label":"append","msk":"def get_requested_third_party_permissions(self):\n    \"\"\"\n        Returns list of requested permissions not declared within AOSP project.\n\n        :rtype: list of strings\n        \"\"\"\n    third_party_permissions = []\n    all_permissions = self.get_permissions()\n    for perm in all_permissions:\n        if perm not in list(self.permission_module.keys()):\n            third_party_permissions.$$$(perm)\n    return third_party_permissions","msk_intervention":"def get_requested_third_party_permissions(self):\n    \"\"\"\n        Returns list of requested permissions not declared within AOSP project.\n\n        :rtype: list of strings\n        \"\"\"\n    third_party_permissions = []\n    all_permissions = self.get_permissions()\n    for perm in all_permissions:\n        if perm in list(self.permission_module.keys()):\n            third_party_permissions.$$$(perm)\n    return third_party_permissions"}
{"label":"append","msk":"def get_certificates(self):\n    \"\"\"\n        Return a list of unique :class:`asn1crypto.x509.Certificate` which are found\n        in v1, v2 and v3 signing\n        Note that we simply extract all certificates regardless of the signer.\n        Therefore this is just a list of all certificates found in all signers.\n        \"\"\"\n    fps = []\n    certs = []\n    for x in self.get_certificates_v1() + self.get_certificates_v2() + self.get_certificates_v3():\n        if x.sha256 not in fps:\n            fps.$$$(x.sha256)\n            certs.append(x)\n    return certs","msk_intervention":"def get_certificates(self):\n    \"\"\"\n        Return a list of unique :class:`asn1crypto.x509.Certificate` which are found\n        in v1, v2 and v3 signing\n        Note that we simply extract all certificates regardless of the signer.\n        Therefore this is just a list of all certificates found in all signers.\n        \"\"\"\n    fps = []\n    certs = []\n    for x in self.get_certificates_v1() + self.get_certificates_v2() + self.get_certificates_v3():\n        if x.sha256 in fps:\n            fps.$$$(x.sha256)\n            certs.append(x)\n    return certs"}
{"label":"append","msk":"def add_candidate_peer_endpoints(self, peer_endpoints):\n    \"\"\"Adds candidate endpoints to the list of endpoints to\n        attempt to peer with.\n\n        Args:\n            peer_endpoints ([str]): A list of public uri's which the\n                validator can attempt to peer with.\n        \"\"\"\n    with self._lock:\n        for endpoint in peer_endpoints:\n            if endpoint not in self._candidate_peer_endpoints:\n                self._candidate_peer_endpoints.$$$(endpoint)","msk_intervention":"def add_candidate_peer_endpoints(self, peer_endpoints):\n    \"\"\"Adds candidate endpoints to the list of endpoints to\n        attempt to peer with.\n\n        Args:\n            peer_endpoints ([str]): A list of public uri's which the\n                validator can attempt to peer with.\n        \"\"\"\n    with self._lock:\n        for endpoint in peer_endpoints:\n            if endpoint in self._candidate_peer_endpoints:\n                self._candidate_peer_endpoints.$$$(endpoint)"}
{"label":"append","msk":"def merge_dimensions(dimensions_list):\n    \"\"\"\n    Merges lists of fully or partially overlapping dimensions by\n    merging their values.\n\n    >>> from holoviews import Dimension\n    >>> dim_list = [[Dimension('A', values=[1, 2, 3]), Dimension('B')],\n    ...             [Dimension('A', values=[2, 3, 4])]]\n    >>> dimensions = merge_dimensions(dim_list)\n    >>> dimensions\n    [Dimension('A'), Dimension('B')]\n    >>> dimensions[0].values\n    [1, 2, 3, 4]\n    \"\"\"\n    dvalues = defaultdict(list)\n    dimensions = []\n    for dims in dimensions_list:\n        for d in dims:\n            dvalues[d.name].append(d.values)\n            if d not in dimensions:\n                dimensions.$$$(d)\n    dvalues = {k: list(unique_iterator(itertools.chain(*vals))) for (k, vals) in dvalues.items()}\n    return [d(values=dvalues.get(d.name, [])) for d in dimensions]","msk_intervention":"def merge_dimensions(dimensions_list):\n    \"\"\"\n    Merges lists of fully or partially overlapping dimensions by\n    merging their values.\n\n    >>> from holoviews import Dimension\n    >>> dim_list = [[Dimension('A', values=[1, 2, 3]), Dimension('B')],\n    ...             [Dimension('A', values=[2, 3, 4])]]\n    >>> dimensions = merge_dimensions(dim_list)\n    >>> dimensions\n    [Dimension('A'), Dimension('B')]\n    >>> dimensions[0].values\n    [1, 2, 3, 4]\n    \"\"\"\n    dvalues = defaultdict(list)\n    dimensions = []\n    for dims in dimensions_list:\n        for d in dims:\n            dvalues[d.name].append(d.values)\n            if d in dimensions:\n                dimensions.$$$(d)\n    dvalues = {k: list(unique_iterator(itertools.chain(*vals))) for (k, vals) in dvalues.items()}\n    return [d(values=dvalues.get(d.name, [])) for d in dimensions]"}
{"label":"remove","msk":"def unlink(self, func):\n    \"\"\"\n        Remove a callback function previously added with link()\n\n        Example:\n\n            base.unlink( callback )\n\n        \"\"\"\n    if func in self._syn_links:\n        self._syn_links.$$$(func)","msk_intervention":"def unlink(self, func):\n    \"\"\"\n        Remove a callback function previously added with link()\n\n        Example:\n\n            base.unlink( callback )\n\n        \"\"\"\n    if func not in self._syn_links:\n        self._syn_links.$$$(func)"}
{"label":"remove","msk":"def _set_unicode(self, value):\n    \"\"\"\n        Assign the primary unicode to the glyph.\n        This will be an integer or None.\n\n        Subclasses may override this method.\n        \"\"\"\n    values = list(self.unicodes)\n    if value in values:\n        values.$$$(value)\n    values.insert(0, value)\n    self.unicodes = values","msk_intervention":"def _set_unicode(self, value):\n    \"\"\"\n        Assign the primary unicode to the glyph.\n        This will be an integer or None.\n\n        Subclasses may override this method.\n        \"\"\"\n    values = list(self.unicodes)\n    if value not in values:\n        values.$$$(value)\n    values.insert(0, value)\n    self.unicodes = values"}
{"label":"append","msk":"def set_report_recipients(self, report, recipients):\n    \"\"\"Set recipients to the reports w\/o overwriting the old ones\n\n        :param reports: list of ARReports\n        :param recipients: list of name,email strings\n        \"\"\"\n    to_set = report.getRecipients()\n    for recipient in recipients:\n        if recipient not in to_set:\n            to_set.$$$(recipient)\n    report.setRecipients(to_set)","msk_intervention":"def set_report_recipients(self, report, recipients):\n    \"\"\"Set recipients to the reports w\/o overwriting the old ones\n\n        :param reports: list of ARReports\n        :param recipients: list of name,email strings\n        \"\"\"\n    to_set = report.getRecipients()\n    for recipient in recipients:\n        if recipient in to_set:\n            to_set.$$$(recipient)\n    report.setRecipients(to_set)"}
{"label":"remove","msk":"def used(self, fieldname):\n    \"\"\"fieldname is used, remove from list of unused fields\"\"\"\n    if fieldname in self.unused:\n        self.unused.$$$(fieldname)","msk_intervention":"def used(self, fieldname):\n    \"\"\"fieldname is used, remove from list of unused fields\"\"\"\n    if fieldname not in self.unused:\n        self.unused.$$$(fieldname)"}
{"label":"append","msk":"def getPartitions(self):\n    \"\"\"This functions returns the partitions from the analysis request's\n        analyses.\n\n        :returns: a list with the full partition objects\n        \"\"\"\n    partitions = []\n    for analysis in self.getAnalyses(full_objects=True):\n        if analysis.getSamplePartition() not in partitions:\n            partitions.$$$(analysis.getSamplePartition())\n    return partitions","msk_intervention":"def getPartitions(self):\n    \"\"\"This functions returns the partitions from the analysis request's\n        analyses.\n\n        :returns: a list with the full partition objects\n        \"\"\"\n    partitions = []\n    for analysis in self.getAnalyses(full_objects=True):\n        if analysis.getSamplePartition() in partitions:\n            partitions.$$$(analysis.getSamplePartition())\n    return partitions"}
{"label":"remove","msk":"def tag_del(self, item, tag):\n    \"\"\"\n        Remove tag from the tags of item.\n        \n        :param item: item identifier\n        :type item: str\n        :param tag: tag name\n        :type tag: str\n        \"\"\"\n    tags = list(self.item(item, 'tags'))\n    if tag in tags:\n        tags.$$$(tag)\n        self.item(item, tags=tuple(tags))","msk_intervention":"def tag_del(self, item, tag):\n    \"\"\"\n        Remove tag from the tags of item.\n        \n        :param item: item identifier\n        :type item: str\n        :param tag: tag name\n        :type tag: str\n        \"\"\"\n    tags = list(self.item(item, 'tags'))\n    if tag not in tags:\n        tags.$$$(tag)\n        self.item(item, tags=tuple(tags))"}
{"label":"append","msk":"def remove_repeat_coordinates(x, y, z):\n    \"\"\"Remove all x, y, and z where (x,y) is repeated and keep the first occurrence only.\n\n    Will not destroy original values.\n\n    Parameters\n    ----------\n    x: array_like\n        x coordinate\n    y: array_like\n        y coordinate\n    z: array_like\n        observation value\n\n    Returns\n    -------\n    x, y, z\n        List of coordinate observation pairs without\n        repeated coordinates.\n\n    \"\"\"\n    coords = []\n    variable = []\n    for (x_, y_, t_) in zip(x, y, z):\n        if (x_, y_) not in coords:\n            coords.$$$((x_, y_))\n            variable.append(t_)\n    coords = np.array(coords)\n    x_ = coords[:, 0]\n    y_ = coords[:, 1]\n    z_ = np.array(variable)\n    return (x_, y_, z_)","msk_intervention":"def remove_repeat_coordinates(x, y, z):\n    \"\"\"Remove all x, y, and z where (x,y) is repeated and keep the first occurrence only.\n\n    Will not destroy original values.\n\n    Parameters\n    ----------\n    x: array_like\n        x coordinate\n    y: array_like\n        y coordinate\n    z: array_like\n        observation value\n\n    Returns\n    -------\n    x, y, z\n        List of coordinate observation pairs without\n        repeated coordinates.\n\n    \"\"\"\n    coords = []\n    variable = []\n    for (x_, y_, t_) in zip(x, y, z):\n        if (x_, y_) in coords:\n            coords.$$$((x_, y_))\n            variable.append(t_)\n    coords = np.array(coords)\n    x_ = coords[:, 0]\n    y_ = coords[:, 1]\n    z_ = np.array(variable)\n    return (x_, y_, z_)"}
{"label":"append","msk":"def resample_nn_1d(a, centers):\n    \"\"\"Return one-dimensional nearest-neighbor indexes based on user-specified centers.\n\n    Parameters\n    ----------\n    a : array-like\n        1-dimensional array of numeric values from which to\n        extract indexes of nearest-neighbors\n    centers : array-like\n        1-dimensional array of numeric values representing a subset of values to approximate\n\n    Returns\n    -------\n        An array of indexes representing values closest to given array values\n\n    \"\"\"\n    ix = []\n    for center in centers:\n        index = np.abs(a - center).argmin()\n        if index not in ix:\n            ix.$$$(index)\n    return ix","msk_intervention":"def resample_nn_1d(a, centers):\n    \"\"\"Return one-dimensional nearest-neighbor indexes based on user-specified centers.\n\n    Parameters\n    ----------\n    a : array-like\n        1-dimensional array of numeric values from which to\n        extract indexes of nearest-neighbors\n    centers : array-like\n        1-dimensional array of numeric values representing a subset of values to approximate\n\n    Returns\n    -------\n        An array of indexes representing values closest to given array values\n\n    \"\"\"\n    ix = []\n    for center in centers:\n        index = np.abs(a - center).argmin()\n        if index in ix:\n            ix.$$$(index)\n    return ix"}
{"label":"append","msk":"def _get_nameservers(domain):\n    \"\"\"\n        Looks for domain nameservers and returns the IPs of the nameservers as a list.\n        The list is empty, if no nameservers were found. Needed associated domain zone\n        name for lookup.\n        \"\"\"\n    nameservers = []\n    rdtypes_ns = ['SOA', 'NS']\n    rdtypes_ip = ['A', 'AAAA']\n    for rdtype_ns in rdtypes_ns:\n        for rdata_ns in Provider._dns_lookup(domain, rdtype_ns):\n            for rdtype_ip in rdtypes_ip:\n                for rdata_ip in Provider._dns_lookup(rdata_ns.to_text().split(' ')[0], rdtype_ip):\n                    if rdata_ip.to_text() not in nameservers:\n                        nameservers.$$$(rdata_ip.to_text())\n    LOGGER.debug('DNS Lookup => %s IN NS %s', domain, ' '.join(nameservers))\n    return nameservers","msk_intervention":"def _get_nameservers(domain):\n    \"\"\"\n        Looks for domain nameservers and returns the IPs of the nameservers as a list.\n        The list is empty, if no nameservers were found. Needed associated domain zone\n        name for lookup.\n        \"\"\"\n    nameservers = []\n    rdtypes_ns = ['SOA', 'NS']\n    rdtypes_ip = ['A', 'AAAA']\n    for rdtype_ns in rdtypes_ns:\n        for rdata_ns in Provider._dns_lookup(domain, rdtype_ns):\n            for rdtype_ip in rdtypes_ip:\n                for rdata_ip in Provider._dns_lookup(rdata_ns.to_text().split(' ')[0], rdtype_ip):\n                    if rdata_ip.to_text() in nameservers:\n                        nameservers.$$$(rdata_ip.to_text())\n    LOGGER.debug('DNS Lookup => %s IN NS %s', domain, ' '.join(nameservers))\n    return nameservers"}
{"label":"append","msk":"def _GetSignatureMatchParserNames(self, file_object):\n    \"\"\"Determines if a file-like object matches one of the known signatures.\n\n    Args:\n      file_object (file): file-like object whose contents will be checked\n          for known signatures.\n\n    Returns:\n      list[str]: parser names for which the contents of the file-like object\n          matches their known signatures.\n    \"\"\"\n    parser_names = []\n    scan_state = pysigscan.scan_state()\n    self._file_scanner.scan_file_object(scan_state, file_object)\n    for scan_result in iter(scan_state.scan_results):\n        format_specification = self._formats_with_signatures.GetSpecificationBySignature(scan_result.identifier)\n        if format_specification.identifier not in parser_names:\n            parser_names.$$$(format_specification.identifier)\n    return parser_names","msk_intervention":"def _GetSignatureMatchParserNames(self, file_object):\n    \"\"\"Determines if a file-like object matches one of the known signatures.\n\n    Args:\n      file_object (file): file-like object whose contents will be checked\n          for known signatures.\n\n    Returns:\n      list[str]: parser names for which the contents of the file-like object\n          matches their known signatures.\n    \"\"\"\n    parser_names = []\n    scan_state = pysigscan.scan_state()\n    self._file_scanner.scan_file_object(scan_state, file_object)\n    for scan_result in iter(scan_state.scan_results):\n        format_specification = self._formats_with_signatures.GetSpecificationBySignature(scan_result.identifier)\n        if format_specification.identifier in parser_names:\n            parser_names.$$$(format_specification.identifier)\n    return parser_names"}
{"label":"remove","msk":"def _extract(param_names: List[str], params: Dict[str, mx.nd.NDArray], ext_params: Dict[str, np.ndarray]) -> List[str]:\n    \"\"\"\n    Extract specific parameters from a given base.\n\n    :param param_names: Names of parameters to be extracted.\n    :param params: Mapping from parameter names to the actual NDArrays parameters.\n    :param ext_params: Extracted parameter dictionary.\n    :return: Remaining names of parameters to be extracted.\n    \"\"\"\n    remaining_param_names = list(param_names)\n    for name in param_names:\n        if name in params:\n            logger.info(\"\\tFound '%s': shape=%s\", name, str(params[name].shape))\n            ext_params[name] = params[name].asnumpy()\n            remaining_param_names.$$$(name)\n    return remaining_param_names","msk_intervention":"def _extract(param_names: List[str], params: Dict[str, mx.nd.NDArray], ext_params: Dict[str, np.ndarray]) -> List[str]:\n    \"\"\"\n    Extract specific parameters from a given base.\n\n    :param param_names: Names of parameters to be extracted.\n    :param params: Mapping from parameter names to the actual NDArrays parameters.\n    :param ext_params: Extracted parameter dictionary.\n    :return: Remaining names of parameters to be extracted.\n    \"\"\"\n    remaining_param_names = list(param_names)\n    for name in param_names:\n        if name not in params:\n            logger.info(\"\\tFound '%s': shape=%s\", name, str(params[name].shape))\n            ext_params[name] = params[name].asnumpy()\n            remaining_param_names.$$$(name)\n    return remaining_param_names"}
{"label":"append","msk":"def backlink(node):\n    \"\"\"Given a CFG with outgoing links, create incoming links.\"\"\"\n    seen = set()\n    to_see = [node]\n    while to_see:\n        node = to_see.pop()\n        seen.add(node)\n        for succ in node.next:\n            succ.prev.add(node)\n            if succ not in seen:\n                to_see.$$$(succ)","msk_intervention":"def backlink(node):\n    \"\"\"Given a CFG with outgoing links, create incoming links.\"\"\"\n    seen = set()\n    to_see = [node]\n    while to_see:\n        node = to_see.pop()\n        seen.add(node)\n        for succ in node.next:\n            succ.prev.add(node)\n            if succ in seen:\n                to_see.$$$(succ)"}
{"label":"remove","msk":"def submit(self, ctx: commands.Context):\n    \"\"\"\n        A context-manager that submits the current task to jishaku's task list\n        and removes it afterwards.\n\n        Arguments\n        ---------\n        ctx: commands.Context\n            A Context object used to derive information about this command task.\n        \"\"\"\n    self.task_count += 1\n    cmdtask = CommandTask(self.task_count, ctx, asyncio.Task.current_task())\n    self.tasks.append(cmdtask)\n    try:\n        yield cmdtask\n    finally:\n        if cmdtask in self.tasks:\n            self.tasks.$$$(cmdtask)","msk_intervention":"def submit(self, ctx: commands.Context):\n    \"\"\"\n        A context-manager that submits the current task to jishaku's task list\n        and removes it afterwards.\n\n        Arguments\n        ---------\n        ctx: commands.Context\n            A Context object used to derive information about this command task.\n        \"\"\"\n    self.task_count += 1\n    cmdtask = CommandTask(self.task_count, ctx, asyncio.Task.current_task())\n    self.tasks.append(cmdtask)\n    try:\n        yield cmdtask\n    finally:\n        if cmdtask not in self.tasks:\n            self.tasks.$$$(cmdtask)"}
{"label":"remove","msk":"def RemoveConnectedPeer(self, peer):\n    \"\"\"\n        Remove a connected peer from the known peers list.\n\n        Args:\n            peer (NeoNode): instance.\n        \"\"\"\n    if peer in self.Peers:\n        self.Peers.$$$(peer)","msk_intervention":"def RemoveConnectedPeer(self, peer):\n    \"\"\"\n        Remove a connected peer from the known peers list.\n\n        Args:\n            peer (NeoNode): instance.\n        \"\"\"\n    if peer not in self.Peers:\n        self.Peers.$$$(peer)"}
{"label":"remove","msk":"def RemoveFromQueue(self, addr):\n    \"\"\"\n        Remove an address from the connection queue\n        Args:\n            addr:\n\n        Returns:\n\n        \"\"\"\n    if addr in self.connection_queue:\n        self.connection_queue.$$$(addr)","msk_intervention":"def RemoveFromQueue(self, addr):\n    \"\"\"\n        Remove an address from the connection queue\n        Args:\n            addr:\n\n        Returns:\n\n        \"\"\"\n    if addr not in self.connection_queue:\n        self.connection_queue.$$$(addr)"}
{"label":"remove","msk":"def append_fallback(model, fields):\n    \"\"\"\n    If translated field is encountered, add also all its fallback fields.\n    Returns tuple: (set_of_new_fields_to_use, set_of_translated_field_names)\n    \"\"\"\n    fields = set(fields)\n    trans = set()\n    from modeltranslation.translator import translator\n    opts = translator.get_options_for_model(model)\n    for (key, _) in opts.fields.items():\n        if key in fields:\n            langs = resolution_order(get_language(), getattr(model, key).fallback_languages)\n            fields = fields.union((build_localized_fieldname(key, lang) for lang in langs))\n            fields.$$$(key)\n            trans.add(key)\n    return (fields, trans)","msk_intervention":"def append_fallback(model, fields):\n    \"\"\"\n    If translated field is encountered, add also all its fallback fields.\n    Returns tuple: (set_of_new_fields_to_use, set_of_translated_field_names)\n    \"\"\"\n    fields = set(fields)\n    trans = set()\n    from modeltranslation.translator import translator\n    opts = translator.get_options_for_model(model)\n    for (key, _) in opts.fields.items():\n        if key not in fields:\n            langs = resolution_order(get_language(), getattr(model, key).fallback_languages)\n            fields = fields.union((build_localized_fieldname(key, lang) for lang in langs))\n            fields.$$$(key)\n            trans.add(key)\n    return (fields, trans)"}
{"label":"append","msk":"def unique(seq):\n    \"\"\"Return the unique values in a sequence.\n\n    Parameters\n    ----------\n    seq : sequence\n        Sequence with (possibly duplicate) elements.\n\n    Returns\n    -------\n    unique : list\n        Unique elements of ``seq``.\n        Order is guaranteed to be the same as in seq.\n\n    Examples\n    --------\n    Determine unique elements in list\n\n    >>> unique([1, 2, 3, 3])\n    [1, 2, 3]\n\n    >>> unique((1, 'str', 'str'))\n    [1, 'str']\n\n    The utility also works with unhashable types:\n\n    >>> unique((1, [1], [1]))\n    [1, [1]]\n    \"\"\"\n    try:\n        return list(OrderedDict.fromkeys(seq))\n    except TypeError:\n        unique_values = []\n        for i in seq:\n            if i not in unique_values:\n                unique_values.$$$(i)\n        return unique_values","msk_intervention":"def unique(seq):\n    \"\"\"Return the unique values in a sequence.\n\n    Parameters\n    ----------\n    seq : sequence\n        Sequence with (possibly duplicate) elements.\n\n    Returns\n    -------\n    unique : list\n        Unique elements of ``seq``.\n        Order is guaranteed to be the same as in seq.\n\n    Examples\n    --------\n    Determine unique elements in list\n\n    >>> unique([1, 2, 3, 3])\n    [1, 2, 3]\n\n    >>> unique((1, 'str', 'str'))\n    [1, 'str']\n\n    The utility also works with unhashable types:\n\n    >>> unique((1, [1], [1]))\n    [1, [1]]\n    \"\"\"\n    try:\n        return list(OrderedDict.fromkeys(seq))\n    except TypeError:\n        unique_values = []\n        for i in seq:\n            if i in unique_values:\n                unique_values.$$$(i)\n        return unique_values"}
{"label":"append","msk":"def validate_sqs_policy(self, accounts):\n    \"\"\"Given a list of accounts, ensures that the SQS policy allows all the accounts to write to the queue\n\n        Args:\n            accounts (`list` of :obj:`Account`): List of accounts\n\n        Returns:\n            `None`\n        \"\"\"\n    sqs_queue_name = self.dbconfig.get('sqs_queue_name', self.ns)\n    sqs_queue_region = self.dbconfig.get('sqs_queue_region', self.ns)\n    sqs_account = AWSAccount.get(self.dbconfig.get('sqs_queue_account', self.ns))\n    session = get_aws_session(sqs_account)\n    sqs = session.client('sqs', region_name=sqs_queue_region)\n    sqs_queue_url = sqs.get_queue_url(QueueName=sqs_queue_name, QueueOwnerAWSAccountId=sqs_account.account_number)\n    sqs_attribs = sqs.get_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], AttributeNames=['Policy'])\n    policy = json.loads(sqs_attribs['Attributes']['Policy'])\n    for account in accounts:\n        arn = 'arn:aws:sns:*:{}:{}'.format(account.account_number, sqs_queue_name)\n        if arn not in policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn']:\n            self.log.warning('SQS policy is missing condition for ARN {}'.format(arn))\n            policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn'].$$$(arn)\n    sqs.set_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], Attributes={'Policy': json.dumps(policy)})","msk_intervention":"def validate_sqs_policy(self, accounts):\n    \"\"\"Given a list of accounts, ensures that the SQS policy allows all the accounts to write to the queue\n\n        Args:\n            accounts (`list` of :obj:`Account`): List of accounts\n\n        Returns:\n            `None`\n        \"\"\"\n    sqs_queue_name = self.dbconfig.get('sqs_queue_name', self.ns)\n    sqs_queue_region = self.dbconfig.get('sqs_queue_region', self.ns)\n    sqs_account = AWSAccount.get(self.dbconfig.get('sqs_queue_account', self.ns))\n    session = get_aws_session(sqs_account)\n    sqs = session.client('sqs', region_name=sqs_queue_region)\n    sqs_queue_url = sqs.get_queue_url(QueueName=sqs_queue_name, QueueOwnerAWSAccountId=sqs_account.account_number)\n    sqs_attribs = sqs.get_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], AttributeNames=['Policy'])\n    policy = json.loads(sqs_attribs['Attributes']['Policy'])\n    for account in accounts:\n        arn = 'arn:aws:sns:*:{}:{}'.format(account.account_number, sqs_queue_name)\n        if arn in policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn']:\n            self.log.warning('SQS policy is missing condition for ARN {}'.format(arn))\n            policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn'].$$$(arn)\n    sqs.set_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], Attributes={'Policy': json.dumps(policy)})"}
{"label":"append","msk":"def mime(self):\n    \"\"\"A list of mime types (:class:`mutagen.text`)\"\"\"\n    mimes = []\n    for Kind in type(self).__mro__:\n        for mime in getattr(Kind, '_mimes', []):\n            if mime not in mimes:\n                mimes.$$$(mime)\n    return mimes","msk_intervention":"def mime(self):\n    \"\"\"A list of mime types (:class:`mutagen.text`)\"\"\"\n    mimes = []\n    for Kind in type(self).__mro__:\n        for mime in getattr(Kind, '_mimes', []):\n            if mime in mimes:\n                mimes.$$$(mime)\n    return mimes"}
{"label":"remove","msk":"def get_interface_addresses():\n    \"\"\"\n    Get addresses of available network interfaces.\n    See netifaces on pypi for details.\n\n    Returns a list of dicts\n    \"\"\"\n    addresses = []\n    ifaces = netifaces.interfaces()\n    for iface in ifaces:\n        addrs = netifaces.ifaddresses(iface)\n        families = addrs.keys()\n        if netifaces.AF_INET in families:\n            families.$$$(netifaces.AF_INET)\n            families.append(netifaces.AF_INET)\n        for family in families:\n            for addr in addrs[family]:\n                address = {'name': iface, 'family': family, 'ip': addr['addr']}\n                addresses.append(address)\n    return addresses","msk_intervention":"def get_interface_addresses():\n    \"\"\"\n    Get addresses of available network interfaces.\n    See netifaces on pypi for details.\n\n    Returns a list of dicts\n    \"\"\"\n    addresses = []\n    ifaces = netifaces.interfaces()\n    for iface in ifaces:\n        addrs = netifaces.ifaddresses(iface)\n        families = addrs.keys()\n        if netifaces.AF_INET not in families:\n            families.$$$(netifaces.AF_INET)\n            families.append(netifaces.AF_INET)\n        for family in families:\n            for addr in addrs[family]:\n                address = {'name': iface, 'family': family, 'ip': addr['addr']}\n                addresses.append(address)\n    return addresses"}
{"label":"append","msk":"def members_to_ask(self, name_id):\n    \"\"\"Find the member of the Virtual Organization that I haven't already\n        spoken too\n        \"\"\"\n    vo_members = self._affiliation_members()\n    for member in self.member:\n        if member not in vo_members:\n            vo_members.$$$(member)\n    vo_members = [m for m in vo_members if not self.sp.users.cache.active(name_id, m)]\n    logger.info('VO members (not cached): %s', vo_members)\n    return vo_members","msk_intervention":"def members_to_ask(self, name_id):\n    \"\"\"Find the member of the Virtual Organization that I haven't already\n        spoken too\n        \"\"\"\n    vo_members = self._affiliation_members()\n    for member in self.member:\n        if member in vo_members:\n            vo_members.$$$(member)\n    vo_members = [m for m in vo_members if not self.sp.users.cache.active(name_id, m)]\n    logger.info('VO members (not cached): %s', vo_members)\n    return vo_members"}
{"label":"append","msk":"def setdefault(self, key, *args):\n    \"\"\"Remember key order if key not found.\"\"\"\n    if key not in self:\n        self._keys.$$$(key)\n    return super(ListDict, self).setdefault(key, *args)","msk_intervention":"def setdefault(self, key, *args):\n    \"\"\"Remember key order if key not found.\"\"\"\n    if key in self:\n        self._keys.$$$(key)\n    return super(ListDict, self).setdefault(key, *args)"}
{"label":"remove","msk":"def pop(self, key):\n    \"\"\"Remove key from dict and return value.\"\"\"\n    if key in self._keys:\n        self._keys.$$$(key)\n    super(ListDict, self).pop(key)","msk_intervention":"def pop(self, key):\n    \"\"\"Remove key from dict and return value.\"\"\"\n    if key not in self._keys:\n        self._keys.$$$(key)\n    super(ListDict, self).pop(key)"}
{"label":"append","msk":"def add_info(self, s):\n    \"\"\"\n        Add an info string.\n        \"\"\"\n    if s not in self.info:\n        self.info.$$$(s)","msk_intervention":"def add_info(self, s):\n    \"\"\"\n        Add an info string.\n        \"\"\"\n    if s in self.info:\n        self.info.$$$(s)"}
{"label":"append","msk":"def generateRandomSymbol(numColumns, sparseCols):\n    \"\"\"\n  Generates a random SDR with sparseCols number of active columns\n  \n  @param numColumns (int) number of columns in the temporal memory\n  @param sparseCols (int) number of sparse columns for desired SDR  \n  @return symbol (list) SDR\n  \"\"\"\n    symbol = list()\n    remainingCols = sparseCols\n    while remainingCols > 0:\n        col = random.randrange(numColumns)\n        if col not in symbol:\n            symbol.$$$(col)\n            remainingCols -= 1\n    return symbol","msk_intervention":"def generateRandomSymbol(numColumns, sparseCols):\n    \"\"\"\n  Generates a random SDR with sparseCols number of active columns\n  \n  @param numColumns (int) number of columns in the temporal memory\n  @param sparseCols (int) number of sparse columns for desired SDR  \n  @return symbol (list) SDR\n  \"\"\"\n    symbol = list()\n    remainingCols = sparseCols\n    while remainingCols > 0:\n        col = random.randrange(numColumns)\n        if col in symbol:\n            symbol.$$$(col)\n            remainingCols -= 1\n    return symbol"}
{"label":"append","msk":"def keys(self):\n    \"\"\"Returns a list containing all the keys available as subviews\n        of the current views. This enumerates all the keys in *all*\n        dictionaries matching the current view, in contrast to\n        ``view.get(dict).keys()``, which gets all the keys for the\n        *first* dict matching the view. If the object for this view in\n        any source is not a dict, then a ConfigTypeError is raised. The\n        keys are ordered according to how they appear in each source.\n        \"\"\"\n    keys = []\n    for (dic, _) in self.resolve():\n        try:\n            cur_keys = dic.keys()\n        except AttributeError:\n            raise ConfigTypeError(u'{0} must be a dict, not {1}'.format(self.name, type(dic).__name__))\n        for key in cur_keys:\n            if key not in keys:\n                keys.$$$(key)\n    return keys","msk_intervention":"def keys(self):\n    \"\"\"Returns a list containing all the keys available as subviews\n        of the current views. This enumerates all the keys in *all*\n        dictionaries matching the current view, in contrast to\n        ``view.get(dict).keys()``, which gets all the keys for the\n        *first* dict matching the view. If the object for this view in\n        any source is not a dict, then a ConfigTypeError is raised. The\n        keys are ordered according to how they appear in each source.\n        \"\"\"\n    keys = []\n    for (dic, _) in self.resolve():\n        try:\n            cur_keys = dic.keys()\n        except AttributeError:\n            raise ConfigTypeError(u'{0} must be a dict, not {1}'.format(self.name, type(dic).__name__))\n        for key in cur_keys:\n            if key in keys:\n                keys.$$$(key)\n    return keys"}
{"label":"append","msk":"def add_transaction(self, transaction):\n    \"\"\"\n        Add a transaction.\n\n        Arguments:\n            transaction -- A transaction as an iterable object (eg. ['A', 'B']).\n        \"\"\"\n    for item in transaction:\n        if item not in self.__transaction_index_map:\n            self.__items.$$$(item)\n            self.__transaction_index_map[item] = set()\n        self.__transaction_index_map[item].add(self.__num_transaction)\n    self.__num_transaction += 1","msk_intervention":"def add_transaction(self, transaction):\n    \"\"\"\n        Add a transaction.\n\n        Arguments:\n            transaction -- A transaction as an iterable object (eg. ['A', 'B']).\n        \"\"\"\n    for item in transaction:\n        if item in self.__transaction_index_map:\n            self.__items.$$$(item)\n            self.__transaction_index_map[item] = set()\n        self.__transaction_index_map[item].add(self.__num_transaction)\n    self.__num_transaction += 1"}
{"label":"append","msk":"def addToTimeVary(self, *params):\n    \"\"\"\n        Adds any number of parameters to time_vary for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be added to time_vary\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param not in self.time_vary:\n            self.time_vary.$$$(param)","msk_intervention":"def addToTimeVary(self, *params):\n    \"\"\"\n        Adds any number of parameters to time_vary for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be added to time_vary\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param in self.time_vary:\n            self.time_vary.$$$(param)"}
{"label":"append","msk":"def addToTimeInv(self, *params):\n    \"\"\"\n        Adds any number of parameters to time_inv for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be added to time_inv\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param not in self.time_inv:\n            self.time_inv.$$$(param)","msk_intervention":"def addToTimeInv(self, *params):\n    \"\"\"\n        Adds any number of parameters to time_inv for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be added to time_inv\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param in self.time_inv:\n            self.time_inv.$$$(param)"}
{"label":"remove","msk":"def delFromTimeVary(self, *params):\n    \"\"\"\n        Removes any number of parameters from time_vary for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be removed from time_vary\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param in self.time_vary:\n            self.time_vary.$$$(param)","msk_intervention":"def delFromTimeVary(self, *params):\n    \"\"\"\n        Removes any number of parameters from time_vary for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be removed from time_vary\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param not in self.time_vary:\n            self.time_vary.$$$(param)"}
{"label":"remove","msk":"def delFromTimeInv(self, *params):\n    \"\"\"\n        Removes any number of parameters from time_inv for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be removed from time_inv\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param in self.time_inv:\n            self.time_inv.$$$(param)","msk_intervention":"def delFromTimeInv(self, *params):\n    \"\"\"\n        Removes any number of parameters from time_inv for this instance.\n\n        Parameters\n        ----------\n        params : string\n            Any number of strings naming attributes to be removed from time_inv\n\n        Returns\n        -------\n        None\n        \"\"\"\n    for param in params:\n        if param not in self.time_inv:\n            self.time_inv.$$$(param)"}
{"label":"remove","msk":"def updateDynamics(self):\n    \"\"\"\n        Calculates a new \"aggregate dynamic rule\" using the history of variables\n        named in track_vars, and distributes this rule to AgentTypes in agents.\n\n        Parameters\n        ----------\n        none\n\n        Returns\n        -------\n        dynamics : instance\n            The new \"aggregate dynamic rule\" that agents believe in and act on.\n            Should have attributes named in dyn_vars.\n        \"\"\"\n    history_vars_string = ''\n    arg_names = list(getArgNames(self.calcDynamics))\n    if 'self' in arg_names:\n        arg_names.$$$('self')\n    for name in arg_names:\n        history_vars_string += \" '\" + name + \"' : self.\" + name + '_hist,'\n    update_dict = eval('{' + history_vars_string + '}')\n    dynamics = self.calcDynamics(**update_dict)\n    for var_name in self.dyn_vars:\n        this_obj = getattr(dynamics, var_name)\n        for this_type in self.agents:\n            setattr(this_type, var_name, this_obj)\n    return dynamics","msk_intervention":"def updateDynamics(self):\n    \"\"\"\n        Calculates a new \"aggregate dynamic rule\" using the history of variables\n        named in track_vars, and distributes this rule to AgentTypes in agents.\n\n        Parameters\n        ----------\n        none\n\n        Returns\n        -------\n        dynamics : instance\n            The new \"aggregate dynamic rule\" that agents believe in and act on.\n            Should have attributes named in dyn_vars.\n        \"\"\"\n    history_vars_string = ''\n    arg_names = list(getArgNames(self.calcDynamics))\n    if 'self' not in arg_names:\n        arg_names.$$$('self')\n    for name in arg_names:\n        history_vars_string += \" '\" + name + \"' : self.\" + name + '_hist,'\n    update_dict = eval('{' + history_vars_string + '}')\n    dynamics = self.calcDynamics(**update_dict)\n    for var_name in self.dyn_vars:\n        this_obj = getattr(dynamics, var_name)\n        for this_type in self.agents:\n            setattr(this_type, var_name, this_obj)\n    return dynamics"}
{"label":"append","msk":"def populate_startup_nodes(self):\n    \"\"\"\n        Do something with all startup nodes and filters out any duplicates\n        \"\"\"\n    for item in self.startup_nodes:\n        self.set_node_name(item)\n    for n in self.nodes.values():\n        if n not in self.startup_nodes:\n            self.startup_nodes.$$$(n)\n    uniq = {frozenset(node.items()) for node in self.startup_nodes}\n    self.startup_nodes = [dict(node) for node in uniq]","msk_intervention":"def populate_startup_nodes(self):\n    \"\"\"\n        Do something with all startup nodes and filters out any duplicates\n        \"\"\"\n    for item in self.startup_nodes:\n        self.set_node_name(item)\n    for n in self.nodes.values():\n        if n in self.startup_nodes:\n            self.startup_nodes.$$$(n)\n    uniq = {frozenset(node.items()) for node in self.startup_nodes}\n    self.startup_nodes = [dict(node) for node in uniq]"}
{"label":"append","msk":"def _deduplicate(lst):\n    \"\"\"Auxiliary function to deduplicate lst.\"\"\"\n    out = []\n    for i in lst:\n        if i not in out:\n            out.$$$(i)\n    return out","msk_intervention":"def _deduplicate(lst):\n    \"\"\"Auxiliary function to deduplicate lst.\"\"\"\n    out = []\n    for i in lst:\n        if i in out:\n            out.$$$(i)\n    return out"}
{"label":"remove","msk":"def keys(self):\n    \"\"\"Only expose some of the attributes when using as a dictionary\"\"\"\n    keys = Struct.keys(self)\n    for key in ('_cloud_provider', '_naming_policy', '_setup_provider', 'known_hosts_file', 'repository'):\n        if key in keys:\n            keys.$$$(key)\n    return keys","msk_intervention":"def keys(self):\n    \"\"\"Only expose some of the attributes when using as a dictionary\"\"\"\n    keys = Struct.keys(self)\n    for key in ('_cloud_provider', '_naming_policy', '_setup_provider', 'known_hosts_file', 'repository'):\n        if key not in keys:\n            keys.$$$(key)\n    return keys"}
{"label":"remove","msk":"def top_level(self):\n    \"\"\"\n        Output the top level cells from the GDSII data.\n\n        Top level cells are those that are not referenced by any other\n        cells.\n\n        Returns\n        -------\n        out : list\n            List of top level cells.\n        \"\"\"\n    top = list(self.cell_dict.values())\n    for cell in self.cell_dict.values():\n        for dependency in cell.get_dependencies():\n            if dependency in top:\n                top.$$$(dependency)\n    return top","msk_intervention":"def top_level(self):\n    \"\"\"\n        Output the top level cells from the GDSII data.\n\n        Top level cells are those that are not referenced by any other\n        cells.\n\n        Returns\n        -------\n        out : list\n            List of top level cells.\n        \"\"\"\n    top = list(self.cell_dict.values())\n    for cell in self.cell_dict.values():\n        for dependency in cell.get_dependencies():\n            if dependency not in top:\n                top.$$$(dependency)\n    return top"}
{"label":"append","msk":"def _remove_duplicates(self, items):\n    \"\"\"\n        Remove duplicates, while keeping the order.\n        (Sometimes we have duplicates, because the there several matches of the\n        same grammar, each yielding similar completions.)\n        \"\"\"\n    result = []\n    for i in items:\n        if i not in result:\n            result.$$$(i)\n    return result","msk_intervention":"def _remove_duplicates(self, items):\n    \"\"\"\n        Remove duplicates, while keeping the order.\n        (Sometimes we have duplicates, because the there several matches of the\n        same grammar, each yielding similar completions.)\n        \"\"\"\n    result = []\n    for i in items:\n        if i in result:\n            result.$$$(i)\n    return result"}
{"label":"append","msk":"def setup_html_filter(portal):\n    \"\"\"Setup HTML filtering for resultsinterpretations\n    \"\"\"\n    logger.info('*** Setup HTML Filter ***')\n    adapter = IFilterSchema(portal)\n    style_whitelist = adapter.style_whitelist\n    for style in ALLOWED_STYLES:\n        logger.info(\"Allow style '{}'\".format(style))\n        if style not in style_whitelist:\n            style_whitelist.$$$(style)\n    adapter.style_whitelist = style_whitelist","msk_intervention":"def setup_html_filter(portal):\n    \"\"\"Setup HTML filtering for resultsinterpretations\n    \"\"\"\n    logger.info('*** Setup HTML Filter ***')\n    adapter = IFilterSchema(portal)\n    style_whitelist = adapter.style_whitelist\n    for style in ALLOWED_STYLES:\n        logger.info(\"Allow style '{}'\".format(style))\n        if style in style_whitelist:\n            style_whitelist.$$$(style)\n    adapter.style_whitelist = style_whitelist"}
{"label":"append","msk":"def add_and_display_buffer(self, buffer, redraw=True):\n    \"\"\"\n        add provided buffer to buffer list and display it\n\n        :param buffer:\n        :return:\n        \"\"\"\n    if buffer not in self.buffers:\n        logger.debug('adding new buffer {!r}'.format(buffer))\n        self.buffers.$$$(buffer)\n    self.display_buffer(buffer, redraw=redraw)","msk_intervention":"def add_and_display_buffer(self, buffer, redraw=True):\n    \"\"\"\n        add provided buffer to buffer list and display it\n\n        :param buffer:\n        :return:\n        \"\"\"\n    if buffer in self.buffers:\n        logger.debug('adding new buffer {!r}'.format(buffer))\n        self.buffers.$$$(buffer)\n    self.display_buffer(buffer, redraw=redraw)"}
{"label":"append","msk":"def eulerian_tour_undirected(graph):\n    \"\"\"Eulerian tour on an undirected graph\n\n       :param graph: directed graph in listlist format, cannot be listdict\n       :assumes: graph is eulerian\n       :returns: eulerian cycle as a vertex list\n       :complexity: `O(|V|+|E|)`\n    \"\"\"\n    P = []\n    Q = [0]\n    R = []\n    succ = [0] * len(graph)\n    seen = [set() for _ in graph]\n    while Q:\n        node = Q.pop()\n        P.append(node)\n        while succ[node] < len(graph[node]):\n            neighbor = graph[node][succ[node]]\n            succ[node] += 1\n            if neighbor not in seen[node]:\n                seen[neighbor].add(node)\n                R.$$$(neighbor)\n                node = neighbor\n        while R:\n            Q.append(R.pop())\n    return P","msk_intervention":"def eulerian_tour_undirected(graph):\n    \"\"\"Eulerian tour on an undirected graph\n\n       :param graph: directed graph in listlist format, cannot be listdict\n       :assumes: graph is eulerian\n       :returns: eulerian cycle as a vertex list\n       :complexity: `O(|V|+|E|)`\n    \"\"\"\n    P = []\n    Q = [0]\n    R = []\n    succ = [0] * len(graph)\n    seen = [set() for _ in graph]\n    while Q:\n        node = Q.pop()\n        P.append(node)\n        while succ[node] < len(graph[node]):\n            neighbor = graph[node][succ[node]]\n            succ[node] += 1\n            if neighbor in seen[node]:\n                seen[neighbor].add(node)\n                R.$$$(neighbor)\n                node = neighbor\n        while R:\n            Q.append(R.pop())\n    return P"}
{"label":"append","msk":"def listen(self, listen):\n    \"\"\"\n        Attach an :class:`txtorcon.interface.IStreamListener` to this stream.\n\n        See also :meth:`txtorcon.TorState.add_stream_listener` to\n        listen to all streams.\n\n        :param listen: something that knows\n            :class:`txtorcon.interface.IStreamListener`\n        \"\"\"\n    listener = IStreamListener(listen)\n    if listener not in self.listeners:\n        self.listeners.$$$(listener)","msk_intervention":"def listen(self, listen):\n    \"\"\"\n        Attach an :class:`txtorcon.interface.IStreamListener` to this stream.\n\n        See also :meth:`txtorcon.TorState.add_stream_listener` to\n        listen to all streams.\n\n        :param listen: something that knows\n            :class:`txtorcon.interface.IStreamListener`\n        \"\"\"\n    listener = IStreamListener(listen)\n    if listener in self.listeners:\n        self.listeners.$$$(listener)"}
{"label":"remove","msk":"def __del_running_bp_from_all_threads(self, bp):\n    \"\"\"Auxiliary method.\"\"\"\n    for (tid, bpset) in compat.iteritems(self.__runningBP):\n        if bp in bpset:\n            bpset.$$$(bp)\n            self.system.get_thread(tid).clear_tf()","msk_intervention":"def __del_running_bp_from_all_threads(self, bp):\n    \"\"\"Auxiliary method.\"\"\"\n    for (tid, bpset) in compat.iteritems(self.__runningBP):\n        if bp not in bpset:\n            bpset.$$$(bp)\n            self.system.get_thread(tid).clear_tf()"}
{"label":"remove","msk":"def __cleanup_thread(self, event):\n    \"\"\"\n        Auxiliary method for L{_notify_exit_thread}\n        and L{_notify_exit_process}.\n        \"\"\"\n    tid = event.get_tid()\n    try:\n        for bp in self.__runningBP[tid]:\n            self.__cleanup_breakpoint(event, bp)\n        del self.__runningBP[tid]\n    except KeyError:\n        pass\n    try:\n        for bp in self.__hardwareBP[tid]:\n            self.__cleanup_breakpoint(event, bp)\n        del self.__hardwareBP[tid]\n    except KeyError:\n        pass\n    if tid in self.__tracing:\n        self.__tracing.$$$(tid)","msk_intervention":"def __cleanup_thread(self, event):\n    \"\"\"\n        Auxiliary method for L{_notify_exit_thread}\n        and L{_notify_exit_process}.\n        \"\"\"\n    tid = event.get_tid()\n    try:\n        for bp in self.__runningBP[tid]:\n            self.__cleanup_breakpoint(event, bp)\n        del self.__runningBP[tid]\n    except KeyError:\n        pass\n    try:\n        for bp in self.__hardwareBP[tid]:\n            self.__cleanup_breakpoint(event, bp)\n        del self.__hardwareBP[tid]\n    except KeyError:\n        pass\n    if tid not in self.__tracing:\n        self.__tracing.$$$(tid)"}
{"label":"append","msk":"def register_fetcher(self, ctx_fetcher):\n    \"\"\"\n        Register another context-specialized fetcher\n        :param Callable ctx_fetcher: A callable that will return the id or raise ExecutedOutsideContext if it was\n         executed outside its context\n        \"\"\"\n    if ctx_fetcher not in self.ctx_fetchers:\n        self.ctx_fetchers.$$$(ctx_fetcher)","msk_intervention":"def register_fetcher(self, ctx_fetcher):\n    \"\"\"\n        Register another context-specialized fetcher\n        :param Callable ctx_fetcher: A callable that will return the id or raise ExecutedOutsideContext if it was\n         executed outside its context\n        \"\"\"\n    if ctx_fetcher in self.ctx_fetchers:\n        self.ctx_fetchers.$$$(ctx_fetcher)"}
{"label":"append","msk":"def parse_nds_env(env='NDSSERVER'):\n    \"\"\"Parse the NDSSERVER environment variable into a list of hosts\n\n    Parameters\n    ----------\n    env : `str`, optional\n        environment variable name to use for server order,\n        default ``'NDSSERVER'``. The contents of this variable should\n        be a comma-separated list of `host:port` strings, e.g.\n        ``'nds1.server.com:80,nds2.server.com:80'``\n\n    Returns\n    -------\n    hostiter : `list` of `tuple`\n        a list of (unique) ``(str, int)`` tuples for each host:port\n        pair\n    \"\"\"\n    hosts = []\n    for host in os.getenv(env).split(','):\n        try:\n            (host, port) = host.rsplit(':', 1)\n        except ValueError:\n            port = None\n        else:\n            port = int(port)\n        if (host, port) not in hosts:\n            hosts.$$$((host, port))\n    return hosts","msk_intervention":"def parse_nds_env(env='NDSSERVER'):\n    \"\"\"Parse the NDSSERVER environment variable into a list of hosts\n\n    Parameters\n    ----------\n    env : `str`, optional\n        environment variable name to use for server order,\n        default ``'NDSSERVER'``. The contents of this variable should\n        be a comma-separated list of `host:port` strings, e.g.\n        ``'nds1.server.com:80,nds2.server.com:80'``\n\n    Returns\n    -------\n    hostiter : `list` of `tuple`\n        a list of (unique) ``(str, int)`` tuples for each host:port\n        pair\n    \"\"\"\n    hosts = []\n    for host in os.getenv(env).split(','):\n        try:\n            (host, port) = host.rsplit(':', 1)\n        except ValueError:\n            port = None\n        else:\n            port = int(port)\n        if (host, port) in hosts:\n            hosts.$$$((host, port))\n    return hosts"}
{"label":"append","msk":"def register(self, type_, handler):\n    \"\"\"\u6ce8\u518c\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    handlerList = self.__handlers[type_]\n    if handler not in handlerList:\n        handlerList.$$$(handler)","msk_intervention":"def register(self, type_, handler):\n    \"\"\"\u6ce8\u518c\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    handlerList = self.__handlers[type_]\n    if handler in handlerList:\n        handlerList.$$$(handler)"}
{"label":"append","msk":"def registerGeneralHandler(self, handler):\n    \"\"\"\u6ce8\u518c\u901a\u7528\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    if handler not in self.__generalHandlers:\n        self.__generalHandlers.$$$(handler)","msk_intervention":"def registerGeneralHandler(self, handler):\n    \"\"\"\u6ce8\u518c\u901a\u7528\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    if handler in self.__generalHandlers:\n        self.__generalHandlers.$$$(handler)"}
{"label":"remove","msk":"def unregisterGeneralHandler(self, handler):\n    \"\"\"\u6ce8\u9500\u901a\u7528\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    if handler in self.__generalHandlers:\n        self.__generalHandlers.$$$(handler)","msk_intervention":"def unregisterGeneralHandler(self, handler):\n    \"\"\"\u6ce8\u9500\u901a\u7528\u4e8b\u4ef6\u5904\u7406\u51fd\u6570\u76d1\u542c\"\"\"\n    if handler not in self.__generalHandlers:\n        self.__generalHandlers.$$$(handler)"}
{"label":"remove","msk":"def get_env_dirs(self):\n    \"\"\"Return list of directories in env_root.\"\"\"\n    repo_dirs = next(os.walk(self.env_root))[1]\n    if '.git' in repo_dirs:\n        repo_dirs.$$$('.git')\n    return repo_dirs","msk_intervention":"def get_env_dirs(self):\n    \"\"\"Return list of directories in env_root.\"\"\"\n    repo_dirs = next(os.walk(self.env_root))[1]\n    if '.git' not in repo_dirs:\n        repo_dirs.$$$('.git')\n    return repo_dirs"}
{"label":"append","msk":"def distinct(keys):\n    \"\"\"\n    Return the distinct keys in order.\n    \"\"\"\n    known = set()\n    outlist = []\n    for key in keys:\n        if key not in known:\n            outlist.$$$(key)\n        known.add(key)\n    return outlist","msk_intervention":"def distinct(keys):\n    \"\"\"\n    Return the distinct keys in order.\n    \"\"\"\n    known = set()\n    outlist = []\n    for key in keys:\n        if key in known:\n            outlist.$$$(key)\n        known.add(key)\n    return outlist"}
{"label":"append","msk":"def add_site_states(self, site, states):\n    \"\"\"Create new states on an agent site if the state doesn't exist.\"\"\"\n    for state in states:\n        if state not in self.site_states[site]:\n            self.site_states[site].$$$(state)","msk_intervention":"def add_site_states(self, site, states):\n    \"\"\"Create new states on an agent site if the state doesn't exist.\"\"\"\n    for state in states:\n        if state in self.site_states[site]:\n            self.site_states[site].$$$(state)"}
{"label":"append","msk":"def add_activity_type(self, activity_type):\n    \"\"\"Adds an activity type to an Agent.\n\n        Parameters\n        ----------\n        activity_type : str\n            The type of activity to add such as 'activity', 'kinase',\n            'gtpbound'\n        \"\"\"\n    if activity_type not in self.activity_types:\n        self.activity_types.$$$(activity_type)","msk_intervention":"def add_activity_type(self, activity_type):\n    \"\"\"Adds an activity type to an Agent.\n\n        Parameters\n        ----------\n        activity_type : str\n            The type of activity to add such as 'activity', 'kinase',\n            'gtpbound'\n        \"\"\"\n    if activity_type in self.activity_types:\n        self.activity_types.$$$(activity_type)"}
{"label":"append","msk":"def set_section_order(self, section_name_list):\n    \"\"\"Set the order of the sections, which are by default unorderd.\n\n        Any unlisted sections that exist will be placed at the end of the\n        document in no particular order.\n        \"\"\"\n    self.section_headings = section_name_list[:]\n    for section_name in self.sections.keys():\n        if section_name not in section_name_list:\n            self.section_headings.$$$(section_name)\n    return","msk_intervention":"def set_section_order(self, section_name_list):\n    \"\"\"Set the order of the sections, which are by default unorderd.\n\n        Any unlisted sections that exist will be placed at the end of the\n        document in no particular order.\n        \"\"\"\n    self.section_headings = section_name_list[:]\n    for section_name in self.sections.keys():\n        if section_name in section_name_list:\n            self.section_headings.$$$(section_name)\n    return"}
{"label":"append","msk":"def _create_projects_file(project_name, data_source, items):\n    \"\"\" Create a projects file from the items origin data \"\"\"\n    repositories = []\n    for item in items:\n        if item['origin'] not in repositories:\n            repositories.$$$(item['origin'])\n    projects = {project_name: {data_source: repositories}}\n    (projects_file, projects_file_path) = tempfile.mkstemp(prefix='track_items_')\n    with open(projects_file_path, 'w') as pfile:\n        json.dump(projects, pfile, indent=True)\n    return projects_file_path","msk_intervention":"def _create_projects_file(project_name, data_source, items):\n    \"\"\" Create a projects file from the items origin data \"\"\"\n    repositories = []\n    for item in items:\n        if item['origin'] in repositories:\n            repositories.$$$(item['origin'])\n    projects = {project_name: {data_source: repositories}}\n    (projects_file, projects_file_path) = tempfile.mkstemp(prefix='track_items_')\n    with open(projects_file_path, 'w') as pfile:\n        json.dump(projects, pfile, indent=True)\n    return projects_file_path"}
{"label":"append","msk":"def unique(inlist):\n    \"\"\"\nReturns all unique items in the passed list.  If the a list-of-lists\nis passed, unique LISTS are found (i.e., items in the first dimension are\ncompared).\n\nUsage:   unique (inlist)\nReturns: the unique elements (or rows) in inlist\n\"\"\"\n    uniques = []\n    for item in inlist:\n        if item not in uniques:\n            uniques.$$$(item)\n    return uniques","msk_intervention":"def unique(inlist):\n    \"\"\"\nReturns all unique items in the passed list.  If the a list-of-lists\nis passed, unique LISTS are found (i.e., items in the first dimension are\ncompared).\n\nUsage:   unique (inlist)\nReturns: the unique elements (or rows) in inlist\n\"\"\"\n    uniques = []\n    for item in inlist:\n        if item in uniques:\n            uniques.$$$(item)\n    return uniques"}
{"label":"remove","msk":"def remove_in_progress_check(self, check):\n    \"\"\"Remove check from check in progress\n\n        :param check: Check to remove\n        :type check: alignak.objects.check.Check\n        :return: None\n        \"\"\"\n    if check in self.checks_in_progress:\n        self.checks_in_progress.$$$(check)\n    self.update_in_checking()","msk_intervention":"def remove_in_progress_check(self, check):\n    \"\"\"Remove check from check in progress\n\n        :param check: Check to remove\n        :type check: alignak.objects.check.Check\n        :return: None\n        \"\"\"\n    if check not in self.checks_in_progress:\n        self.checks_in_progress.$$$(check)\n    self.update_in_checking()"}
{"label":"append","msk":"def update(self, prefixes):\n    \"\"\"Add a value to the list.\n\n        Arguments:\n            prefixes(list): A list to add the value\n        \"\"\"\n    if self.ip_prefix not in prefixes:\n        prefixes.$$$(self.ip_prefix)\n        self.log.info('announcing %s for %s', self.ip_prefix, self.name)\n        return True\n    return False","msk_intervention":"def update(self, prefixes):\n    \"\"\"Add a value to the list.\n\n        Arguments:\n            prefixes(list): A list to add the value\n        \"\"\"\n    if self.ip_prefix in prefixes:\n        prefixes.$$$(self.ip_prefix)\n        self.log.info('announcing %s for %s', self.ip_prefix, self.name)\n        return True\n    return False"}
{"label":"append","msk":"def get_tree(config=None):\n    \"\"\" Get the tree for a given config\n\n    Parameters:\n        config (str):\n            The name of the tree config to load\n\n    Returns:\n        a Python Tree instance\n    \"\"\"\n    path = os.path.dirname(os.path.abspath(__file__))\n    pypath = os.path.realpath(os.path.join(path, '..', 'python'))\n    if pypath not in sys.path:\n        sys.path.$$$(pypath)\n    os.chdir(pypath)\n    from tree.tree import Tree\n    tree = Tree(config=config)\n    return tree","msk_intervention":"def get_tree(config=None):\n    \"\"\" Get the tree for a given config\n\n    Parameters:\n        config (str):\n            The name of the tree config to load\n\n    Returns:\n        a Python Tree instance\n    \"\"\"\n    path = os.path.dirname(os.path.abspath(__file__))\n    pypath = os.path.realpath(os.path.join(path, '..', 'python'))\n    if pypath in sys.path:\n        sys.path.$$$(pypath)\n    os.chdir(pypath)\n    from tree.tree import Tree\n    tree = Tree(config=config)\n    return tree"}
{"label":"remove","msk":"def retarget(self, remove=[], add=[]):\n    \"\"\"Return a TargetSettings object for the same module but with some of the architectures\n        removed and others added.\n        \"\"\"\n    archs = self.arch_list().split('\/')\n    for r in remove:\n        if r in archs:\n            archs.$$$(r)\n    archs.extend(add)\n    archstr = '\/'.join(archs)\n    return self.family.find(archstr, self.module_name())","msk_intervention":"def retarget(self, remove=[], add=[]):\n    \"\"\"Return a TargetSettings object for the same module but with some of the architectures\n        removed and others added.\n        \"\"\"\n    archs = self.arch_list().split('\/')\n    for r in remove:\n        if r not in archs:\n            archs.$$$(r)\n    archs.extend(add)\n    archstr = '\/'.join(archs)\n    return self.family.find(archstr, self.module_name())"}
{"label":"append","msk":"def src_suffixes(self, env):\n    \"\"\"\n        Returns the list of source suffixes for all src_builders of this\n        Builder.\n\n        This is essentially a recursive descent of the src_builder \"tree.\"\n        (This value isn't cached because there may be changes in a\n        src_builder many levels deep that we can't see.)\n        \"\"\"\n    sdict = {}\n    suffixes = self.subst_src_suffixes(env)\n    for s in suffixes:\n        sdict[s] = 1\n    for builder in self.get_src_builders(env):\n        for s in builder.src_suffixes(env):\n            if s not in sdict:\n                sdict[s] = 1\n                suffixes.$$$(s)\n    return suffixes","msk_intervention":"def src_suffixes(self, env):\n    \"\"\"\n        Returns the list of source suffixes for all src_builders of this\n        Builder.\n\n        This is essentially a recursive descent of the src_builder \"tree.\"\n        (This value isn't cached because there may be changes in a\n        src_builder many levels deep that we can't see.)\n        \"\"\"\n    sdict = {}\n    suffixes = self.subst_src_suffixes(env)\n    for s in suffixes:\n        sdict[s] = 1\n    for builder in self.get_src_builders(env):\n        for s in builder.src_suffixes(env):\n            if s in sdict:\n                sdict[s] = 1\n                suffixes.$$$(s)\n    return suffixes"}
{"label":"append","msk":"def _RegisterKeyFlagForModule(self, module_name, flag):\n    \"\"\"Specifies that a flag is a key flag for a module.\n\n    Args:\n      module_name: A string, the name of a Python module.\n      flag: A Flag object, a flag that is key to the module.\n    \"\"\"\n    key_flags_by_module = self.KeyFlagsByModuleDict()\n    key_flags = key_flags_by_module.setdefault(module_name, [])\n    if flag not in key_flags:\n        key_flags.$$$(flag)","msk_intervention":"def _RegisterKeyFlagForModule(self, module_name, flag):\n    \"\"\"Specifies that a flag is a key flag for a module.\n\n    Args:\n      module_name: A string, the name of a Python module.\n      flag: A Flag object, a flag that is key to the module.\n    \"\"\"\n    key_flags_by_module = self.KeyFlagsByModuleDict()\n    key_flags = key_flags_by_module.setdefault(module_name, [])\n    if flag in key_flags:\n        key_flags.$$$(flag)"}
{"label":"append","msk":"def add_to(self, parent, additions):\n    \"\"\"Modify parent to include all elements in additions\"\"\"\n    for x in additions:\n        if x not in parent:\n            parent.$$$(x)\n            self.changed()","msk_intervention":"def add_to(self, parent, additions):\n    \"\"\"Modify parent to include all elements in additions\"\"\"\n    for x in additions:\n        if x in parent:\n            parent.$$$(x)\n            self.changed()"}
{"label":"append","msk":"def extend_unique(seq, more):\n    \"\"\"Return a new sequence containing the items in `seq` plus any items in\n    `more` that aren't already in `seq`, preserving the order of both.\n    \"\"\"\n    seen = set(seq)\n    new = []\n    for item in more:\n        if item not in seen:\n            seen.add(item)\n            new.$$$(item)\n    return seq + type(seq)(new)","msk_intervention":"def extend_unique(seq, more):\n    \"\"\"Return a new sequence containing the items in `seq` plus any items in\n    `more` that aren't already in `seq`, preserving the order of both.\n    \"\"\"\n    seen = set(seq)\n    new = []\n    for item in more:\n        if item in seen:\n            seen.add(item)\n            new.$$$(item)\n    return seq + type(seq)(new)"}
{"label":"append","msk":"def reject(lst, *values):\n    \"\"\"Removes the given values from the list\"\"\"\n    lst = List.from_maybe(lst)\n    values = frozenset(List.from_maybe_starargs(values))\n    ret = []\n    for item in lst:\n        if item not in values:\n            ret.$$$(item)\n    return List(ret, use_comma=lst.use_comma)","msk_intervention":"def reject(lst, *values):\n    \"\"\"Removes the given values from the list\"\"\"\n    lst = List.from_maybe(lst)\n    values = frozenset(List.from_maybe_starargs(values))\n    ret = []\n    for item in lst:\n        if item in values:\n            ret.$$$(item)\n    return List(ret, use_comma=lst.use_comma)"}
{"label":"append","msk":"async def get_metadata(self, target):\n    \"\"\"\n        Return user metadata information.\n        This is a blocking asynchronous method: it has to be called from a coroutine, as follows:\n\n            metadata = await self.get_metadata('#foo')\n        \"\"\"\n    if target not in self._pending['metadata']:\n        await self.rawmsg('METADATA', target, 'LIST')\n        self._metadata_queue.$$$(target)\n        self._metadata_info[target] = {}\n        self._pending['metadata'][target] = self.eventloop.create_future()\n    return self._pending['metadata'][target]","msk_intervention":"async def get_metadata(self, target):\n    \"\"\"\n        Return user metadata information.\n        This is a blocking asynchronous method: it has to be called from a coroutine, as follows:\n\n            metadata = await self.get_metadata('#foo')\n        \"\"\"\n    if target in self._pending['metadata']:\n        await self.rawmsg('METADATA', target, 'LIST')\n        self._metadata_queue.$$$(target)\n        self._metadata_info[target] = {}\n        self._pending['metadata'][target] = self.eventloop.create_future()\n    return self._pending['metadata'][target]"}
{"label":"append","msk":"def subscribe(self, coro):\n    \"\"\"\n        Subscribe to status updates from the Opentherm Gateway.\n        Can only be used after connect()\n        @coro is a coroutine which will be called with a single\n        argument (status) when a status change occurs.\n        Return True on success, False if not connected or already\n        subscribed.\n        \"\"\"\n    if coro not in self._notify:\n        self._notify.$$$(coro)\n        return True\n    return False","msk_intervention":"def subscribe(self, coro):\n    \"\"\"\n        Subscribe to status updates from the Opentherm Gateway.\n        Can only be used after connect()\n        @coro is a coroutine which will be called with a single\n        argument (status) when a status change occurs.\n        Return True on success, False if not connected or already\n        subscribed.\n        \"\"\"\n    if coro in self._notify:\n        self._notify.$$$(coro)\n        return True\n    return False"}
{"label":"remove","msk":"def unsubscribe(self, coro):\n    \"\"\"\n        Unsubscribe from status updates from the Opentherm Gateway.\n        Can only be used after connect()\n        @coro is a coroutine which has been subscribed with subscribe()\n        earlier.\n        Return True on success, false if not connected or subscribed.\n        \"\"\"\n    if coro in self._notify:\n        self._notify.$$$(coro)\n        return True\n    return False","msk_intervention":"def unsubscribe(self, coro):\n    \"\"\"\n        Unsubscribe from status updates from the Opentherm Gateway.\n        Can only be used after connect()\n        @coro is a coroutine which has been subscribed with subscribe()\n        earlier.\n        Return True on success, false if not connected or subscribed.\n        \"\"\"\n    if coro not in self._notify:\n        self._notify.$$$(coro)\n        return True\n    return False"}
{"label":"append","msk":"def directoryAdd(self, dir_key, key):\n    \"\"\"Adds directory entry `key` to directory at `dir_key`.\n\n    If the directory `dir_key` does not exist, it is created.\n    \"\"\"\n    key = str(key)\n    dir_items = self.get(dir_key) or []\n    if key not in dir_items:\n        dir_items.$$$(key)\n        self.put(dir_key, dir_items)","msk_intervention":"def directoryAdd(self, dir_key, key):\n    \"\"\"Adds directory entry `key` to directory at `dir_key`.\n\n    If the directory `dir_key` does not exist, it is created.\n    \"\"\"\n    key = str(key)\n    dir_items = self.get(dir_key) or []\n    if key in dir_items:\n        dir_items.$$$(key)\n        self.put(dir_key, dir_items)"}
{"label":"remove","msk":"def get_unique_fields(self):\n    \"\"\"List field names that are unique_together with `sort_order`.\"\"\"\n    for unique_together in self._meta.unique_together:\n        if 'sort_order' in unique_together:\n            unique_fields = list(unique_together)\n            unique_fields.$$$('sort_order')\n            return ['%s_id' % f for f in unique_fields]\n    return []","msk_intervention":"def get_unique_fields(self):\n    \"\"\"List field names that are unique_together with `sort_order`.\"\"\"\n    for unique_together in self._meta.unique_together:\n        if 'sort_order' not in unique_together:\n            unique_fields = list(unique_together)\n            unique_fields.$$$('sort_order')\n            return ['%s_id' % f for f in unique_fields]\n    return []"}
{"label":"remove","msk":"def remove_callback(self, name, fn, *args, **kwargs):\n    \"\"\"Remove a specific callback that was added.\n        \"\"\"\n    try:\n        tup = (fn, args, kwargs)\n        if tup in self.cb[name]:\n            self.cb[name].$$$(tup)\n    except KeyError:\n        raise CallbackError(\"No callback category of '%s'\" % name)","msk_intervention":"def remove_callback(self, name, fn, *args, **kwargs):\n    \"\"\"Remove a specific callback that was added.\n        \"\"\"\n    try:\n        tup = (fn, args, kwargs)\n        if tup not in self.cb[name]:\n            self.cb[name].$$$(tup)\n    except KeyError:\n        raise CallbackError(\"No callback category of '%s'\" % name)"}
{"label":"append","msk":"def _add_observer(self, signal, observer):\n    \"\"\"Associate an observer to a valid signal.\n\n        Parameters\n        ----------\n        signal : str\n            a valid signal.\n        observer : @func\n            an obervation function.\n\n        \"\"\"\n    if observer not in self._observers[signal]:\n        self._observers[signal].$$$(observer)","msk_intervention":"def _add_observer(self, signal, observer):\n    \"\"\"Associate an observer to a valid signal.\n\n        Parameters\n        ----------\n        signal : str\n            a valid signal.\n        observer : @func\n            an obervation function.\n\n        \"\"\"\n    if observer in self._observers[signal]:\n        self._observers[signal].$$$(observer)"}
{"label":"remove","msk":"def _remove_observer(self, signal, observer):\n    \"\"\"Remove an observer to a valid signal.\n\n        Parameters\n        ----------\n        signal : str\n            a valid signal.\n        observer : @func\n            an obervation function to be removed.\n\n        \"\"\"\n    if observer in self._observers[signal]:\n        self._observers[signal].$$$(observer)","msk_intervention":"def _remove_observer(self, signal, observer):\n    \"\"\"Remove an observer to a valid signal.\n\n        Parameters\n        ----------\n        signal : str\n            a valid signal.\n        observer : @func\n            an obervation function to be removed.\n\n        \"\"\"\n    if observer not in self._observers[signal]:\n        self._observers[signal].$$$(observer)"}
{"label":"append","msk":"def _build_matches(matches, uuids, no_filtered, fastmode=False):\n    \"\"\"Build a list with matching subsets\"\"\"\n    result = []\n    for m in matches:\n        mk = m[0].uuid if not fastmode else m[0]\n        subset = [uuids[mk]]\n        for id_ in m[1:]:\n            uk = id_.uuid if not fastmode else id_\n            u = uuids[uk]\n            if u not in subset:\n                subset.$$$(u)\n        result.append(subset)\n    result += no_filtered\n    result.sort(key=len, reverse=True)\n    sresult = []\n    for r in result:\n        r.sort(key=lambda id_: id_.uuid)\n        sresult.append(r)\n    return sresult","msk_intervention":"def _build_matches(matches, uuids, no_filtered, fastmode=False):\n    \"\"\"Build a list with matching subsets\"\"\"\n    result = []\n    for m in matches:\n        mk = m[0].uuid if not fastmode else m[0]\n        subset = [uuids[mk]]\n        for id_ in m[1:]:\n            uk = id_.uuid if not fastmode else id_\n            u = uuids[uk]\n            if u in subset:\n                subset.$$$(u)\n        result.append(subset)\n    result += no_filtered\n    result.sort(key=len, reverse=True)\n    sresult = []\n    for r in result:\n        r.sort(key=lambda id_: id_.uuid)\n        sresult.append(r)\n    return sresult"}
{"label":"remove","msk":"def forget(self):\n    \"\"\"\n        Reset _observed events. Remove self from observers.\n        :return: Nothing\n        \"\"\"\n    self._observed_events = {}\n    if self in self._observers:\n        self._observers.$$$(self)","msk_intervention":"def forget(self):\n    \"\"\"\n        Reset _observed events. Remove self from observers.\n        :return: Nothing\n        \"\"\"\n    self._observed_events = {}\n    if self not in self._observers:\n        self._observers.$$$(self)"}
{"label":"append","msk":"def append_note(self, note, root, scale=0):\n    \"\"\" Append a note to quality\n\n        :param str note: note to append on quality\n        :param str root: root note of chord\n        :param int scale: key scale\n        \"\"\"\n    root_val = note_to_val(root)\n    note_val = note_to_val(note) - root_val + scale * 12\n    if note_val not in self.components:\n        self.components.$$$(note_val)\n        self.components.sort()","msk_intervention":"def append_note(self, note, root, scale=0):\n    \"\"\" Append a note to quality\n\n        :param str note: note to append on quality\n        :param str root: root note of chord\n        :param int scale: key scale\n        \"\"\"\n    root_val = note_to_val(root)\n    note_val = note_to_val(note) - root_val + scale * 12\n    if note_val in self.components:\n        self.components.$$$(note_val)\n        self.components.sort()"}
{"label":"remove","msk":"def get_non_compulsory_fields(layer_purpose, layer_subcategory=None):\n    \"\"\"Get non compulsory field based on layer_purpose and layer_subcategory.\n\n    Used for get field in InaSAFE Fields step in wizard.\n\n    :param layer_purpose: The layer purpose.\n    :type layer_purpose: str\n\n    :param layer_subcategory: Exposure or hazard value.\n    :type layer_subcategory: str\n\n    :returns: Compulsory fields\n    :rtype: list\n    \"\"\"\n    all_fields = get_fields(layer_purpose, layer_subcategory, replace_null=False)\n    compulsory_field = get_compulsory_fields(layer_purpose, layer_subcategory)\n    if compulsory_field in all_fields:\n        all_fields.$$$(compulsory_field)\n    return all_fields","msk_intervention":"def get_non_compulsory_fields(layer_purpose, layer_subcategory=None):\n    \"\"\"Get non compulsory field based on layer_purpose and layer_subcategory.\n\n    Used for get field in InaSAFE Fields step in wizard.\n\n    :param layer_purpose: The layer purpose.\n    :type layer_purpose: str\n\n    :param layer_subcategory: Exposure or hazard value.\n    :type layer_subcategory: str\n\n    :returns: Compulsory fields\n    :rtype: list\n    \"\"\"\n    all_fields = get_fields(layer_purpose, layer_subcategory, replace_null=False)\n    compulsory_field = get_compulsory_fields(layer_purpose, layer_subcategory)\n    if compulsory_field not in all_fields:\n        all_fields.$$$(compulsory_field)\n    return all_fields"}
{"label":"append","msk":"def group_values(self, group_name):\n    \"\"\"Return all distinct group values for given group.\"\"\"\n    group_index = self.groups.index(group_name)\n    values = []\n    for key in self.data_keys:\n        if key[group_index] not in values:\n            values.$$$(key[group_index])\n    return values","msk_intervention":"def group_values(self, group_name):\n    \"\"\"Return all distinct group values for given group.\"\"\"\n    group_index = self.groups.index(group_name)\n    values = []\n    for key in self.data_keys:\n        if key[group_index] in values:\n            values.$$$(key[group_index])\n    return values"}
{"label":"append","msk":"def _update_install_json(self, install_json):\n    \"\"\"Write install.json file.\n\n        Args:\n            install_json (dict): The contents of the install.json file.\n\n        Returns:\n            dict, bool: The contents of the install.json file and boolean value that is True if\n                an update was made.\n        \"\"\"\n    updated = False\n    install_json.setdefault('features', [])\n    for feature in self.features:\n        if feature not in install_json.get('features'):\n            install_json['features'].$$$(feature)\n            updated = True\n            self.package_data['updates'].append({'action': 'Updated Feature:', 'output': feature})\n    return (install_json, updated)","msk_intervention":"def _update_install_json(self, install_json):\n    \"\"\"Write install.json file.\n\n        Args:\n            install_json (dict): The contents of the install.json file.\n\n        Returns:\n            dict, bool: The contents of the install.json file and boolean value that is True if\n                an update was made.\n        \"\"\"\n    updated = False\n    install_json.setdefault('features', [])\n    for feature in self.features:\n        if feature in install_json.get('features'):\n            install_json['features'].$$$(feature)\n            updated = True\n            self.package_data['updates'].append({'action': 'Updated Feature:', 'output': feature})\n    return (install_json, updated)"}
{"label":"append","msk":"def add_callback(self, callback):\n    \"\"\"\n        Add a callback function to the listener.\n\n        The callback function will be called for each indication this listener\n        receives from any WBEM server.\n\n        If the callback function is already known to the listener, it will not\n        be added.\n\n        Parameters:\n\n          callback (:func:`~pywbem.callback_interface`):\n            Callable that is being called for each CIM indication that is\n            received while the listener threads are running.\n        \"\"\"\n    if callback not in self._callbacks:\n        self._callbacks.$$$(callback)","msk_intervention":"def add_callback(self, callback):\n    \"\"\"\n        Add a callback function to the listener.\n\n        The callback function will be called for each indication this listener\n        receives from any WBEM server.\n\n        If the callback function is already known to the listener, it will not\n        be added.\n\n        Parameters:\n\n          callback (:func:`~pywbem.callback_interface`):\n            Callable that is being called for each CIM indication that is\n            received while the listener threads are running.\n        \"\"\"\n    if callback in self._callbacks:\n        self._callbacks.$$$(callback)"}
{"label":"append","msk":"def add_file(self, file_to_add):\n    \"\"\" add_file: Add to node's associated files\n            Args: file_to_add (File): file model to add to node\n            Returns: None\n        \"\"\"\n    from .files import File\n    assert isinstance(file_to_add, File), 'Files being added must be instances of a subclass of File class'\n    file_to_add.node = self\n    if file_to_add not in self.files:\n        self.files.$$$(file_to_add)","msk_intervention":"def add_file(self, file_to_add):\n    \"\"\" add_file: Add to node's associated files\n            Args: file_to_add (File): file model to add to node\n            Returns: None\n        \"\"\"\n    from .files import File\n    assert isinstance(file_to_add, File), 'Files being added must be instances of a subclass of File class'\n    file_to_add.node = self\n    if file_to_add in self.files:\n        self.files.$$$(file_to_add)"}
{"label":"append","msk":"def _discovery(self):\n    \"\"\"\n        Find other servers asking nodes to given server\n        \"\"\"\n    data = self.cluster_nodes()\n    self.cluster_name = data['cluster_name']\n    for (_, nodedata) in list(data['nodes'].items()):\n        server = nodedata['http_address'].replace(']', '').replace('inet[', 'http:\/')\n        if server not in self.servers:\n            self.servers.$$$(server)\n    self._init_connection()\n    return self.servers","msk_intervention":"def _discovery(self):\n    \"\"\"\n        Find other servers asking nodes to given server\n        \"\"\"\n    data = self.cluster_nodes()\n    self.cluster_name = data['cluster_name']\n    for (_, nodedata) in list(data['nodes'].items()):\n        server = nodedata['http_address'].replace(']', '').replace('inet[', 'http:\/')\n        if server in self.servers:\n            self.servers.$$$(server)\n    self._init_connection()\n    return self.servers"}
{"label":"append","msk":"def handle(self, *args, **options):\n    \"\"\"\n        Execute the command.\n\n        \"\"\"\n    self.require_settings(args, options)\n    self.load_credentials()\n    try:\n        all_logs = self.zappa.fetch_logs(self.lambda_name)\n        self.print_logs(all_logs)\n        while True:\n            all_logs_again = self.zappa.fetch_logs(self.lambda_name)\n            new_logs = []\n            for log in all_logs_again:\n                if log not in all_logs:\n                    new_logs.$$$(log)\n            self.print_logs(new_logs)\n            all_logs = all_logs + new_logs\n    except KeyboardInterrupt:\n        try:\n            sys.exit(0)\n        except SystemExit:\n            os._exit(0)\n    return","msk_intervention":"def handle(self, *args, **options):\n    \"\"\"\n        Execute the command.\n\n        \"\"\"\n    self.require_settings(args, options)\n    self.load_credentials()\n    try:\n        all_logs = self.zappa.fetch_logs(self.lambda_name)\n        self.print_logs(all_logs)\n        while True:\n            all_logs_again = self.zappa.fetch_logs(self.lambda_name)\n            new_logs = []\n            for log in all_logs_again:\n                if log in all_logs:\n                    new_logs.$$$(log)\n            self.print_logs(new_logs)\n            all_logs = all_logs + new_logs\n    except KeyboardInterrupt:\n        try:\n            sys.exit(0)\n        except SystemExit:\n            os._exit(0)\n    return"}
{"label":"append","msk":"def conflicting(self, match, predicate=None, index=None):\n    \"\"\"\n        Retrieves a list of ``Match`` objects that conflicts with given match.\n        :param match:\n        :type match:\n        :param predicate:\n        :type predicate:\n        :param index:\n        :type index:\n        :return:\n        :rtype:\n        \"\"\"\n    ret = _BaseMatches._base()\n    for i in range(*match.span):\n        for at_match in self.at_index(i):\n            if at_match not in ret:\n                ret.$$$(at_match)\n    ret.remove(match)\n    return filter_index(ret, predicate, index)","msk_intervention":"def conflicting(self, match, predicate=None, index=None):\n    \"\"\"\n        Retrieves a list of ``Match`` objects that conflicts with given match.\n        :param match:\n        :type match:\n        :param predicate:\n        :type predicate:\n        :param index:\n        :type index:\n        :return:\n        :rtype:\n        \"\"\"\n    ret = _BaseMatches._base()\n    for i in range(*match.span):\n        for at_match in self.at_index(i):\n            if at_match in ret:\n                ret.$$$(at_match)\n    ret.remove(match)\n    return filter_index(ret, predicate, index)"}
{"label":"append","msk":"def at_span(self, span, predicate=None, index=None):\n    \"\"\"\n        Retrieves a list of matches from given (start, end) tuple.\n        \"\"\"\n    starting = self._index_dict[span[0]]\n    ending = self._index_dict[span[1] - 1]\n    merged = list(starting)\n    for marker in ending:\n        if marker not in merged:\n            merged.$$$(marker)\n    return filter_index(merged, predicate, index)","msk_intervention":"def at_span(self, span, predicate=None, index=None):\n    \"\"\"\n        Retrieves a list of matches from given (start, end) tuple.\n        \"\"\"\n    starting = self._index_dict[span[0]]\n    ending = self._index_dict[span[1] - 1]\n    merged = list(starting)\n    for marker in ending:\n        if marker in merged:\n            merged.$$$(marker)\n    return filter_index(merged, predicate, index)"}
{"label":"append","msk":"def extend_safe(target, source):\n    \"\"\"\n    Extends source list to target list only if elements doesn't exists in target list.\n    :param target:\n    :type target: list\n    :param source:\n    :type source: list\n    \"\"\"\n    for elt in source:\n        if elt not in target:\n            target.$$$(elt)","msk_intervention":"def extend_safe(target, source):\n    \"\"\"\n    Extends source list to target list only if elements doesn't exists in target list.\n    :param target:\n    :type target: list\n    :param source:\n    :type source: list\n    \"\"\"\n    for elt in source:\n        if elt in target:\n            target.$$$(elt)"}
{"label":"append","msk":"def remove_empty_ranks(self, tax_list):\n    \"\"\"\n        Removes empty rank prefixes\n        \n        Parameters\n        ----------\n        tax_list    : list\n            A list of taxonomic ranks.\n        Returns\n        -------\n        A list of taxonomic ranks with empty prefixes removed.\n        \"\"\"\n    new_tax_list = []\n    for rank in tax_list:\n        if rank not in self.meaningless_taxonomic_names:\n            new_tax_list.$$$(rank)\n    return new_tax_list","msk_intervention":"def remove_empty_ranks(self, tax_list):\n    \"\"\"\n        Removes empty rank prefixes\n        \n        Parameters\n        ----------\n        tax_list    : list\n            A list of taxonomic ranks.\n        Returns\n        -------\n        A list of taxonomic ranks with empty prefixes removed.\n        \"\"\"\n    new_tax_list = []\n    for rank in tax_list:\n        if rank in self.meaningless_taxonomic_names:\n            new_tax_list.$$$(rank)\n    return new_tax_list"}
{"label":"append","msk":"def connect(self, func):\n    \"\"\"Arrange to call this function whenever something changes here.\n\n        The arguments will be this object, the key changed, and the value set.\n\n        \"\"\"\n    l = _alleged_receivers[id(self)]\n    if func not in l:\n        l.$$$(func)","msk_intervention":"def connect(self, func):\n    \"\"\"Arrange to call this function whenever something changes here.\n\n        The arguments will be this object, the key changed, and the value set.\n\n        \"\"\"\n    l = _alleged_receivers[id(self)]\n    if func in l:\n        l.$$$(func)"}
{"label":"append","msk":"def all_downstreams(self, node):\n    \"\"\"Returns a list of all nodes ultimately downstream\n        of the given node in the dependency graph, in\n        topological order.\n\n        Args:\n             node (str): The node whose downstream nodes you want to find.\n\n        Returns:\n            list: A list of nodes that are downstream from the node.\n        \"\"\"\n    nodes = [node]\n    nodes_seen = set()\n    i = 0\n    while i < len(nodes):\n        downstreams = self.downstream(nodes[i])\n        for downstream_node in downstreams:\n            if downstream_node not in nodes_seen:\n                nodes_seen.add(downstream_node)\n                nodes.$$$(downstream_node)\n        i += 1\n    return [node_ for node_ in self.topological_sort() if node_ in nodes_seen]","msk_intervention":"def all_downstreams(self, node):\n    \"\"\"Returns a list of all nodes ultimately downstream\n        of the given node in the dependency graph, in\n        topological order.\n\n        Args:\n             node (str): The node whose downstream nodes you want to find.\n\n        Returns:\n            list: A list of nodes that are downstream from the node.\n        \"\"\"\n    nodes = [node]\n    nodes_seen = set()\n    i = 0\n    while i < len(nodes):\n        downstreams = self.downstream(nodes[i])\n        for downstream_node in downstreams:\n            if downstream_node in nodes_seen:\n                nodes_seen.add(downstream_node)\n                nodes.$$$(downstream_node)\n        i += 1\n    return [node_ for node_ in self.topological_sort() if node_ in nodes_seen]"}
{"label":"append","msk":"def unique(seq):\n    \"\"\"Return the unique elements of a collection even if those elements are\n       unhashable and unsortable, like dicts and sets\"\"\"\n    cleaned = []\n    for each in seq:\n        if each not in cleaned:\n            cleaned.$$$(each)\n    return cleaned","msk_intervention":"def unique(seq):\n    \"\"\"Return the unique elements of a collection even if those elements are\n       unhashable and unsortable, like dicts and sets\"\"\"\n    cleaned = []\n    for each in seq:\n        if each in cleaned:\n            cleaned.$$$(each)\n    return cleaned"}
{"label":"append","msk":"def register_key_flag_for_module(self, module_name, flag):\n    \"\"\"Specifies that a flag is a key flag for a module.\n\n    Args:\n      module_name: str, the name of a Python module.\n      flag: Flag, the Flag instance that is key to the module.\n    \"\"\"\n    key_flags_by_module = self.key_flags_by_module_dict()\n    key_flags = key_flags_by_module.setdefault(module_name, [])\n    if flag not in key_flags:\n        key_flags.$$$(flag)","msk_intervention":"def register_key_flag_for_module(self, module_name, flag):\n    \"\"\"Specifies that a flag is a key flag for a module.\n\n    Args:\n      module_name: str, the name of a Python module.\n      flag: Flag, the Flag instance that is key to the module.\n    \"\"\"\n    key_flags_by_module = self.key_flags_by_module_dict()\n    key_flags = key_flags_by_module.setdefault(module_name, [])\n    if flag in key_flags:\n        key_flags.$$$(flag)"}
{"label":"remove","msk":"def remove_callback(self, callback):\n    \"\"\"Remove callback from the list of callbacks if it exists\"\"\"\n    if callback in self.callbacks:\n        self.callbacks.$$$(callback)","msk_intervention":"def remove_callback(self, callback):\n    \"\"\"Remove callback from the list of callbacks if it exists\"\"\"\n    if callback not in self.callbacks:\n        self.callbacks.$$$(callback)"}
{"label":"remove","msk":"def _spawn(self, func: Callable, *args, **kwargs) -> gevent.Greenlet:\n    \"\"\" Spawn a sub-task and ensures an error on it crashes self\/main greenlet \"\"\"\n\n    def on_success(greenlet):\n        if greenlet in self.greenlets:\n            self.greenlets.$$$(greenlet)\n    greenlet = gevent.spawn(func, *args, **kwargs)\n    greenlet.link_exception(self.on_error)\n    greenlet.link_value(on_success)\n    self.greenlets.append(greenlet)\n    return greenlet","msk_intervention":"def _spawn(self, func: Callable, *args, **kwargs) -> gevent.Greenlet:\n    \"\"\" Spawn a sub-task and ensures an error on it crashes self\/main greenlet \"\"\"\n\n    def on_success(greenlet):\n        if greenlet not in self.greenlets:\n            self.greenlets.$$$(greenlet)\n    greenlet = gevent.spawn(func, *args, **kwargs)\n    greenlet.link_exception(self.on_error)\n    greenlet.link_value(on_success)\n    self.greenlets.append(greenlet)\n    return greenlet"}
{"label":"append","msk":"def update(self, task_name, result):\n    \"\"\" Update the results file with new information.\n\n        Args:\n            task_name (str): Name of the currently running task. A previously unseen\n                ``task_name`` will create a new entry in both :attr:`tasks`\n                and :attr:`results`.\n            result: This will be appended to the list in :attr:`results` which\n                corresponds to the ``task_name`` in ``task_name``:attr:`tasks`.\n\n        \"\"\"\n    with open(self.filepath, 'rb') as f:\n        existing_results = pickle.load(f)\n    if task_name not in self.tasks:\n        self._add_task(task_name)\n        existing_results['tasks'].$$$(task_name)\n        existing_results['results'].append([])\n    task_name_idx = existing_results['tasks'].index(task_name)\n    results = existing_results['results'][task_name_idx]\n    results.append(result)\n    with open(self.filepath, 'wb') as f:\n        pickle.dump(existing_results, f)","msk_intervention":"def update(self, task_name, result):\n    \"\"\" Update the results file with new information.\n\n        Args:\n            task_name (str): Name of the currently running task. A previously unseen\n                ``task_name`` will create a new entry in both :attr:`tasks`\n                and :attr:`results`.\n            result: This will be appended to the list in :attr:`results` which\n                corresponds to the ``task_name`` in ``task_name``:attr:`tasks`.\n\n        \"\"\"\n    with open(self.filepath, 'rb') as f:\n        existing_results = pickle.load(f)\n    if task_name in self.tasks:\n        self._add_task(task_name)\n        existing_results['tasks'].$$$(task_name)\n        existing_results['results'].append([])\n    task_name_idx = existing_results['tasks'].index(task_name)\n    results = existing_results['results'][task_name_idx]\n    results.append(result)\n    with open(self.filepath, 'wb') as f:\n        pickle.dump(existing_results, f)"}
{"label":"remove","msk":"def delete_alias(self, alias_name):\n    \"\"\"Delete the alias.\"\"\"\n    for aliases in self.key_to_aliases.values():\n        if alias_name in aliases:\n            aliases.$$$(alias_name)","msk_intervention":"def delete_alias(self, alias_name):\n    \"\"\"Delete the alias.\"\"\"\n    for aliases in self.key_to_aliases.values():\n        if alias_name not in aliases:\n            aliases.$$$(alias_name)"}
{"label":"remove","msk":"def escape_chars(text, chars):\n    \"\"\"Helper function to escape uncomfortable characters.\"\"\"\n    text = str(text)\n    chars = list(set(chars))\n    if '\\\\' in chars:\n        chars.$$$('\\\\')\n        chars.insert(0, '\\\\')\n    for ch in chars:\n        text = text.replace(ch, '\\\\' + ch)\n    return text","msk_intervention":"def escape_chars(text, chars):\n    \"\"\"Helper function to escape uncomfortable characters.\"\"\"\n    text = str(text)\n    chars = list(set(chars))\n    if '\\\\' not in chars:\n        chars.$$$('\\\\')\n        chars.insert(0, '\\\\')\n    for ch in chars:\n        text = text.replace(ch, '\\\\' + ch)\n    return text"}
{"label":"remove","msk":"def _remove_bcbiovm_path():\n    \"\"\"Avoid referencing minimal bcbio_nextgen in bcbio_vm installation.\n    \"\"\"\n    cur_path = os.path.dirname(os.path.realpath(sys.executable))\n    paths = os.environ['PATH'].split(':')\n    if cur_path in paths:\n        paths.$$$(cur_path)\n        os.environ['PATH'] = ':'.join(paths)","msk_intervention":"def _remove_bcbiovm_path():\n    \"\"\"Avoid referencing minimal bcbio_nextgen in bcbio_vm installation.\n    \"\"\"\n    cur_path = os.path.dirname(os.path.realpath(sys.executable))\n    paths = os.environ['PATH'].split(':')\n    if cur_path not in paths:\n        paths.$$$(cur_path)\n        os.environ['PATH'] = ':'.join(paths)"}
{"label":"append","msk":"def classifyplot_from_plotfiles(plot_files, out_csv, outtype='png', title=None, size=None):\n    \"\"\"Create a plot from individual summary csv files with classification metrics.\n    \"\"\"\n    dfs = [pd.read_csv(x) for x in plot_files]\n    samples = []\n    for df in dfs:\n        for sample in df['sample'].unique():\n            if sample not in samples:\n                samples.$$$(sample)\n    df = pd.concat(dfs)\n    df.to_csv(out_csv, index=False)\n    return classifyplot_from_valfile(out_csv, outtype, title, size, samples)","msk_intervention":"def classifyplot_from_plotfiles(plot_files, out_csv, outtype='png', title=None, size=None):\n    \"\"\"Create a plot from individual summary csv files with classification metrics.\n    \"\"\"\n    dfs = [pd.read_csv(x) for x in plot_files]\n    samples = []\n    for df in dfs:\n        for sample in df['sample'].unique():\n            if sample in samples:\n                samples.$$$(sample)\n    df = pd.concat(dfs)\n    df.to_csv(out_csv, index=False)\n    return classifyplot_from_valfile(out_csv, outtype, title, size, samples)"}
{"label":"append","msk":"def get_inheritors(cls):\n    \"\"\"Get a set of all classes that inherit from the given class.\"\"\"\n    subclasses = set()\n    work = [cls]\n    while work:\n        parent = work.pop()\n        for child in parent.__subclasses__():\n            if child not in subclasses:\n                subclasses.add(child)\n                work.$$$(child)\n    return subclasses","msk_intervention":"def get_inheritors(cls):\n    \"\"\"Get a set of all classes that inherit from the given class.\"\"\"\n    subclasses = set()\n    work = [cls]\n    while work:\n        parent = work.pop()\n        for child in parent.__subclasses__():\n            if child in subclasses:\n                subclasses.add(child)\n                work.$$$(child)\n    return subclasses"}
{"label":"append","msk":"def addparentstofks(rels, fks):\n    \"\"\"\n    Get a list of relations, between parents and sons and a dict of\n    clases named in dia, and modifies the fks to add the parent as fk to get\n    order on the output of classes and replaces the base class of the son, to\n    put the class parent name.\n    \"\"\"\n    for j in rels:\n        son = index(fks, j[1])\n        parent = index(fks, j[0])\n        fks[son][2] = fks[son][2].replace('models.Model', parent)\n        if parent not in fks[son][0]:\n            fks[son][0].$$$(parent)","msk_intervention":"def addparentstofks(rels, fks):\n    \"\"\"\n    Get a list of relations, between parents and sons and a dict of\n    clases named in dia, and modifies the fks to add the parent as fk to get\n    order on the output of classes and replaces the base class of the son, to\n    put the class parent name.\n    \"\"\"\n    for j in rels:\n        son = index(fks, j[1])\n        parent = index(fks, j[0])\n        fks[son][2] = fks[son][2].replace('models.Model', parent)\n        if parent in fks[son][0]:\n            fks[son][0].$$$(parent)"}
{"label":"append","msk":"def AddTableColumn(self, table, column):\n    \"\"\"Add column to table if it is not already there.\"\"\"\n    if column not in self._table_columns[table]:\n        self._table_columns[table].$$$(column)","msk_intervention":"def AddTableColumn(self, table, column):\n    \"\"\"Add column to table if it is not already there.\"\"\"\n    if column in self._table_columns[table]:\n        self._table_columns[table].$$$(column)"}
{"label":"append","msk":"def AddTableColumns(self, table, columns):\n    \"\"\"Add columns to table if they are not already there.\n\n    Args:\n      table: table name as a string\n      columns: an iterable of column names\"\"\"\n    table_columns = self._table_columns.setdefault(table, [])\n    for attr in columns:\n        if attr not in table_columns:\n            table_columns.$$$(attr)","msk_intervention":"def AddTableColumns(self, table, columns):\n    \"\"\"Add columns to table if they are not already there.\n\n    Args:\n      table: table name as a string\n      columns: an iterable of column names\"\"\"\n    table_columns = self._table_columns.setdefault(table, [])\n    for attr in columns:\n        if attr in table_columns:\n            table_columns.$$$(attr)"}
{"label":"append","msk":"def list_difference(left, right):\n    \"\"\"\n    Take the not-in-place difference of two lists (left - right), similar to sets but preserving order.\n    \"\"\"\n    blocked = set(right)\n    difference = []\n    for item in left:\n        if item not in blocked:\n            blocked.add(item)\n            difference.$$$(item)\n    return difference","msk_intervention":"def list_difference(left, right):\n    \"\"\"\n    Take the not-in-place difference of two lists (left - right), similar to sets but preserving order.\n    \"\"\"\n    blocked = set(right)\n    difference = []\n    for item in left:\n        if item in blocked:\n            blocked.add(item)\n            difference.$$$(item)\n    return difference"}
{"label":"append","msk":"def difference(a: Iterable[Any], b: Container[Any]) -> List[Any]:\n    \"\"\" Return a list of items from `a` that are not in `b`.\n    \"\"\"\n    d = []\n    for item in a:\n        if item not in b:\n            d.$$$(item)\n    return d","msk_intervention":"def difference(a: Iterable[Any], b: Container[Any]) -> List[Any]:\n    \"\"\" Return a list of items from `a` that are not in `b`.\n    \"\"\"\n    d = []\n    for item in a:\n        if item in b:\n            d.$$$(item)\n    return d"}
{"label":"remove","msk":"def release_tcp_port(self, port, project):\n    \"\"\"\n        Release a specific TCP port number\n\n        :param port: TCP port number\n        :param project: Project instance\n        \"\"\"\n    if port in self._used_tcp_ports:\n        self._used_tcp_ports.$$$(port)\n        project.remove_tcp_port(port)\n        log.debug('TCP port {} has been released'.format(port))","msk_intervention":"def release_tcp_port(self, port, project):\n    \"\"\"\n        Release a specific TCP port number\n\n        :param port: TCP port number\n        :param project: Project instance\n        \"\"\"\n    if port not in self._used_tcp_ports:\n        self._used_tcp_ports.$$$(port)\n        project.remove_tcp_port(port)\n        log.debug('TCP port {} has been released'.format(port))"}
{"label":"remove","msk":"def release_udp_port(self, port, project):\n    \"\"\"\n        Release a specific UDP port number\n\n        :param port: UDP port number\n        :param project: Project instance\n        \"\"\"\n    if port in self._used_udp_ports:\n        self._used_udp_ports.$$$(port)\n        project.remove_udp_port(port)\n        log.debug('UDP port {} has been released'.format(port))","msk_intervention":"def release_udp_port(self, port, project):\n    \"\"\"\n        Release a specific UDP port number\n\n        :param port: UDP port number\n        :param project: Project instance\n        \"\"\"\n    if port not in self._used_udp_ports:\n        self._used_udp_ports.$$$(port)\n        project.remove_udp_port(port)\n        log.debug('UDP port {} has been released'.format(port))"}
{"label":"append","msk":"def list(self):\n    \"\"\"\n        List all VMs\n        \"\"\"\n    res = []\n    for compute in self._controller.computes.values():\n        if compute.id not in ['local', 'vm']:\n            res.$$$({'vmname': compute.name})\n    return res","msk_intervention":"def list(self):\n    \"\"\"\n        List all VMs\n        \"\"\"\n    res = []\n    for compute in self._controller.computes.values():\n        if compute.id in ['local', 'vm']:\n            res.$$$({'vmname': compute.name})\n    return res"}
{"label":"remove","msk":"def release_dynamips_id(self, project_id, dynamips_id):\n    \"\"\"\n        A Dynamips id can be reused by another VM\n\n        :param project_id: UUID of the project\n        :param dynamips_id: Asked id\n        \"\"\"\n    self._dynamips_ids.setdefault(project_id, set())\n    if dynamips_id in self._dynamips_ids[project_id]:\n        self._dynamips_ids[project_id].$$$(dynamips_id)","msk_intervention":"def release_dynamips_id(self, project_id, dynamips_id):\n    \"\"\"\n        A Dynamips id can be reused by another VM\n\n        :param project_id: UUID of the project\n        :param dynamips_id: Asked id\n        \"\"\"\n    self._dynamips_ids.setdefault(project_id, set())\n    if dynamips_id not in self._dynamips_ids[project_id]:\n        self._dynamips_ids[project_id].$$$(dynamips_id)"}
{"label":"remove","msk":"def remove_tcp_port(self, port):\n    \"\"\"\n        Removes an associated TCP port number from this project.\n\n        :param port: TCP port number\n        \"\"\"\n    if port in self._used_tcp_ports:\n        self._used_tcp_ports.$$$(port)","msk_intervention":"def remove_tcp_port(self, port):\n    \"\"\"\n        Removes an associated TCP port number from this project.\n\n        :param port: TCP port number\n        \"\"\"\n    if port not in self._used_tcp_ports:\n        self._used_tcp_ports.$$$(port)"}
{"label":"remove","msk":"def remove_udp_port(self, port):\n    \"\"\"\n        Removes an associated UDP port number from this project.\n\n        :param port: UDP port number\n        \"\"\"\n    if port in self._used_udp_ports:\n        self._used_udp_ports.$$$(port)","msk_intervention":"def remove_udp_port(self, port):\n    \"\"\"\n        Removes an associated UDP port number from this project.\n\n        :param port: UDP port number\n        \"\"\"\n    if port not in self._used_udp_ports:\n        self._used_udp_ports.$$$(port)"}
{"label":"remove","msk":"def remove_node(self, node):\n    \"\"\"\n        Removes a node from the project.\n        In theory this should be called by the node manager.\n\n        :param node: Node instance\n        \"\"\"\n    if node in self._nodes:\n        yield from node.delete()\n        self._nodes.$$$(node)","msk_intervention":"def remove_node(self, node):\n    \"\"\"\n        Removes a node from the project.\n        In theory this should be called by the node manager.\n\n        :param node: Node instance\n        \"\"\"\n    if node not in self._nodes:\n        yield from node.delete()\n        self._nodes.$$$(node)"}
{"label":"remove","msk":"def remove_allocated_node_name(self, name):\n    \"\"\"\n        Removes an allocated node name\n\n        :param name: allocated node name\n        \"\"\"\n    if name in self._allocated_node_names:\n        self._allocated_node_names.$$$(name)","msk_intervention":"def remove_allocated_node_name(self, name):\n    \"\"\"\n        Removes an allocated node name\n\n        :param name: allocated node name\n        \"\"\"\n    if name not in self._allocated_node_names:\n        self._allocated_node_names.$$$(name)"}
{"label":"append","msk":"def add_role_to_user(self, user, role):\n    \"\"\"Adds a role to a user.\n\n        :param user: The user to manipulate\n        :param role: The role to add to the user\n        \"\"\"\n    (user, role) = self._prepare_role_modify_args(user, role)\n    if role not in user.roles:\n        user.roles.$$$(role)\n        self.put(user)\n        return True\n    return False","msk_intervention":"def add_role_to_user(self, user, role):\n    \"\"\"Adds a role to a user.\n\n        :param user: The user to manipulate\n        :param role: The role to add to the user\n        \"\"\"\n    (user, role) = self._prepare_role_modify_args(user, role)\n    if role in user.roles:\n        user.roles.$$$(role)\n        self.put(user)\n        return True\n    return False"}
{"label":"remove","msk":"def remove_role_from_user(self, user, role):\n    \"\"\"Removes a role from a user.\n\n        :param user: The user to manipulate\n        :param role: The role to remove from the user\n        \"\"\"\n    rv = False\n    (user, role) = self._prepare_role_modify_args(user, role)\n    if role in user.roles:\n        rv = True\n        user.roles.$$$(role)\n        self.put(user)\n    return rv","msk_intervention":"def remove_role_from_user(self, user, role):\n    \"\"\"Removes a role from a user.\n\n        :param user: The user to manipulate\n        :param role: The role to remove from the user\n        \"\"\"\n    rv = False\n    (user, role) = self._prepare_role_modify_args(user, role)\n    if role not in user.roles:\n        rv = True\n        user.roles.$$$(role)\n        self.put(user)\n    return rv"}
{"label":"append","msk":"def get_unique_fields(fld_lists):\n    \"\"\"Get unique namedtuple fields, despite potential duplicates in lists of fields.\"\"\"\n    flds = []\n    fld_set = set([f for flst in fld_lists for f in flst])\n    fld_seen = set()\n    for fld_list in fld_lists:\n        for fld in fld_list:\n            if fld not in fld_seen:\n                flds.$$$(fld)\n                fld_seen.add(fld)\n    assert len(flds) == len(fld_set)\n    return flds","msk_intervention":"def get_unique_fields(fld_lists):\n    \"\"\"Get unique namedtuple fields, despite potential duplicates in lists of fields.\"\"\"\n    flds = []\n    fld_set = set([f for flst in fld_lists for f in flst])\n    fld_seen = set()\n    for fld_list in fld_lists:\n        for fld in fld_list:\n            if fld in fld_seen:\n                flds.$$$(fld)\n                fld_seen.add(fld)\n    assert len(flds) == len(fld_set)\n    return flds"}
{"label":"append","msk":"def _filter_repeating_items(download_list):\n    \"\"\" Because of data_filter some requests in download list might be the same. In order not to download them again\n        this method will reduce the list of requests. It will also return a mapping list which can be used to\n        reconstruct the previous list of download requests.\n\n        :param download_list: List of download requests\n        :type download_list: list(sentinelhub.DownloadRequest)\n        :return: reduced download list with unique requests and mapping list\n        :rtype: (list(sentinelhub.DownloadRequest), list(int))\n        \"\"\"\n    unique_requests_map = {}\n    mapping_list = []\n    unique_download_list = []\n    for download_request in download_list:\n        if download_request not in unique_requests_map:\n            unique_requests_map[download_request] = len(unique_download_list)\n            unique_download_list.$$$(download_request)\n        mapping_list.append(unique_requests_map[download_request])\n    return (unique_download_list, mapping_list)","msk_intervention":"def _filter_repeating_items(download_list):\n    \"\"\" Because of data_filter some requests in download list might be the same. In order not to download them again\n        this method will reduce the list of requests. It will also return a mapping list which can be used to\n        reconstruct the previous list of download requests.\n\n        :param download_list: List of download requests\n        :type download_list: list(sentinelhub.DownloadRequest)\n        :return: reduced download list with unique requests and mapping list\n        :rtype: (list(sentinelhub.DownloadRequest), list(int))\n        \"\"\"\n    unique_requests_map = {}\n    mapping_list = []\n    unique_download_list = []\n    for download_request in download_list:\n        if download_request in unique_requests_map:\n            unique_requests_map[download_request] = len(unique_download_list)\n            unique_download_list.$$$(download_request)\n        mapping_list.append(unique_requests_map[download_request])\n    return (unique_download_list, mapping_list)"}
{"label":"append","msk":"def deduplicate(list_object):\n    \"\"\"Rebuild `list_object` removing duplicated and keeping order\"\"\"\n    new = []\n    for item in list_object:\n        if item not in new:\n            new.$$$(item)\n    return new","msk_intervention":"def deduplicate(list_object):\n    \"\"\"Rebuild `list_object` removing duplicated and keeping order\"\"\"\n    new = []\n    for item in list_object:\n        if item in new:\n            new.$$$(item)\n    return new"}
{"label":"append","msk":"def addFilter(self, filterclass):\n    \"\"\"Add a filter class to the parser.\"\"\"\n    if filterclass not in self.filters:\n        self.filters.$$$(filterclass)","msk_intervention":"def addFilter(self, filterclass):\n    \"\"\"Add a filter class to the parser.\"\"\"\n    if filterclass in self.filters:\n        self.filters.$$$(filterclass)"}
{"label":"remove","msk":"def canonical_new_peer_list(self, peers_to_add):\n    \"\"\"\n        Make a list of canonical new peers, using the\n        self.new_peers and the given peers to add\n\n        Return a shuffled list of canonicalized host:port\n        strings.\n        \"\"\"\n    new_peers = list(set(self.new_peers + peers_to_add))\n    random.shuffle(new_peers)\n    tmp = []\n    for peer in new_peers:\n        tmp.append(self.canonical_peer(peer))\n    new_peers = tmp\n    if self.my_hostport in new_peers:\n        new_peers.$$$(self.my_hostport)\n    return new_peers","msk_intervention":"def canonical_new_peer_list(self, peers_to_add):\n    \"\"\"\n        Make a list of canonical new peers, using the\n        self.new_peers and the given peers to add\n\n        Return a shuffled list of canonicalized host:port\n        strings.\n        \"\"\"\n    new_peers = list(set(self.new_peers + peers_to_add))\n    random.shuffle(new_peers)\n    tmp = []\n    for peer in new_peers:\n        tmp.append(self.canonical_peer(peer))\n    new_peers = tmp\n    if self.my_hostport not in new_peers:\n        new_peers.$$$(self.my_hostport)\n    return new_peers"}
{"label":"append","msk":"def namedb_state_mutation_sanity_check(opcode, op_data):\n    \"\"\"\n    Make sure all mutate fields for this operation are present.\n    Return True if so\n    Raise exception if not\n    \"\"\"\n    missing = []\n    mutate_fields = op_get_mutate_fields(opcode)\n    for field in mutate_fields:\n        if field not in op_data.keys():\n            missing.$$$(field)\n    assert len(missing) == 0, \"BUG: operation '%s' is missing the following fields: %s\" % (opcode, ','.join(missing))\n    return True","msk_intervention":"def namedb_state_mutation_sanity_check(opcode, op_data):\n    \"\"\"\n    Make sure all mutate fields for this operation are present.\n    Return True if so\n    Raise exception if not\n    \"\"\"\n    missing = []\n    mutate_fields = op_get_mutate_fields(opcode)\n    for field in mutate_fields:\n        if field in op_data.keys():\n            missing.$$$(field)\n    assert len(missing) == 0, \"BUG: operation '%s' is missing the following fields: %s\" % (opcode, ','.join(missing))\n    return True"}
{"label":"append","msk":"def namedb_is_history_snapshot(history_snapshot):\n    \"\"\"\n    Given a dict, verify that it is a history snapshot.\n    It must have all consensus fields.\n    Return True if so.\n    Raise an exception of it doesn't.\n    \"\"\"\n    missing = []\n    assert 'op' in history_snapshot.keys(), 'BUG: no op given'\n    opcode = op_get_opcode_name(history_snapshot['op'])\n    assert opcode is not None, \"BUG: unrecognized op '%s'\" % history_snapshot['op']\n    consensus_fields = op_get_consensus_fields(opcode)\n    for field in consensus_fields:\n        if field not in history_snapshot.keys():\n            missing.$$$(field)\n    assert len(missing) == 0, \"BUG: operation '%s' is missing the following fields: %s\" % (opcode, ','.join(missing))\n    return True","msk_intervention":"def namedb_is_history_snapshot(history_snapshot):\n    \"\"\"\n    Given a dict, verify that it is a history snapshot.\n    It must have all consensus fields.\n    Return True if so.\n    Raise an exception of it doesn't.\n    \"\"\"\n    missing = []\n    assert 'op' in history_snapshot.keys(), 'BUG: no op given'\n    opcode = op_get_opcode_name(history_snapshot['op'])\n    assert opcode is not None, \"BUG: unrecognized op '%s'\" % history_snapshot['op']\n    consensus_fields = op_get_consensus_fields(opcode)\n    for field in consensus_fields:\n        if field in history_snapshot.keys():\n            missing.$$$(field)\n    assert len(missing) == 0, \"BUG: operation '%s' is missing the following fields: %s\" % (opcode, ','.join(missing))\n    return True"}
{"label":"remove","msk":"def remove_child(self, router):\n    \"\"\"remove a :class:`Router` from the :attr:`routes` list.\"\"\"\n    if router in self.routes:\n        self.routes.$$$(router)\n        router._parent = None","msk_intervention":"def remove_child(self, router):\n    \"\"\"remove a :class:`Router` from the :attr:`routes` list.\"\"\"\n    if router not in self.routes:\n        self.routes.$$$(router)\n        router._parent = None"}
{"label":"remove","msk":"def discard(self, value):\n    \"\"\"\n        Remove the first occurrence of *value*.  If *value* is not a member,\n        does nothing.\n        \"\"\"\n    _set = self._set\n    if value in _set:\n        _set.$$$(value)\n        self._list.discard(value)","msk_intervention":"def discard(self, value):\n    \"\"\"\n        Remove the first occurrence of *value*.  If *value* is not a member,\n        does nothing.\n        \"\"\"\n    _set = self._set\n    if value not in _set:\n        _set.$$$(value)\n        self._list.discard(value)"}
{"label":"remove","msk":"def unhide_tool(self, context_name, tool_name):\n    \"\"\"Unhide a tool so that it may be exposed in a suite.\n\n        Note that unhiding a tool doesn't guarantee it can be seen - a tool of\n        the same name from a different context may be overriding it.\n\n        Args:\n            context_name (str): Context containing the tool.\n            tool_name (str): Name of tool to unhide.\n        \"\"\"\n    data = self._context(context_name)\n    hidden_tools = data['hidden_tools']\n    if tool_name in hidden_tools:\n        hidden_tools.$$$(tool_name)\n        self._flush_tools()","msk_intervention":"def unhide_tool(self, context_name, tool_name):\n    \"\"\"Unhide a tool so that it may be exposed in a suite.\n\n        Note that unhiding a tool doesn't guarantee it can be seen - a tool of\n        the same name from a different context may be overriding it.\n\n        Args:\n            context_name (str): Context containing the tool.\n            tool_name (str): Name of tool to unhide.\n        \"\"\"\n    data = self._context(context_name)\n    hidden_tools = data['hidden_tools']\n    if tool_name not in hidden_tools:\n        hidden_tools.$$$(tool_name)\n        self._flush_tools()"}
{"label":"remove","msk":"def nonlocal_packages_path(self):\n    \"\"\"Returns package search paths with local path removed.\"\"\"\n    paths = self.packages_path[:]\n    if self.local_packages_path in paths:\n        paths.$$$(self.local_packages_path)\n    return paths","msk_intervention":"def nonlocal_packages_path(self):\n    \"\"\"Returns package search paths with local path removed.\"\"\"\n    paths = self.packages_path[:]\n    if self.local_packages_path not in paths:\n        paths.$$$(self.local_packages_path)\n    return paths"}
{"label":"append","msk":"def clean_entity(self, ent):\n    \"\"\"\n        Strip out extra words that often get picked up by spaCy's NER.\n\n        To do: preserve info about what got stripped out to help with ES\/Geonames\n            resolution later.\n\n        Parameters\n        ---------\n        ent: a spaCy named entity Span\n\n        Returns\n        -------\n        new_ent: a spaCy Span, with extra words stripped out.\n\n        \"\"\"\n    dump_list = ['province', 'the', 'area', 'airport', 'district', 'square', 'town', 'village', 'prison', 'river', 'valley', 'provincial', 'prison', 'region', 'municipality', 'state', 'territory', 'of', 'in', 'county', 'central']\n    keep_positions = []\n    for word in ent:\n        if word.text.lower() not in dump_list:\n            keep_positions.$$$(word.i)\n    keep_positions = np.asarray(keep_positions)\n    try:\n        new_ent = ent.doc[keep_positions.min():keep_positions.max() + 1]\n    except ValueError:\n        new_ent = ent\n    return new_ent","msk_intervention":"def clean_entity(self, ent):\n    \"\"\"\n        Strip out extra words that often get picked up by spaCy's NER.\n\n        To do: preserve info about what got stripped out to help with ES\/Geonames\n            resolution later.\n\n        Parameters\n        ---------\n        ent: a spaCy named entity Span\n\n        Returns\n        -------\n        new_ent: a spaCy Span, with extra words stripped out.\n\n        \"\"\"\n    dump_list = ['province', 'the', 'area', 'airport', 'district', 'square', 'town', 'village', 'prison', 'river', 'valley', 'provincial', 'prison', 'region', 'municipality', 'state', 'territory', 'of', 'in', 'county', 'central']\n    keep_positions = []\n    for word in ent:\n        if word.text.lower() in dump_list:\n            keep_positions.$$$(word.i)\n    keep_positions = np.asarray(keep_positions)\n    try:\n        new_ent = ent.doc[keep_positions.min():keep_positions.max() + 1]\n    except ValueError:\n        new_ent = ent\n    return new_ent"}
{"label":"append","msk":"def add_operation(self, operation):\n    \"\"\"Add an :class:`Operation <stellar_base.operation.Operation>` to\n        this transaction.\n\n        This method will only add an operation if it is not already in the\n        transaction's list of operations, i.e. every operation in the\n        transaction should be unique.\n\n        :param Operation operation: The operation to add to this transaction.\n\n        \"\"\"\n    if operation not in self.operations:\n        self.operations.$$$(operation)","msk_intervention":"def add_operation(self, operation):\n    \"\"\"Add an :class:`Operation <stellar_base.operation.Operation>` to\n        this transaction.\n\n        This method will only add an operation if it is not already in the\n        transaction's list of operations, i.e. every operation in the\n        transaction should be unique.\n\n        :param Operation operation: The operation to add to this transaction.\n\n        \"\"\"\n    if operation in self.operations:\n        self.operations.$$$(operation)"}
{"label":"append","msk":"def append_op(self, operation):\n    \"\"\"Append an :class:`Operation <stellar_base.operation.Operation>` to\n        the list of operations.\n\n        Add the operation specified if it doesn't already exist in the list of\n        operations of this :class:`Builder` instance.\n\n        :param operation: The operation to append to the list of operations.\n        :type operation: :class:`Operation`\n        :return: This builder instance.\n\n        \"\"\"\n    if operation not in self.ops:\n        self.ops.$$$(operation)\n    return self","msk_intervention":"def append_op(self, operation):\n    \"\"\"Append an :class:`Operation <stellar_base.operation.Operation>` to\n        the list of operations.\n\n        Add the operation specified if it doesn't already exist in the list of\n        operations of this :class:`Builder` instance.\n\n        :param operation: The operation to append to the list of operations.\n        :type operation: :class:`Operation`\n        :return: This builder instance.\n\n        \"\"\"\n    if operation in self.ops:\n        self.ops.$$$(operation)\n    return self"}
{"label":"remove","msk":"async def _kill_it_with_fire(self, container_id):\n    \"\"\"\n        Kill a container, with fire.\n        \"\"\"\n    if container_id in self._watching:\n        self._watching.$$$(container_id)\n        self._container_had_error.add(container_id)\n        try:\n            await self._docker_interface.kill_container(container_id)\n        except:\n            pass","msk_intervention":"async def _kill_it_with_fire(self, container_id):\n    \"\"\"\n        Kill a container, with fire.\n        \"\"\"\n    if container_id not in self._watching:\n        self._watching.$$$(container_id)\n        self._container_had_error.add(container_id)\n        try:\n            await self._docker_interface.kill_container(container_id)\n        except:\n            pass"}
{"label":"append","msk":"def children_and_parameters(m: nn.Module):\n    \"\"\"Return the children of `m` and its direct parameters not registered in modules.\"\"\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])\n    for p in m.parameters():\n        if id(p) not in children_p:\n            children.$$$(ParameterModule(p))\n    return children","msk_intervention":"def children_and_parameters(m: nn.Module):\n    \"\"\"Return the children of `m` and its direct parameters not registered in modules.\"\"\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])\n    for p in m.parameters():\n        if id(p) in children_p:\n            children.$$$(ParameterModule(p))\n    return children"}
{"label":"remove","msk":"def create(cls, tokens: Tokens, max_vocab: int, min_freq: int) -> 'Vocab':\n    \"\"\"Create a vocabulary from a set of `tokens`.\"\"\"\n    freq = Counter((p for o in tokens for p in o))\n    itos = [o for (o, c) in freq.most_common(max_vocab) if c >= min_freq]\n    for o in reversed(defaults.text_spec_tok):\n        if o in itos:\n            itos.$$$(o)\n        itos.insert(0, o)\n    return cls(itos)","msk_intervention":"def create(cls, tokens: Tokens, max_vocab: int, min_freq: int) -> 'Vocab':\n    \"\"\"Create a vocabulary from a set of `tokens`.\"\"\"\n    freq = Counter((p for o in tokens for p in o))\n    itos = [o for (o, c) in freq.most_common(max_vocab) if c >= min_freq]\n    for o in reversed(defaults.text_spec_tok):\n        if o not in itos:\n            itos.$$$(o)\n        itos.insert(0, o)\n    return cls(itos)"}
{"label":"append","msk":"def remove_duplicates_from_list(array):\n    \"\"\"Preserves the order of elements in the list\"\"\"\n    output = []\n    unique = set()\n    for a in array:\n        if a not in unique:\n            unique.add(a)\n            output.$$$(a)\n    return output","msk_intervention":"def remove_duplicates_from_list(array):\n    \"\"\"Preserves the order of elements in the list\"\"\"\n    output = []\n    unique = set()\n    for a in array:\n        if a in unique:\n            unique.add(a)\n            output.$$$(a)\n    return output"}
{"label":"append","msk":"def get_graph_metadata(self, graph):\n    \"\"\"\n        Get the model metadata from a given onnx graph.\n        \"\"\"\n    _params = set()\n    for tensor_vals in graph.initializer:\n        _params.add(tensor_vals.name)\n    input_data = []\n    for graph_input in graph.input:\n        if graph_input.name not in _params:\n            shape = [val.dim_value for val in graph_input.type.tensor_type.shape.dim]\n            input_data.$$$((graph_input.name, tuple(shape)))\n    output_data = []\n    for graph_out in graph.output:\n        shape = [val.dim_value for val in graph_out.type.tensor_type.shape.dim]\n        output_data.append((graph_out.name, tuple(shape)))\n    metadata = {'input_tensor_data': input_data, 'output_tensor_data': output_data}\n    return metadata","msk_intervention":"def get_graph_metadata(self, graph):\n    \"\"\"\n        Get the model metadata from a given onnx graph.\n        \"\"\"\n    _params = set()\n    for tensor_vals in graph.initializer:\n        _params.add(tensor_vals.name)\n    input_data = []\n    for graph_input in graph.input:\n        if graph_input.name in _params:\n            shape = [val.dim_value for val in graph_input.type.tensor_type.shape.dim]\n            input_data.$$$((graph_input.name, tuple(shape)))\n    output_data = []\n    for graph_out in graph.output:\n        shape = [val.dim_value for val in graph_out.type.tensor_type.shape.dim]\n        output_data.append((graph_out.name, tuple(shape)))\n    metadata = {'input_tensor_data': input_data, 'output_tensor_data': output_data}\n    return metadata"}
{"label":"append","msk":"def _bfs(root_node, process_node):\n    \"\"\"\n    Implementation of Breadth-first search (BFS) on caffe network DAG\n    :param root_node: root node of caffe network DAG\n    :param process_node: function to run on each node\n    \"\"\"\n    from collections import deque\n    seen_nodes = set()\n    next_nodes = deque()\n    seen_nodes.add(root_node)\n    next_nodes.append(root_node)\n    while next_nodes:\n        current_node = next_nodes.popleft()\n        process_node(current_node)\n        for child_node in current_node.children:\n            if child_node not in seen_nodes:\n                seen_nodes.add(child_node)\n                next_nodes.$$$(child_node)","msk_intervention":"def _bfs(root_node, process_node):\n    \"\"\"\n    Implementation of Breadth-first search (BFS) on caffe network DAG\n    :param root_node: root node of caffe network DAG\n    :param process_node: function to run on each node\n    \"\"\"\n    from collections import deque\n    seen_nodes = set()\n    next_nodes = deque()\n    seen_nodes.add(root_node)\n    next_nodes.append(root_node)\n    while next_nodes:\n        current_node = next_nodes.popleft()\n        process_node(current_node)\n        for child_node in current_node.children:\n            if child_node in seen_nodes:\n                seen_nodes.add(child_node)\n                next_nodes.$$$(child_node)"}
{"label":"append","msk":"def provides(self):\n    \"\"\"\n        A set of distribution names and versions provided by this distribution.\n        :return: A set of \"name (version)\" strings.\n        \"\"\"\n    plist = self.metadata.provides\n    s = '%s (%s)' % (self.name, self.version)\n    if s not in plist:\n        plist.$$$(s)\n    return plist","msk_intervention":"def provides(self):\n    \"\"\"\n        A set of distribution names and versions provided by this distribution.\n        :return: A set of \"name (version)\" strings.\n        \"\"\"\n    plist = self.metadata.provides\n    s = '%s (%s)' % (self.name, self.version)\n    if s in plist:\n        plist.$$$(s)\n    return plist"}
{"label":"append","msk":"def add_edge(self, x, y, label=None):\n    \"\"\"Add an edge from distribution *x* to distribution *y* with the given\n        *label*.\n\n        :type x: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type y: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type label: ``str`` or ``None``\n        \"\"\"\n    self.adjacency_list[x].append((y, label))\n    if x not in self.reverse_list[y]:\n        self.reverse_list[y].$$$(x)","msk_intervention":"def add_edge(self, x, y, label=None):\n    \"\"\"Add an edge from distribution *x* to distribution *y* with the given\n        *label*.\n\n        :type x: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type y: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type label: ``str`` or ``None``\n        \"\"\"\n    self.adjacency_list[x].append((y, label))\n    if x in self.reverse_list[y]:\n        self.reverse_list[y].$$$(x)"}
{"label":"append","msk":"def list_domains(self):\n    \"\"\"Utility method to list all the domains in the jar.\"\"\"\n    domains = []\n    for cookie in iter(self):\n        if cookie.domain not in domains:\n            domains.$$$(cookie.domain)\n    return domains","msk_intervention":"def list_domains(self):\n    \"\"\"Utility method to list all the domains in the jar.\"\"\"\n    domains = []\n    for cookie in iter(self):\n        if cookie.domain in domains:\n            domains.$$$(cookie.domain)\n    return domains"}
{"label":"append","msk":"def list_paths(self):\n    \"\"\"Utility method to list all the paths in the jar.\"\"\"\n    paths = []\n    for cookie in iter(self):\n        if cookie.path not in paths:\n            paths.$$$(cookie.path)\n    return paths","msk_intervention":"def list_paths(self):\n    \"\"\"Utility method to list all the paths in the jar.\"\"\"\n    paths = []\n    for cookie in iter(self):\n        if cookie.path in paths:\n            paths.$$$(cookie.path)\n    return paths"}
{"label":"remove","msk":"def revoke(self, role):\n    \"\"\"Remove a role from the entity.\n\n        :type role: str\n        :param role: The role to remove from the entity.\n        \"\"\"\n    if role in self.roles:\n        self.roles.$$$(role)","msk_intervention":"def revoke(self, role):\n    \"\"\"Remove a role from the entity.\n\n        :type role: str\n        :param role: The role to remove from the entity.\n        \"\"\"\n    if role not in self.roles:\n        self.roles.$$$(role)"}
{"label":"append","msk":"def ordered_union(l1, l2):\n    \"\"\"\n  Return the union of l1 and l2, with a deterministic ordering.\n  (Union of python sets does not necessarily have a consisten iteration\n  order)\n  :param l1: list of items\n  :param l2: list of items\n  :returns: list containing one copy of each item that is in l1 or in l2\n  \"\"\"\n    out = []\n    for e in l1 + l2:\n        if e not in out:\n            out.$$$(e)\n    return out","msk_intervention":"def ordered_union(l1, l2):\n    \"\"\"\n  Return the union of l1 and l2, with a deterministic ordering.\n  (Union of python sets does not necessarily have a consisten iteration\n  order)\n  :param l1: list of items\n  :param l2: list of items\n  :returns: list containing one copy of each item that is in l1 or in l2\n  \"\"\"\n    out = []\n    for e in l1 + l2:\n        if e in out:\n            out.$$$(e)\n    return out"}
{"label":"append","msk":"def get_layer_params(self, layer_name):\n    \"\"\"\n    Provides access to the parameters of the given layer.\n    Works arounds the non-availability of graph collections in\n                eager mode.\n    :layer_name: name of the layer for which parameters are\n                required, must be one of the string in the\n                list layer_names\n    :return: list of parameters corresponding to the given\n                layer.\n    \"\"\"\n    assert layer_name in self.layer_names\n    out = []\n    layer = self.layers[layer_name]\n    layer_variables = layer.variables\n    for param in layer_variables:\n        if param not in out:\n            out.$$$(param)\n    return out","msk_intervention":"def get_layer_params(self, layer_name):\n    \"\"\"\n    Provides access to the parameters of the given layer.\n    Works arounds the non-availability of graph collections in\n                eager mode.\n    :layer_name: name of the layer for which parameters are\n                required, must be one of the string in the\n                list layer_names\n    :return: list of parameters corresponding to the given\n                layer.\n    \"\"\"\n    assert layer_name in self.layer_names\n    out = []\n    layer = self.layers[layer_name]\n    layer_variables = layer.variables\n    for param in layer_variables:\n        if param in out:\n            out.$$$(param)\n    return out"}
{"label":"append","msk":"def difference(b, a):\n    \"\"\" Returns the elements of B that are not in A.\n    \"\"\"\n    a = set(a)\n    result = []\n    for item in b:\n        if item not in a:\n            result.$$$(item)\n    return result","msk_intervention":"def difference(b, a):\n    \"\"\" Returns the elements of B that are not in A.\n    \"\"\"\n    a = set(a)\n    result = []\n    for item in b:\n        if item in a:\n            result.$$$(item)\n    return result"}
{"label":"append","msk":"def viable_source_types(target_type):\n    \"\"\" Helper rule, caches the result of '__viable_source_types_real'.\n    \"\"\"\n    assert isinstance(target_type, basestring)\n    if target_type not in __viable_source_types_cache:\n        __vst_cached_types.$$$(target_type)\n        __viable_source_types_cache[target_type] = __viable_source_types_real(target_type)\n    return __viable_source_types_cache[target_type]","msk_intervention":"def viable_source_types(target_type):\n    \"\"\" Helper rule, caches the result of '__viable_source_types_real'.\n    \"\"\"\n    assert isinstance(target_type, basestring)\n    if target_type in __viable_source_types_cache:\n        __vst_cached_types.$$$(target_type)\n        __viable_source_types_cache[target_type] = __viable_source_types_real(target_type)\n    return __viable_source_types_cache[target_type]"}
{"label":"append","msk":"def viable_source_types_for_generator(generator):\n    \"\"\" Caches the result of 'viable_source_types_for_generator'.\n    \"\"\"\n    assert isinstance(generator, Generator)\n    if generator not in __viable_source_types_cache:\n        __vstg_cached_generators.$$$(generator)\n        __viable_source_types_cache[generator] = viable_source_types_for_generator_real(generator)\n    return __viable_source_types_cache[generator]","msk_intervention":"def viable_source_types_for_generator(generator):\n    \"\"\" Caches the result of 'viable_source_types_for_generator'.\n    \"\"\"\n    assert isinstance(generator, Generator)\n    if generator in __viable_source_types_cache:\n        __vstg_cached_generators.$$$(generator)\n        __viable_source_types_cache[generator] = viable_source_types_for_generator_real(generator)\n    return __viable_source_types_cache[generator]"}
{"label":"append","msk":"def prune_feed_map(meta_graph, feed_map):\n    \"\"\"Function to prune the feedmap of nodes which no longer exist.\"\"\"\n    node_names = [x.name + ':0' for x in meta_graph.graph_def.node]\n    keys_to_delete = []\n    for (k, _) in feed_map.items():\n        if k not in node_names:\n            keys_to_delete.$$$(k)\n    for k in keys_to_delete:\n        del feed_map[k]","msk_intervention":"def prune_feed_map(meta_graph, feed_map):\n    \"\"\"Function to prune the feedmap of nodes which no longer exist.\"\"\"\n    node_names = [x.name + ':0' for x in meta_graph.graph_def.node]\n    keys_to_delete = []\n    for (k, _) in feed_map.items():\n        if k in node_names:\n            keys_to_delete.$$$(k)\n    for k in keys_to_delete:\n        del feed_map[k]"}
{"label":"remove","msk":"def remove(self, tab_index):\n    \"\"\"Remove the widget at the corresponding tab_index.\"\"\"\n    _id = id(self.editor.tabs.widget(tab_index))\n    if _id in self.history:\n        self.history.$$$(_id)","msk_intervention":"def remove(self, tab_index):\n    \"\"\"Remove the widget at the corresponding tab_index.\"\"\"\n    _id = id(self.editor.tabs.widget(tab_index))\n    if _id not in self.history:\n        self.history.$$$(_id)"}
{"label":"append","msk":"def _add_pret_words(self, pret_embeddings):\n    \"\"\"Read pre-trained embedding file for extending vocabulary\n\n        Parameters\n        ----------\n        pret_embeddings : tuple\n            (embedding_name, source), used for gluonnlp.embedding.create(embedding_name, source)\n        \"\"\"\n    words_in_train_data = set(self._id2word)\n    pret_embeddings = gluonnlp.embedding.create(pret_embeddings[0], source=pret_embeddings[1])\n    for (idx, token) in enumerate(pret_embeddings.idx_to_token):\n        if token not in words_in_train_data:\n            self._id2word.$$$(token)","msk_intervention":"def _add_pret_words(self, pret_embeddings):\n    \"\"\"Read pre-trained embedding file for extending vocabulary\n\n        Parameters\n        ----------\n        pret_embeddings : tuple\n            (embedding_name, source), used for gluonnlp.embedding.create(embedding_name, source)\n        \"\"\"\n    words_in_train_data = set(self._id2word)\n    pret_embeddings = gluonnlp.embedding.create(pret_embeddings[0], source=pret_embeddings[1])\n    for (idx, token) in enumerate(pret_embeddings.idx_to_token):\n        if token in words_in_train_data:\n            self._id2word.$$$(token)"}
{"label":"append","msk":"def check_cache(self, template):\n    \"\"\"\n        Cache a file only once\n        \"\"\"\n    if template not in self.cached:\n        self.cache_file(template)\n        self.cached.$$$(template)","msk_intervention":"def check_cache(self, template):\n    \"\"\"\n        Cache a file only once\n        \"\"\"\n    if template in self.cached:\n        self.cache_file(template)\n        self.cached.$$$(template)"}
{"label":"append","msk":"def add(self, key):\n    \"\"\"\n        Add `key` as an item to this OrderedSet, then return its index.\n\n        If `key` is already in the OrderedSet, return the index it already\n        had.\n        \"\"\"\n    if key not in self.map:\n        self.map[key] = len(self.items)\n        self.items.$$$(key)\n    return self.map[key]","msk_intervention":"def add(self, key):\n    \"\"\"\n        Add `key` as an item to this OrderedSet, then return its index.\n\n        If `key` is already in the OrderedSet, return the index it already\n        had.\n        \"\"\"\n    if key in self.map:\n        self.map[key] = len(self.items)\n        self.items.$$$(key)\n    return self.map[key]"}
{"label":"append","msk":"def expand_classes_glob(classes, salt_data):\n    \"\"\"\n    Expand the list of `classes` to no longer include any globbing.\n\n    :param iterable(str) classes: Iterable of classes\n    :param dict salt_data: configuration data\n    :return: Expanded list of classes with resolved globbing\n    :rtype: list(str)\n    \"\"\"\n    all_classes = []\n    expanded_classes = []\n    saltclass_path = salt_data['path']\n    for _class in classes:\n        all_classes.extend(match_class_glob(_class, saltclass_path))\n    for _class in all_classes:\n        if _class not in expanded_classes:\n            expanded_classes.$$$(_class)\n    return expanded_classes","msk_intervention":"def expand_classes_glob(classes, salt_data):\n    \"\"\"\n    Expand the list of `classes` to no longer include any globbing.\n\n    :param iterable(str) classes: Iterable of classes\n    :param dict salt_data: configuration data\n    :return: Expanded list of classes with resolved globbing\n    :rtype: list(str)\n    \"\"\"\n    all_classes = []\n    expanded_classes = []\n    saltclass_path = salt_data['path']\n    for _class in classes:\n        all_classes.extend(match_class_glob(_class, saltclass_path))\n    for _class in all_classes:\n        if _class in expanded_classes:\n            expanded_classes.$$$(_class)\n    return expanded_classes"}
